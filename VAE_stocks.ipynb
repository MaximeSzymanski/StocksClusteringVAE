{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:47.581400Z",
     "end_time": "2023-11-09T09:48:49.478684Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in ./venv/lib/python3.9/site-packages (0.2.31)\r\n",
      "Requirement already satisfied: pandas>=1.3.0 in ./venv/lib/python3.9/site-packages (from yfinance) (2.1.2)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in ./venv/lib/python3.9/site-packages (from yfinance) (1.26.1)\r\n",
      "Requirement already satisfied: requests>=2.31 in ./venv/lib/python3.9/site-packages (from yfinance) (2.31.0)\r\n",
      "Requirement already satisfied: multitasking>=0.0.7 in ./venv/lib/python3.9/site-packages (from yfinance) (0.0.11)\r\n",
      "Requirement already satisfied: lxml>=4.9.1 in ./venv/lib/python3.9/site-packages (from yfinance) (4.9.3)\r\n",
      "Requirement already satisfied: appdirs>=1.4.4 in ./venv/lib/python3.9/site-packages (from yfinance) (1.4.4)\r\n",
      "Requirement already satisfied: pytz>=2022.5 in ./venv/lib/python3.9/site-packages (from yfinance) (2023.3.post1)\r\n",
      "Requirement already satisfied: frozendict>=2.3.4 in ./venv/lib/python3.9/site-packages (from yfinance) (2.3.8)\r\n",
      "Requirement already satisfied: peewee>=3.16.2 in ./venv/lib/python3.9/site-packages (from yfinance) (3.17.0)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in ./venv/lib/python3.9/site-packages (from yfinance) (4.12.2)\r\n",
      "Requirement already satisfied: html5lib>=1.1 in ./venv/lib/python3.9/site-packages (from yfinance) (1.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\r\n",
      "Requirement already satisfied: six>=1.9 in ./venv/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\r\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2023.7.22)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T14:20:20.202061Z",
     "end_time": "2023-11-09T14:20:21.306441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the stock symbol (Google in this case)\n",
    "stock_symbol_1 = 'GOOGL'\n",
    "stock_symbol_2 = 'AAPL'\n",
    "stock_symbol_3 = 'MSFT'\n",
    "stock_symbol_4 = 'MRNA'\n",
    "stock_symbol_5 = 'TTOO'\n",
    "# Define the date range for the past 4 years\n",
    "start_date = '2019-11-08'\n",
    "end_date = '2023-11-08'\n",
    "\n",
    "# Download historical stock data using yfinance\n",
    "stock_data_1 = yf.download(stock_symbol_1, start=start_date, end=end_date)\n",
    "stock_data_2 = yf.download(stock_symbol_2, start=start_date, end=end_date)\n",
    "stock_data_3 = yf.download(stock_symbol_3, start=start_date, end=end_date)\n",
    "stock_data_4 = yf.download(stock_symbol_4, start=start_date, end=end_date)\n",
    "stock_data_5 = yf.download(stock_symbol_5, start=start_date, end=end_date)\n",
    "# Extract the 'Close' column\n",
    "close_values_1 = stock_data_1['Close'].values\n",
    "close_values_2 = stock_data_2['Close'].values\n",
    "close_values_3 = stock_data_3['Close'].values\n",
    "close_values_4 = stock_data_4['Close'].values\n",
    "close_values_5 = stock_data_5['Close'].values\n",
    "\n",
    "# Normalize the data between -1 and 1\n",
    "normalized_values_1 = 2 * (close_values_1 - np.min(close_values_1)) / np.ptp(close_values_1) -1\n",
    "normalized_values_2 = 2 * (close_values_2 - np.min(close_values_2)) / np.ptp(close_values_2) -1\n",
    "normalized_values_3 = 2 * (close_values_3 - np.min(close_values_3)) / np.ptp(close_values_3) -1\n",
    "normalized_values_4 = 2 * (close_values_4 - np.min(close_values_4)) / np.ptp(close_values_4) -1\n",
    "normalized_values_5 = 2 * (close_values_5 - np.min(close_values_5)) / np.ptp(close_values_5) -1\n",
    "\n",
    "print(f\"shape before : {normalized_values_1.shape}\")\n",
    "print(f\"shape before : {normalized_values_2.shape}\")\n",
    "print(f\"shape before : {normalized_values_3.shape}\")\n",
    "print(f\"shape before : {normalized_values_4.shape}\")\n",
    "print(f\"shape before : {normalized_values_5.shape}\")\n",
    "# remove the last 6 values\n",
    "normalized_values_1 = normalized_values_1[:-6]\n",
    "normalized_values_2 = normalized_values_2[:-6]\n",
    "normalized_values_3 = normalized_values_3[:-6]\n",
    "normalized_values_4 = normalized_values_4[:-6]\n",
    "normalized_values_5 = normalized_values_5[:-6]\n",
    "\n",
    "print(f\"shape after : {normalized_values_1.shape}\")\n",
    "print(f\"shape after : {normalized_values_2.shape}\")\n",
    "print(f\"shape after : {normalized_values_3.shape}\")\n",
    "print(f\"shape after : {normalized_values_4.shape}\")\n",
    "print(f\"shape after : {normalized_values_5.shape}\")\n",
    "# Plot the normalized data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(normalized_values_1)\n",
    "plt.plot(normalized_values_2)\n",
    "plt.plot(normalized_values_3)\n",
    "plt.plot(normalized_values_4)\n",
    "plt.plot(normalized_values_5)\n",
    "plt.legend([stock_symbol_1,stock_symbol_2,stock_symbol_3,stock_symbol_4,stock_symbol_5])\n",
    "\n",
    "plt.title('Normalized Stock Prices')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:49.483543Z",
     "end_time": "2023-11-09T09:48:50.478174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_series_length = 100\n",
    "assert len(normalized_values_1) % sub_series_length == 0\n",
    "assert len(normalized_values_2) % sub_series_length == 0\n",
    "assert len(normalized_values_3) % sub_series_length == 0\n",
    "assert len(normalized_values_4) % sub_series_length == 0\n",
    "assert len(normalized_values_5) % sub_series_length == 0\n",
    "\n",
    "sub_series_1 = normalized_values_1.reshape((-1, sub_series_length))\n",
    "sub_series_2 = normalized_values_2.reshape((-1, sub_series_length))\n",
    "sub_series_3 = normalized_values_3.reshape((-1, sub_series_length))\n",
    "sub_series_4 = normalized_values_4.reshape((-1, sub_series_length))\n",
    "sub_series_5 = normalized_values_5.reshape((-1, sub_series_length))\n",
    "print(f\"sub_series shape : {sub_series_1.shape}\")\n",
    "print(f\"sub_series shape : {sub_series_2.shape}\")\n",
    "print(f\"sub_series shape : {sub_series_3.shape}\")\n",
    "print(f\"sub_series shape : {sub_series_4.shape}\")\n",
    "print(f\"sub_series shape : {sub_series_5.shape}\")\n",
    "number_of_sub_series = sub_series_1.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.480105Z",
     "end_time": "2023-11-09T09:48:50.482495Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print a random sub series\n",
    "random_index = np.random.randint(0, sub_series_1.shape[0])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sub_series_1[random_index])\n",
    "plt.title('Random Sub Series')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.485929Z",
     "end_time": "2023-11-09T09:48:50.569372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SamplingLayerVAE(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SamplingLayerVAE, self).__init__()\n",
    "\n",
    "  def forward(self, mu, log_var):\n",
    "    std = torch.exp(0.5 * log_var)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=64,num_layers=3,bidirectional=False,\n",
    "               transfromer_hidden_size_attention = 64,num_heads=8,sub_seq_len=20,\n",
    "               latent_dim=64):\n",
    "    super(Encoder, self).__init__()\n",
    "    assert seq_len % sub_seq_len  == 0\n",
    "    self.number_of_sub_seq = seq_len // sub_seq_len\n",
    "    self.sub_seq_len = sub_seq_len\n",
    "    self.seq_len, self.n_features = seq_len, n_features\n",
    "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "    print(f\"hidden_dim: {self.hidden_dim}\")\n",
    "    self.num_layers = num_layers\n",
    "    self.bidirectional = bidirectional\n",
    "    self.mu = nn.Linear(self.sub_seq_len*self.embedding_dim, latent_dim)\n",
    "    self.log_var = nn.Linear(self.sub_seq_len*self.embedding_dim, latent_dim)\n",
    "    self.sampling_layer = SamplingLayerVAE()\n",
    "    self.rnn1 = nn.LSTM(\n",
    "          input_size=embedding_dim,\n",
    "          hidden_size=self.hidden_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "\n",
    "    multiple_bi = 2 if bidirectional else 1\n",
    "\n",
    "    self.rnn2 = nn.LSTM(\n",
    "          input_size=multiple_bi * self.hidden_dim,\n",
    "          hidden_size=embedding_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True\n",
    "    )\n",
    "    #self.positional_encoding = PositionalEncoding(embedding_dim)\n",
    "    self.embedding_layer = nn.Linear(n_features, embedding_dim)\n",
    "    print(f\"embedding_dim: {embedding_dim}\")\n",
    "    self.transformer_1 = CompressWithAttentionResidual(input_size=embedding_dim,output_size=embedding_dim,\n",
    "                                             hidden_size_attention=embedding_dim,\n",
    "                                             group_size=self.number_of_sub_seq)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    batch_size, seq_len, n_features = x.size()\n",
    "    original_x = x\n",
    "    #x = x.reshape((batch_size * seq_len, n_features))\n",
    "    x = self.embedding_layer(x)\n",
    "    x, (_, _) = self.rnn1(x)\n",
    "    x, (hidden_n, _) = self.rnn2(x)\n",
    "    x = self.transformer_1(x)\n",
    "    x = x.reshape((batch_size, self.sub_seq_len*self.embedding_dim))\n",
    "    mu = self.mu(x)\n",
    "    log_var = self.log_var(x)\n",
    "    z = self.sampling_layer(mu, log_var)\n",
    "\n",
    "    return z, mu, log_var, original_x\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, seq_len, input_dim=64, n_features=1,num_layers=3,bidirectional=False,\n",
    "               sub_seq_len=20,latent_dim=64):\n",
    "    super(Decoder, self).__init__()\n",
    "    assert seq_len % sub_seq_len  == 0\n",
    "    self.number_of_sub_seq = seq_len // sub_seq_len\n",
    "    self.sub_seq_len = sub_seq_len\n",
    "    self.seq_len, self.input_dim = seq_len, input_dim\n",
    "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "    self.num_layers = num_layers\n",
    "    self.bidirectional = bidirectional\n",
    "    self.output_embeding = OutputEmbedding(input_dim=self.hidden_dim,seq_len=self.seq_len,output_dim=1)\n",
    "    self.rnn1 = nn.LSTM(\n",
    "          input_size=latent_dim,\n",
    "          hidden_size=input_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "    multiple_bi = 2 if bidirectional else 1\n",
    "    self.rnn2 = nn.LSTM(\n",
    "      input_size=input_dim * multiple_bi,\n",
    "      hidden_size=self.hidden_dim,\n",
    "      num_layers=self.num_layers,\n",
    "      batch_first=True\n",
    "    )\n",
    "  def forward(self, x):\n",
    "\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    # x is shape (batch_size, 1, n_features)\n",
    "    # repeat the last dimension to have (batch_size, seq_len, n_features)\n",
    "    x = x.unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "\n",
    "\n",
    "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "    x = x.reshape((batch_size,self.seq_len, self.hidden_dim))\n",
    "    x = self.output_embeding(x)\n",
    "\n",
    "    # keep only the last layer\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "class CompressWithAttentionResidual(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size_attention, group_size):\n",
    "        super(CompressWithAttentionResidual, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size_attention\n",
    "        self.group_size = group_size\n",
    "\n",
    "        # Linear projections for attention\n",
    "        self.Q_linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.K_linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.V_linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "\n",
    "        # Final linear transformations\n",
    "        self.attention_output_linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.output_linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is shape (batch_size, seq_len, n_features)\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        # Reshape input into groups of size self.group_size\n",
    "        x = x.view(batch_size, -1, self.group_size, n_features)\n",
    "        group_len = x.size(1)\n",
    "\n",
    "        # Linear projections for attention\n",
    "        Q = self.Q_linear(x)\n",
    "        K = self.K_linear(x)\n",
    "        V = self.V_linear(x)\n",
    "\n",
    "        # Compute attention weights\n",
    "        attention_weights = torch.matmul(Q, K.transpose(-2, -1)) / (self.hidden_size ** 0.5)\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "\n",
    "        # Apply attention weights to values\n",
    "        attended_values = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # Sum along the group dimension\n",
    "        attended_values = attended_values.sum(dim=2)\n",
    "\n",
    "        # Apply final linear transformations\n",
    "        attention_output = self.attention_output_linear(attended_values)\n",
    "        # Add residual connection\n",
    "        out = attention_output\n",
    "\n",
    "        # Final linear transformation\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        # RElu\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self,seq_len, input_dim=1,output_dim=64):\n",
    "        super(InputEmbedding, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Linear(self.input_dim, self.output_dim)\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        x = x.reshape((batch_size * seq_len, n_features))\n",
    "        x = self.embedding(x)\n",
    "        x = x.reshape((batch_size, seq_len, self.output_dim))\n",
    "        return x\n",
    "\n",
    "class OutputEmbedding(nn.Module):\n",
    "    def __init__(self,seq_len, input_dim=64,output_dim=1):\n",
    "        super(OutputEmbedding, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Linear(self.input_dim, self.output_dim)\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        x = x.reshape((batch_size * seq_len, n_features))\n",
    "        x = self.embedding(x)\n",
    "        x = x.reshape((batch_size, seq_len, self.output_dim))\n",
    "        return x\n",
    "\"\"\"class PositionalEncoding(nn.Module):\n",
    "    # write positional encoding for time series data\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.pe = torch.zeros(self.max_len, self.d_model).to(self.device)\n",
    "        position = torch.arange(0, self.max_len, dtype=torch.float).unsqueeze(1).to(self.device)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model)).to(self.device)\n",
    "        self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0).transpose(0, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "\n",
    "        return self.dropout(x).permute(1, 0, 2)\"\"\"\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.585716Z",
     "end_time": "2023-11-09T09:48:50.588155Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RecurrentAutoencoder(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=128,sub_seq_len=10,latent_dim=2):\n",
    "    super(RecurrentAutoencoder, self).__init__()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.encoder = Encoder(seq_len, n_features, embedding_dim,bidirectional=True,num_layers=1,\n",
    "        sub_seq_len=sub_seq_len,latent_dim=latent_dim).to(device)\n",
    "    self.decoder = Decoder(seq_len, embedding_dim, n_features,bidirectional=True,num_layers=1,\n",
    "        sub_seq_len=sub_seq_len,latent_dim=latent_dim).to(device)\n",
    "  def forward(self, x):\n",
    "    z, mu, sigma, original_x = self.encoder(x)\n",
    "    x = self.decoder(z)\n",
    "    x = nn.Tanh()(x)\n",
    "    return x, original_x, mu, sigma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.589895Z",
     "end_time": "2023-11-09T09:48:50.636661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"sub_series_length : {sub_series_length}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RecurrentAutoencoder(sub_series_length, 1, 128,sub_seq_len=50,latent_dim=16).to(device)\n",
    "print(f\"model : {model}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.593670Z",
     "end_time": "2023-11-09T09:48:50.636889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def KL_loss(mu, sigma):\n",
    "    return -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "\n",
    "def reconstruction_loss(x, y):\n",
    "\n",
    "    return nn.MSELoss(reduction='sum')(x,y)\n",
    "\n",
    "def loss_function(x, original_x, mu, sigma,k1=1,k2=1e-2):\n",
    "    return k1 *reconstruction_loss(original_x, x) + k2 * KL_loss(mu, sigma)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.618465Z",
     "end_time": "2023-11-09T09:48:50.636918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# take only square and sinusoidal signals\n",
    "\n",
    "\n",
    "signal_to_tensor_1 = torch.from_numpy(sub_series_1).float().unsqueeze(2).to(device)\n",
    "signal_to_tensor_2 = torch.from_numpy(sub_series_2).float().unsqueeze(2).to(device)\n",
    "signal_to_tensor_3 = torch.from_numpy(sub_series_3).float().unsqueeze(2).to(device)\n",
    "signal_to_tensor_4 = torch.from_numpy(sub_series_4).float().unsqueeze(2).to(device)\n",
    "signal_to_tensor_5 = torch.from_numpy(sub_series_5).float().unsqueeze(2).to(device)\n",
    "\n",
    "signal_to_tensor_cat = torch.cat((signal_to_tensor_1,signal_to_tensor_2,signal_to_tensor_3,\n",
    "                                  signal_to_tensor_4,signal_to_tensor_5),dim=0)\n",
    "print(f\"Initial signal shape: {signal_to_tensor_cat.shape}\")\n",
    "x, original_x, mu, sigma = model(signal_to_tensor_cat)\n",
    "print(f\"Input shape: {signal_to_tensor_cat.shape}\")\n",
    "print(f\"Output shape: {x.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.627637Z",
     "end_time": "2023-11-09T09:48:50.926899Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the reconstruction\n",
    "# get a random signal\n",
    "random_index = np.random.randint(0, signal_to_tensor_cat.shape[0])\n",
    "output_decoded = x[random_index].squeeze().detach().numpy()\n",
    "# take the first signal\n",
    "signal = signal_to_tensor_cat[random_index].squeeze().detach().numpy()\n",
    "print(signal.shape)\n",
    "plt.plot(signal, label='signal')\n",
    "plt.plot(output_decoded, label='reconstructed signal')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:48:50.930510Z",
     "end_time": "2023-11-09T09:48:50.994074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# try a simple overfitting\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00008)\n",
    "#loss_fn = nn.L1Loss(reduction='sum')\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    x, original_x, mu, sigma = model(signal_to_tensor_cat)\n",
    "\n",
    "    loss = loss_function(x, original_x, mu, sigma)\n",
    "    loss.backward()\n",
    "    # visualize the gradients of the last lstm layer\n",
    "\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, loss: {loss.item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:31:21.429610Z",
     "end_time": "2023-11-09T09:31:22.601586Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the reconstruction\n",
    "# get a random signal\n",
    "random_index = np.random.randint(0, signal_to_tensor_cat.shape[0])\n",
    "output_decoded = x[random_index].squeeze().detach().numpy()\n",
    "# take the first signal\n",
    "signal = signal_to_tensor_cat[random_index].squeeze().detach().numpy()\n",
    "plt.plot(signal, label='signal')\n",
    "plt.plot(output_decoded, label='reconstructed signal')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:50:21.144837Z",
     "end_time": "2023-11-09T09:50:21.216827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# encode and decode all the signals\n",
    "signals_1,_,_,_ = model(signal_to_tensor_1)\n",
    "signals_1 = signals_1.squeeze().detach().numpy()\n",
    "signals_2,_,_,_ = model(signal_to_tensor_2)\n",
    "signals_2 = signals_2.squeeze().detach().numpy()\n",
    "signals_3,_,_,_ = model(signal_to_tensor_3)\n",
    "signals_3 = signals_3.squeeze().detach().numpy()\n",
    "signals_4,_,_,_ = model(signal_to_tensor_4)\n",
    "signals_4 = signals_4.squeeze().detach().numpy()\n",
    "signals_5,_,_,_ = model(signal_to_tensor_5)\n",
    "signals_5 = signals_5.squeeze().detach().numpy()\n",
    "# concatenate all the signals\n",
    "\n",
    "signals_1 = signals_1.reshape(len(normalized_values_1))\n",
    "signals_2 = signals_2.reshape(len(normalized_values_2))\n",
    "signals_3 = signals_3.reshape(len(normalized_values_3))\n",
    "signals_4 = signals_4.reshape(len(normalized_values_4))\n",
    "signals_5 = signals_5.reshape(len(normalized_values_5))\n",
    "# Assuming normalized_values_1, normalized_values_2, normalized_values_3,\n",
    "# signals_1, signals_2, and signals_3 are defined\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot signal_1 in the first subplot\n",
    "axes[0].plot(normalized_values_1, label='signal_1')\n",
    "axes[0].plot(signals_1, label='reconstructed signal')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot signal_2 in the second subplot\n",
    "axes[1].plot(normalized_values_2, label='signal_2')\n",
    "axes[1].plot(signals_2, label='reconstructed signal')\n",
    "axes[1].legend()\n",
    "\n",
    "# Plot signal_3 in the third subplot\n",
    "axes[2].plot(normalized_values_3, label='signal_3')\n",
    "axes[2].plot(signals_3, label='reconstructed signal')\n",
    "axes[2].legend()\n",
    "\n",
    "# Plot signal_4 in the fourth subplot\n",
    "axes[3].plot(normalized_values_4, label='signal_4')\n",
    "axes[3].plot(signals_4, label='reconstructed signal')\n",
    "axes[3].legend()\n",
    "\n",
    "# Plot signal_5 in the fifth subplot\n",
    "axes[4].plot(normalized_values_5, label='signal_5')\n",
    "axes[4].plot(signals_5, label='reconstructed signal')\n",
    "axes[4].legend()\n",
    "# Show the subplots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:50:21.803049Z",
     "end_time": "2023-11-09T09:50:22.565638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# apply PCA on the latent space\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "latent_space = pca.fit_transform(mu.detach().numpy())\n",
    "print(f\"latent space shape : {latent_space.shape}\")\n",
    "print(f\"normalized_values_1 shape : {normalized_values_1.shape}\")\n",
    "# decompose the latent space\n",
    "print(f\"sequences : {number_of_sub_series}\")\n",
    "latent_space_1 = latent_space[0:number_of_sub_series]\n",
    "latent_space_2 = latent_space[number_of_sub_series:2*number_of_sub_series]\n",
    "latent_space_3 = latent_space[2*number_of_sub_series:3*number_of_sub_series]\n",
    "latent_space_4 = latent_space[3*number_of_sub_series:4*number_of_sub_series]\n",
    "latent_space_5 = latent_space[4*number_of_sub_series:5*number_of_sub_series]\n",
    "\n",
    "# plot the latent space with the 3 signals in different colors\n",
    "plt.scatter(latent_space_1[:,0],latent_space_1[:,1],label='signal_1')\n",
    "plt.scatter(latent_space_2[:,0],latent_space_2[:,1],label='signal_2')\n",
    "plt.scatter(latent_space_3[:,0],latent_space_3[:,1],label='signal_3')\n",
    "plt.scatter(latent_space_4[:,0],latent_space_4[:,1],label='signal_4')\n",
    "plt.scatter(latent_space_5[:,0],latent_space_5[:,1],label='signal_5')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:43:50.009080Z",
     "end_time": "2023-11-09T09:43:51.026537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sum all point of each signal in the latent space and plot the result\n",
    "latent_space_1_sum = np.sum(latent_space_1,axis=0)\n",
    "latent_space_2_sum = np.sum(latent_space_2,axis=0)\n",
    "latent_space_3_sum = np.sum(latent_space_3,axis=0)\n",
    "latent_space_4_sum = np.sum(latent_space_4,axis=0)\n",
    "latent_space_5_sum = np.sum(latent_space_5,axis=0)\n",
    "\n",
    "# Define a small neighborhood around the given point\n",
    "neighborhood_size = 0.1\n",
    "neighborhood = np.random.uniform(-neighborhood_size, neighborhood_size, size=(number_of_sub_series, 2))\n",
    "\n",
    "# Generate points around the given point\n",
    "latent_points_around_given = latent_space_1_sum + neighborhood\n",
    "# concatenate all the latent points\n",
    "\n",
    "\n",
    "plt.scatter(latent_space_1_sum[0],latent_space_1_sum[1],label='signal_1')\n",
    "plt.scatter(latent_space_2_sum[0],latent_space_2_sum[1],label='signal_2')\n",
    "plt.scatter(latent_space_3_sum[0],latent_space_3_sum[1],label='signal_3')\n",
    "plt.scatter(latent_space_4_sum[0],latent_space_4_sum[1],label='signal_4')\n",
    "plt.scatter(latent_space_5_sum[0],latent_space_5_sum[1],label='signal_5')\n",
    "plt.scatter(latent_points_around_given[:,0],latent_points_around_given[:,1],label='latent points around signal_1')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:43:51.039322Z",
     "end_time": "2023-11-09T09:43:51.165333Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "latent_points_around_given = np.concatenate(latent_points_around_given,axis=0)\n",
    "print(f\"latent_points_around_given shape : {latent_points_around_given.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:43:53.472128Z",
     "end_time": "2023-11-09T09:43:53.505017Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sum all point of each signal in the latent space and plot the result\n",
    "latent_space_1_sum = np.sum(latent_space_1,axis=0)\n",
    "latent_space_2_sum = np.sum(latent_space_2,axis=0)\n",
    "latent_space_3_sum = np.sum(latent_space_3,axis=0)\n",
    "latent_space_4_sum = np.sum(latent_space_4,axis=0)\n",
    "latent_space_5_sum = np.sum(latent_space_5,axis=0)\n",
    "plt.scatter(latent_space_1_sum[0],latent_space_1_sum[1],label='signal_1')\n",
    "plt.scatter(latent_space_2_sum[0],latent_space_2_sum[1],label='signal_2')\n",
    "plt.scatter(latent_space_3_sum[0],latent_space_3_sum[1],label='signal_3')\n",
    "plt.scatter(latent_space_4_sum[0],latent_space_4_sum[1],label='signal_4')\n",
    "plt.scatter(latent_space_5_sum[0],latent_space_5_sum[1],label='signal_5')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:43:53.627544Z",
     "end_time": "2023-11-09T09:43:53.713493Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the normalized data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(normalized_values_1)\n",
    "plt.plot(normalized_values_2)\n",
    "plt.plot(normalized_values_3)\n",
    "plt.plot(normalized_values_4)\n",
    "plt.plot(normalized_values_5)\n",
    "plt.legend([stock_symbol_1,stock_symbol_2,stock_symbol_3,stock_symbol_4,stock_symbol_5])\n",
    "\n",
    "plt.title('Normalized Stock Prices')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T09:31:35.521366Z",
     "end_time": "2023-11-09T09:31:35.668536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-09T01:34:23.720712Z",
     "end_time": "2023-11-09T01:34:23.721889Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
