{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MaximeSzymanski/StocksClusteringVAE/blob/main/VAE_stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "JWeowTDmufGn",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:26:55.996430Z",
     "start_time": "2023-11-25T20:26:55.986947Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DhNDk_sdufGo",
    "outputId": "91033c3f-4fec-49d8-ad65-074c1970a7f6",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:17:25.126226Z",
     "start_time": "2023-11-25T20:17:25.023042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'!pip install yfinance\\n!pip install BeautifulSoup\\n!pip install requests'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"!pip install yfinance\n",
    "!pip install BeautifulSoup\n",
    "!pip install requests\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ixrPIZEgufGo",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:17:25.128039Z",
     "start_time": "2023-11-25T20:17:25.124447Z"
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def download_stocks(ticker_list, start_date='2019-11-08', end_date='2023-11-08'):\n",
    "    # Set seed for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Initialize an empty list to store normalized values\n",
    "    normalized_values_list = []\n",
    "    stocks_kept = []\n",
    "    iterator = 0\n",
    "    kept_stocks_with_indexes = []\n",
    "\n",
    "    # Loop through each stock symbol\n",
    "    for index, symbol in enumerate(ticker_list):\n",
    "        try:\n",
    "            # Download historical stock data using yfinance\n",
    "            stock_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "            # Extract the 'Close' column\n",
    "            close_values = stock_data['Close'].values\n",
    "            if len(close_values) >= 0:\n",
    "                # Normalize the data between -1 and 1\n",
    "                normalized_values = 2 * (close_values - np.min(close_values)) / np.ptp(close_values) - 1\n",
    "                normalized_values_list.append(normalized_values)\n",
    "                stocks_kept.append(symbol)\n",
    "                print(f\"stocks {iterator}/{len(ticker_list)}\")\n",
    "                iterator += 1\n",
    "                kept_stocks_with_indexes.append((index, symbol, normalized_values))\n",
    "            else:\n",
    "                # remove the stock if it has not enough data\n",
    "                print(f\"stock {symbol} has not enough data\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading data for {symbol}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # get the different lengths of the stocks\n",
    "    lengths = [len(stock[2]) for stock in kept_stocks_with_indexes]\n",
    "    lengths_set = set(lengths)\n",
    "\n",
    "    # get the most common length\n",
    "    most_common_length = max(set(lengths), key=lengths.count)\n",
    "\n",
    "    # keep only the stocks with the most common length\n",
    "    normalized_values_list = [stock[2] for stock in kept_stocks_with_indexes if len(stock[2]) == most_common_length]\n",
    "    kept_stocks_with_indexes = [(index, symbol) for index, symbol, normalized_values in kept_stocks_with_indexes if len(normalized_values) == most_common_length]\n",
    "\n",
    "    # length is 1006, so we need to remove the last 6 values for each stock\n",
    "    normalized_values_list = [normalized_values[:-6] for normalized_values in normalized_values_list]\n",
    "\n",
    "    return normalized_values_list, kept_stocks_with_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyYwAcFYcnVH",
    "outputId": "85ed04ce-251d-41fe-9d40-2f57e077b3c3",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:17:25.802541Z",
     "start_time": "2023-11-25T20:17:25.355407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker : AAON\n",
      "ticker : AAP\n",
      "ticker : AAT\n",
      "ticker : ABCB\n",
      "ticker : ABG\n",
      "ticker : ABM\n",
      "ticker : ABR\n",
      "ticker : ACA\n",
      "ticker : ACIW\n",
      "ticker : ACLS\n",
      "ticker : ADEA\n",
      "ticker : ADTN\n",
      "ticker : ADUS\n",
      "ticker : AEIS\n",
      "ticker : AEL\n",
      "ticker : AEO\n",
      "ticker : AGO\n",
      "ticker : AGTI\n",
      "ticker : AGYS\n",
      "ticker : AHCO\n",
      "ticker : AHH\n",
      "ticker : AIN\n",
      "ticker : AIR\n",
      "ticker : AIT\n",
      "ticker : AKR\n",
      "ticker : ALEX\n",
      "ticker : ALG\n",
      "ticker : ALGT\n",
      "ticker : ALRM\n",
      "ticker : AMBC\n",
      "ticker : AMCX\n",
      "ticker : AMEH\n",
      "ticker : AMN\n",
      "ticker : AMPH\n",
      "ticker : AMR\n",
      "ticker : AMSF\n",
      "ticker : AMWD\n",
      "ticker : ANDE\n",
      "ticker : ANF\n",
      "ticker : ANIP\n",
      "ticker : AORT\n",
      "ticker : AOSL\n",
      "ticker : APAM\n",
      "ticker : APLE\n",
      "ticker : APOG\n",
      "ticker : APPS\n",
      "ticker : ARCB\n",
      "ticker : ARI\n",
      "ticker : ARLO\n",
      "ticker : AROC\n",
      "ticker : ARR\n",
      "ticker : ASIX\n",
      "ticker : ASO\n",
      "ticker : ASTE\n",
      "ticker : ATEN\n",
      "ticker : ATGE\n",
      "ticker : ATI\n",
      "ticker : ATNI\n",
      "ticker : AUB\n",
      "ticker : AVA\n",
      "ticker : AVAV\n",
      "ticker : AVNS\n",
      "ticker : AVTA\n",
      "ticker : AWR\n",
      "ticker : AX\n",
      "ticker : AXL\n",
      "ticker : AZZ\n",
      "ticker : B\n",
      "ticker : BANC\n",
      "ticker : BANF\n",
      "ticker : BANR\n",
      "ticker : BCC\n",
      "ticker : BCPC\n",
      "ticker : BDN\n",
      "ticker : BFH\n",
      "ticker : BFS\n",
      "ticker : BGS\n",
      "ticker : BHE\n",
      "ticker : BHLB\n",
      "ticker : BJRI\n",
      "ticker : BKE\n",
      "ticker : BKU\n",
      "ticker : BLFS\n",
      "ticker : BLMN\n",
      "ticker : BMI\n",
      "ticker : BOH\n",
      "ticker : BOOT\n",
      "ticker : BRC\n",
      "ticker : BRKL\n",
      "ticker : BSIG\n",
      "ticker : BXMT\n",
      "ticker : CAKE\n",
      "ticker : CAL\n",
      "ticker : CALM\n",
      "ticker : CARG\n",
      "ticker : CARS\n",
      "ticker : CASH\n",
      "ticker : CATY\n",
      "ticker : CBRL\n",
      "ticker : CBU\n",
      "ticker : CCOI\n",
      "ticker : CCRN\n",
      "ticker : CCS\n",
      "ticker : CCSI\n",
      "ticker : CDMO\n",
      "ticker : CEIX\n",
      "ticker : CENT\n",
      "ticker : CENTA\n",
      "ticker : CENX\n",
      "ticker : CERT\n",
      "ticker : CEVA\n",
      "ticker : CFFN\n",
      "ticker : CHCO\n",
      "ticker : CHCT\n",
      "ticker : CHEF\n",
      "ticker : CHS\n",
      "ticker : CHUY\n",
      "ticker : CLB\n",
      "ticker : CLDT\n",
      "ticker : CLFD\n",
      "ticker : CLW\n",
      "ticker : CMP\n",
      "ticker : CNK\n",
      "ticker : CNMD\n",
      "ticker : CNSL\n",
      "ticker : CNXN\n",
      "ticker : COHU\n",
      "ticker : COLL\n",
      "ticker : COOP\n",
      "ticker : CORT\n",
      "ticker : CPE\n",
      "ticker : CPF\n",
      "ticker : CPK\n",
      "ticker : CPRX\n",
      "ticker : CRC\n",
      "ticker : CRK\n",
      "ticker : CRMT\n",
      "ticker : CRNC\n",
      "ticker : CRS\n",
      "ticker : CRSR\n",
      "ticker : CRVL\n",
      "ticker : CSGS\n",
      "ticker : CSR\n",
      "ticker : CTKB\n",
      "ticker : CTRE\n",
      "ticker : CTS\n",
      "ticker : CUBI\n",
      "ticker : CVBF\n",
      "ticker : CVCO\n",
      "ticker : CVGW\n",
      "ticker : CVI\n",
      "ticker : CWK\n",
      "ticker : CWT\n",
      "ticker : CXW\n",
      "ticker : CYH\n",
      "ticker : CYTK\n",
      "ticker : DAN\n",
      "ticker : DBI\n",
      "ticker : DCOM\n",
      "ticker : DDD\n",
      "ticker : DEA\n",
      "ticker : DEI\n",
      "ticker : DFIN\n",
      "ticker : DGII\n",
      "ticker : DIN\n",
      "ticker : DIOD\n",
      "ticker : DISH\n",
      "ticker : DLX\n",
      "ticker : DNOW\n",
      "ticker : DORM\n",
      "ticker : DRH\n",
      "ticker : DRQ\n",
      "ticker : DV\n",
      "ticker : DVAX\n",
      "ticker : DXC\n",
      "ticker : DXPE\n",
      "ticker : DY\n",
      "ticker : EAT\n",
      "ticker : ECPG\n",
      "ticker : EFC\n",
      "ticker : EGBN\n",
      "ticker : EHAB\n",
      "ticker : EIG\n",
      "ticker : ELF\n",
      "ticker : EMBC\n",
      "ticker : ENR\n",
      "ticker : ENSG\n",
      "ticker : ENV\n",
      "ticker : ENVA\n",
      "ticker : EPAC\n",
      "ticker : EPC\n",
      "ticker : EPRT\n",
      "ticker : ESE\n",
      "ticker : ETD\n",
      "ticker : EVTC\n",
      "ticker : EXPI\n",
      "ticker : EXTR\n",
      "ticker : EYE\n",
      "ticker : EZPW\n",
      "ticker : FBK\n",
      "ticker : FBNC\n",
      "ticker : FBP\n",
      "ticker : FBRT\n",
      "ticker : FCF\n",
      "ticker : FCPT\n",
      "ticker : FDP\n",
      "ticker : FELE\n",
      "ticker : FFBC\n",
      "ticker : FHB\n",
      "ticker : FIX\n",
      "ticker : FIZZ\n",
      "ticker : FL\n",
      "ticker : FLGT\n",
      "ticker : FN\n",
      "ticker : FORM\n",
      "ticker : FORR\n",
      "ticker : FSS\n",
      "ticker : FTDR\n",
      "ticker : FTRE\n",
      "ticker : FUL\n",
      "ticker : FULT\n",
      "ticker : FWRD\n",
      "ticker : GBX\n",
      "ticker : GDEN\n",
      "ticker : GDOT\n",
      "ticker : GEO\n",
      "ticker : GES\n",
      "ticker : GFF\n",
      "ticker : GIII\n",
      "ticker : GKOS\n",
      "ticker : GMS\n",
      "ticker : GNL\n",
      "ticker : GNW\n",
      "ticker : GOGO\n",
      "ticker : GPI\n",
      "ticker : GPRE\n",
      "ticker : GRBK\n",
      "ticker : GSHD\n",
      "ticker : GTY\n",
      "ticker : GVA\n",
      "ticker : HAFC\n",
      "ticker : HAIN\n",
      "ticker : HASI\n",
      "ticker : HAYN\n",
      "ticker : HAYW\n",
      "ticker : HBI\n",
      "ticker : HCC\n",
      "ticker : HCI\n",
      "ticker : HCSG\n",
      "ticker : HFWA\n",
      "ticker : HI\n",
      "ticker : HIBB\n",
      "ticker : HIW\n",
      "ticker : HLIT\n",
      "ticker : HLX\n",
      "ticker : HMN\n",
      "ticker : HNI\n",
      "ticker : HOPE\n",
      "ticker : HOUS\n",
      "ticker : HP\n",
      "ticker : HPP\n",
      "ticker : HRMY\n",
      "ticker : NVRI\n",
      "ticker : HSII\n",
      "ticker : HSTM\n",
      "ticker : HTH\n",
      "ticker : HTLD\n",
      "ticker : HUBG\n",
      "ticker : HVT\n",
      "ticker : HWKN\n",
      "ticker : HZO\n",
      "ticker : IBP\n",
      "ticker : IBTX\n",
      "ticker : ICHR\n",
      "ticker : IDCC\n",
      "ticker : IIIN\n",
      "ticker : IIPR\n",
      "ticker : INDB\n",
      "ticker : INN\n",
      "ticker : INVA\n",
      "ticker : IOSP\n",
      "ticker : IPAR\n",
      "ticker : IRBT\n",
      "ticker : IRWD\n",
      "ticker : ITGR\n",
      "ticker : ITRI\n",
      "ticker : IVR\n",
      "ticker : JACK\n",
      "ticker : JBGS\n",
      "ticker : JBLU\n",
      "ticker : JBSS\n",
      "ticker : JBT\n",
      "ticker : JJSF\n",
      "ticker : JOE\n",
      "ticker : JRVR\n",
      "ticker : JXN\n",
      "ticker : KALU\n",
      "ticker : KAMN\n",
      "ticker : KAR\n",
      "ticker : KELYA\n",
      "ticker : KFY\n",
      "ticker : KLG\n",
      "ticker : KLIC\n",
      "ticker : KMT\n",
      "ticker : KN\n",
      "ticker : KOP\n",
      "ticker : KREF\n",
      "ticker : KSS\n",
      "ticker : KTB\n",
      "ticker : KW\n",
      "ticker : KWR\n",
      "ticker : LBRT\n",
      "ticker : LCII\n",
      "ticker : LESL\n",
      "ticker : LGIH\n",
      "ticker : LGND\n",
      "ticker : LKFN\n",
      "ticker : LMAT\n",
      "ticker : LNC\n",
      "ticker : LNN\n",
      "ticker : LPG\n",
      "ticker : LQDT\n",
      "ticker : LRN\n",
      "ticker : LTC\n",
      "ticker : LTHM\n",
      "ticker : LUMN\n",
      "ticker : LXP\n",
      "ticker : LZB\n",
      "ticker : MAC\n",
      "ticker : MATV\n",
      "ticker : MATW\n",
      "ticker : MATX\n",
      "ticker : MBC\n",
      "ticker : MC\n",
      "ticker : MCRI\n",
      "ticker : MCS\n",
      "ticker : MCW\n",
      "ticker : MCY\n",
      "ticker : MD\n",
      "ticker : MDC\n",
      "ticker : MDRX\n",
      "ticker : MED\n",
      "ticker : MEI\n",
      "ticker : MERC\n",
      "ticker : MGPI\n",
      "ticker : MHO\n",
      "ticker : MLAB\n",
      "ticker : MLKN\n",
      "ticker : MLI\n",
      "ticker : MMI\n",
      "ticker : MMSI\n",
      "ticker : MNRO\n",
      "ticker : MODV\n",
      "ticker : MOG-A\n",
      "ticker : MOV\n",
      "ticker : MRCY\n",
      "ticker : MRTN\n",
      "ticker : MSEX\n",
      "ticker : MSGS\n",
      "ticker : MTH\n",
      "ticker : MTRN\n",
      "ticker : MTX\n",
      "ticker : MXL\n",
      "ticker : MYE\n",
      "ticker : MYGN\n",
      "ticker : MYRG\n",
      "ticker : NABL\n",
      "ticker : NATL\n",
      "ticker : NAVI\n",
      "ticker : NBHC\n",
      "ticker : NBR\n",
      "ticker : NBTB\n",
      "ticker : NEO\n",
      "ticker : NFBK\n",
      "ticker : NGVT\n",
      "ticker : NMIH\n",
      "ticker : NOG\n",
      "ticker : NPK\n",
      "ticker : NPO\n",
      "ticker : NSIT\n",
      "ticker : NTCT\n",
      "ticker : NUS\n",
      "ticker : NVEE\n",
      "ticker : NWBI\n",
      "ticker : NWL\n",
      "ticker : NWN\n",
      "ticker : NX\n",
      "ticker : NXRT\n",
      "ticker : NYMT\n",
      "ticker : ODP\n",
      "ticker : OFG\n",
      "ticker : OFIX\n",
      "ticker : OGN\n",
      "ticker : OI\n",
      "ticker : OII\n",
      "ticker : OIS\n",
      "ticker : OMCL\n",
      "ticker : OMI\n",
      "ticker : OSIS\n",
      "ticker : OSPN\n",
      "ticker : OSUR\n",
      "ticker : OTTR\n",
      "ticker : OUT\n",
      "ticker : OXM\n",
      "ticker : PACW\n",
      "ticker : PAHC\n",
      "ticker : PARR\n",
      "ticker : PAYO\n",
      "ticker : PATK\n",
      "ticker : PBH\n",
      "ticker : PBI\n",
      "ticker : PCRX\n",
      "ticker : PDFS\n",
      "ticker : PEB\n",
      "ticker : PECO\n",
      "ticker : PFBC\n",
      "ticker : PFS\n",
      "ticker : PGTI\n",
      "ticker : PHIN\n",
      "ticker : PINC\n",
      "ticker : PIPR\n",
      "ticker : PLAB\n",
      "ticker : PLAY\n",
      "ticker : PLMR\n",
      "ticker : PLUS\n",
      "ticker : PLXS\n",
      "ticker : PMT\n",
      "ticker : POWL\n",
      "ticker : PPBI\n",
      "ticker : PRA\n",
      "ticker : PRAA\n",
      "ticker : PRDO\n",
      "ticker : PRFT\n",
      "ticker : PRG\n",
      "ticker : PRGS\n",
      "ticker : PRK\n",
      "ticker : PRLB\n",
      "ticker : PRVA\n",
      "ticker : PSMT\n",
      "ticker : PTEN\n",
      "ticker : PUMP\n",
      "ticker : PZZA\n",
      "ticker : QNST\n",
      "ticker : RAMP\n",
      "ticker : RC\n",
      "ticker : UPBD\n",
      "ticker : RCUS\n",
      "ticker : RDN\n",
      "ticker : RDNT\n",
      "ticker : RES\n",
      "ticker : REX\n",
      "ticker : REZI\n",
      "ticker : RGNX\n",
      "ticker : RGP\n",
      "ticker : RGR\n",
      "ticker : RILY\n",
      "ticker : RMBS\n",
      "ticker : RNST\n",
      "ticker : ROCK\n",
      "ticker : ROG\n",
      "ticker : ROIC\n",
      "ticker : RPT\n",
      "ticker : RWT\n",
      "ticker : RXO\n",
      "ticker : SAFE\n",
      "ticker : SABR\n",
      "ticker : SAFT\n",
      "ticker : SAH\n",
      "ticker : SANM\n",
      "ticker : SBCF\n",
      "ticker : SBH\n",
      "ticker : SBSI\n",
      "ticker : SCHL\n",
      "ticker : SCL\n",
      "ticker : SCSC\n",
      "ticker : SCVL\n",
      "ticker : SDGR\n",
      "ticker : SEM\n",
      "ticker : SFBS\n",
      "ticker : SFNC\n",
      "ticker : SGH\n",
      "ticker : SHAK\n",
      "ticker : SHEN\n",
      "ticker : SHO\n",
      "ticker : SHOO\n",
      "ticker : SIG\n",
      "ticker : SITC\n",
      "ticker : SITM\n",
      "ticker : SIX\n",
      "ticker : SJW\n",
      "ticker : SKT\n",
      "ticker : SKYW\n",
      "ticker : SLCA\n",
      "ticker : SLG\n",
      "ticker : SLP\n",
      "ticker : SLVM\n",
      "ticker : SM\n",
      "ticker : SMP\n",
      "ticker : SMPL\n",
      "ticker : SMTC\n",
      "ticker : SNBR\n",
      "ticker : SNCY\n",
      "ticker : SNEX\n",
      "ticker : SONO\n",
      "ticker : SPNT\n",
      "ticker : SPSC\n",
      "ticker : SPTN\n",
      "ticker : SPWR\n",
      "ticker : SPXC\n",
      "ticker : SSP\n",
      "ticker : SSTK\n",
      "ticker : STAA\n",
      "ticker : STBA\n",
      "ticker : STC\n",
      "ticker : STEL\n",
      "ticker : STRA\n",
      "ticker : SUPN\n",
      "ticker : SVC\n",
      "ticker : SXC\n",
      "ticker : SXI\n",
      "ticker : SXT\n",
      "ticker : TALO\n",
      "ticker : TBBK\n",
      "ticker : TBI\n",
      "ticker : TDS\n",
      "ticker : TFIN\n",
      "ticker : TGI\n",
      "ticker : THRM\n",
      "ticker : THRY\n",
      "ticker : THS\n",
      "ticker : TILE\n",
      "ticker : TMP\n",
      "ticker : TMST\n",
      "ticker : TNC\n",
      "ticker : TNDM\n",
      "ticker : TPH\n",
      "ticker : TR\n",
      "ticker : TRIP\n",
      "ticker : TRMK\n",
      "ticker : TRN\n",
      "ticker : TRST\n",
      "ticker : TRUP\n",
      "ticker : TTEC\n",
      "ticker : TTGT\n",
      "ticker : TTMI\n",
      "ticker : TWI\n",
      "ticker : TWO\n",
      "ticker : UCBI\n",
      "ticker : UCTT\n",
      "ticker : UE\n",
      "ticker : UFCS\n",
      "ticker : UFPT\n",
      "ticker : UHT\n",
      "ticker : UNF\n",
      "ticker : UNFI\n",
      "ticker : UNIT\n",
      "ticker : URBN\n",
      "ticker : USNA\n",
      "ticker : USPH\n",
      "ticker : UTL\n",
      "ticker : UVV\n",
      "ticker : VBTX\n",
      "ticker : VCEL\n",
      "ticker : VECO\n",
      "ticker : VGR\n",
      "ticker : VIAV\n",
      "ticker : VICR\n",
      "ticker : VIR\n",
      "ticker : VRE\n",
      "ticker : VREX\n",
      "ticker : VRRM\n",
      "ticker : VRTS\n",
      "ticker : VRTV\n",
      "ticker : VSAT\n",
      "ticker : VSCO\n",
      "ticker : VSTO\n",
      "ticker : VTOL\n",
      "ticker : VTLE\n",
      "ticker : VVI\n",
      "ticker : WABC\n",
      "ticker : WAFD\n",
      "ticker : WD\n",
      "ticker : WDFC\n",
      "ticker : WGO\n",
      "ticker : WIRE\n",
      "ticker : WKC\n",
      "ticker : WLY\n",
      "ticker : WNC\n",
      "ticker : ELME\n",
      "ticker : WRLD\n",
      "ticker : WSFS\n",
      "ticker : WSR\n",
      "ticker : WT\n",
      "ticker : WWW\n",
      "ticker : XHR\n",
      "ticker : XNCR\n",
      "ticker : XPEL\n",
      "ticker : XPER\n",
      "ticker : XRX\n",
      "ticker : YELP\n",
      "ticker : ZEUS\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# request this url https://en.wikipedia.org/wiki/List_of_S%26P_600_companies\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_600_companies'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# get the table by the id constituents\n",
    "table = soup.find('table', {'id': 'constituents'})\n",
    "ticker_list = []\n",
    "# iterate over the tr balise in the table\n",
    "for tr in table.find_all('tr'):\n",
    "    # get the first td balise in the tr balise\n",
    "    td = tr.findAll('td')\n",
    "    # if the td balise is not empty\n",
    "    if td is not None and len(td) > 1:\n",
    "        # get the first a balise in the td balise\n",
    "\n",
    "        a = td[0].find('a')\n",
    "        # if the a balise is not empty\n",
    "        if a is not None:\n",
    "            # get the text of the a balise\n",
    "            ticker = a.text\n",
    "            # add the ticker to the list\n",
    "            print(f\"ticker : {ticker}\")\n",
    "            ticker_list.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2_EwwaUcnVH",
    "outputId": "9209fcdc-bcaa-42e0-eba6-7058166f9624",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:17:25.811429Z",
     "start_time": "2023-11-25T20:17:25.804500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kept_stocks_with_indexes : [(0, 'AAON'), (1, 'AAP'), (2, 'AAT'), (3, 'ABCB'), (4, 'ABG'), (5, 'ABM'), (6, 'ABR'), (7, 'ACA'), (8, 'ACIW'), (9, 'ACLS'), (10, 'ADEA'), (11, 'ADTN'), (12, 'ADUS'), (13, 'AEIS'), (14, 'AEL'), (15, 'AEO'), (16, 'AGO'), (18, 'AGYS'), (19, 'AHCO'), (20, 'AHH'), (21, 'AIN'), (22, 'AIR'), (23, 'AIT'), (24, 'AKR'), (25, 'ALEX'), (26, 'ALG'), (27, 'ALGT'), (28, 'ALRM'), (29, 'AMBC'), (30, 'AMCX'), (31, 'AMEH'), (32, 'AMN'), (33, 'AMPH'), (35, 'AMSF'), (36, 'AMWD'), (37, 'ANDE'), (38, 'ANF'), (39, 'ANIP'), (40, 'AORT'), (41, 'AOSL'), (42, 'APAM'), (43, 'APLE'), (44, 'APOG'), (45, 'APPS'), (46, 'ARCB'), (47, 'ARI'), (48, 'ARLO'), (49, 'AROC'), (50, 'ARR'), (51, 'ASIX'), (53, 'ASTE'), (54, 'ATEN'), (55, 'ATGE'), (56, 'ATI'), (57, 'ATNI'), (58, 'AUB'), (59, 'AVA'), (60, 'AVAV'), (61, 'AVNS'), (62, 'AVTA'), (63, 'AWR'), (64, 'AX'), (65, 'AXL'), (66, 'AZZ'), (67, 'B'), (68, 'BANC'), (69, 'BANF'), (70, 'BANR'), (71, 'BCC'), (72, 'BCPC'), (73, 'BDN'), (74, 'BFH'), (75, 'BFS'), (76, 'BGS'), (77, 'BHE'), (78, 'BHLB'), (79, 'BJRI'), (80, 'BKE'), (81, 'BKU'), (82, 'BLFS'), (83, 'BLMN'), (84, 'BMI'), (85, 'BOH'), (86, 'BOOT'), (87, 'BRC'), (88, 'BRKL'), (89, 'BSIG'), (90, 'BXMT'), (91, 'CAKE'), (92, 'CAL'), (93, 'CALM'), (94, 'CARG'), (95, 'CARS'), (96, 'CASH'), (97, 'CATY'), (98, 'CBRL'), (99, 'CBU'), (100, 'CCOI'), (101, 'CCRN'), (102, 'CCS'), (104, 'CDMO'), (105, 'CEIX'), (106, 'CENT'), (107, 'CENTA'), (108, 'CENX'), (110, 'CEVA'), (111, 'CFFN'), (112, 'CHCO'), (113, 'CHCT'), (114, 'CHEF'), (115, 'CHS'), (116, 'CHUY'), (117, 'CLB'), (118, 'CLDT'), (119, 'CLFD'), (120, 'CLW'), (121, 'CMP'), (122, 'CNK'), (123, 'CNMD'), (124, 'CNSL'), (125, 'CNXN'), (126, 'COHU'), (127, 'COLL'), (128, 'COOP'), (129, 'CORT'), (130, 'CPE'), (131, 'CPF'), (132, 'CPK'), (133, 'CPRX'), (135, 'CRK'), (136, 'CRMT'), (137, 'CRNC'), (138, 'CRS'), (140, 'CRVL'), (141, 'CSGS'), (142, 'CSR'), (144, 'CTRE'), (145, 'CTS'), (146, 'CUBI'), (147, 'CVBF'), (148, 'CVCO'), (149, 'CVGW'), (150, 'CVI'), (151, 'CWK'), (152, 'CWT'), (153, 'CXW'), (154, 'CYH'), (155, 'CYTK'), (156, 'DAN'), (157, 'DBI'), (158, 'DCOM'), (159, 'DDD'), (160, 'DEA'), (161, 'DEI'), (162, 'DFIN'), (163, 'DGII'), (164, 'DIN'), (165, 'DIOD'), (166, 'DISH'), (167, 'DLX'), (168, 'DNOW'), (169, 'DORM'), (170, 'DRH'), (171, 'DRQ'), (173, 'DVAX'), (174, 'DXC'), (175, 'DXPE'), (176, 'DY'), (177, 'EAT'), (178, 'ECPG'), (179, 'EFC'), (180, 'EGBN'), (182, 'EIG'), (183, 'ELF'), (185, 'ENR'), (186, 'ENSG'), (187, 'ENV'), (188, 'ENVA'), (189, 'EPAC'), (190, 'EPC'), (191, 'EPRT'), (192, 'ESE'), (193, 'ETD'), (194, 'EVTC'), (195, 'EXPI'), (196, 'EXTR'), (197, 'EYE'), (198, 'EZPW'), (199, 'FBK'), (200, 'FBNC'), (201, 'FBP'), (203, 'FCF'), (204, 'FCPT'), (205, 'FDP'), (206, 'FELE'), (207, 'FFBC'), (208, 'FHB'), (209, 'FIX'), (210, 'FIZZ'), (211, 'FL'), (212, 'FLGT'), (213, 'FN'), (214, 'FORM'), (215, 'FORR'), (216, 'FSS'), (217, 'FTDR'), (219, 'FUL'), (220, 'FULT'), (221, 'FWRD'), (222, 'GBX'), (223, 'GDEN'), (224, 'GDOT'), (225, 'GEO'), (226, 'GES'), (227, 'GFF'), (228, 'GIII'), (229, 'GKOS'), (230, 'GMS'), (231, 'GNL'), (232, 'GNW'), (233, 'GOGO'), (234, 'GPI'), (235, 'GPRE'), (236, 'GRBK'), (237, 'GSHD'), (238, 'GTY'), (239, 'GVA'), (240, 'HAFC'), (241, 'HAIN'), (242, 'HASI'), (243, 'HAYN'), (245, 'HBI'), (246, 'HCC'), (247, 'HCI'), (248, 'HCSG'), (249, 'HFWA'), (250, 'HI'), (251, 'HIBB'), (252, 'HIW'), (253, 'HLIT'), (254, 'HLX'), (255, 'HMN'), (256, 'HNI'), (257, 'HOPE'), (258, 'HOUS'), (259, 'HP'), (260, 'HPP'), (263, 'HSII'), (264, 'HSTM'), (265, 'HTH'), (266, 'HTLD'), (267, 'HUBG'), (268, 'HVT'), (269, 'HWKN'), (270, 'HZO'), (271, 'IBP'), (272, 'IBTX'), (273, 'ICHR'), (274, 'IDCC'), (275, 'IIIN'), (276, 'IIPR'), (277, 'INDB'), (278, 'INN'), (279, 'INVA'), (280, 'IOSP'), (281, 'IPAR'), (282, 'IRBT'), (283, 'IRWD'), (284, 'ITGR'), (285, 'ITRI'), (286, 'IVR'), (287, 'JACK'), (288, 'JBGS'), (289, 'JBLU'), (290, 'JBSS'), (291, 'JBT'), (292, 'JJSF'), (293, 'JOE'), (294, 'JRVR'), (296, 'KALU'), (297, 'KAMN'), (298, 'KAR'), (299, 'KELYA'), (300, 'KFY'), (302, 'KLIC'), (303, 'KMT'), (304, 'KN'), (305, 'KOP'), (306, 'KREF'), (307, 'KSS'), (308, 'KTB'), (309, 'KW'), (310, 'KWR'), (311, 'LBRT'), (312, 'LCII'), (314, 'LGIH'), (315, 'LGND'), (316, 'LKFN'), (317, 'LMAT'), (318, 'LNC'), (319, 'LNN'), (320, 'LPG'), (321, 'LQDT'), (322, 'LRN'), (323, 'LTC'), (324, 'LTHM'), (325, 'LUMN'), (326, 'LXP'), (327, 'LZB'), (328, 'MAC'), (329, 'MATV'), (330, 'MATW'), (331, 'MATX'), (333, 'MC'), (334, 'MCRI'), (335, 'MCS'), (337, 'MCY'), (338, 'MD'), (339, 'MDC'), (340, 'MDRX'), (341, 'MED'), (342, 'MEI'), (343, 'MERC'), (344, 'MGPI'), (345, 'MHO'), (346, 'MLAB'), (347, 'MLKN'), (348, 'MLI'), (349, 'MMI'), (350, 'MMSI'), (351, 'MNRO'), (352, 'MODV'), (353, 'MOG-A'), (354, 'MOV'), (355, 'MRCY'), (356, 'MRTN'), (357, 'MSEX'), (358, 'MSGS'), (359, 'MTH'), (360, 'MTRN'), (361, 'MTX'), (362, 'MXL'), (363, 'MYE'), (364, 'MYGN'), (365, 'MYRG'), (368, 'NAVI'), (369, 'NBHC'), (370, 'NBR'), (371, 'NBTB'), (372, 'NEO'), (373, 'NFBK'), (374, 'NGVT'), (375, 'NMIH'), (376, 'NOG'), (377, 'NPK'), (378, 'NPO'), (379, 'NSIT'), (380, 'NTCT'), (381, 'NUS'), (382, 'NVEE'), (383, 'NWBI'), (384, 'NWL'), (385, 'NWN'), (386, 'NX'), (387, 'NXRT'), (388, 'NYMT'), (389, 'ODP'), (390, 'OFG'), (391, 'OFIX'), (393, 'OI'), (394, 'OII'), (395, 'OIS'), (396, 'OMCL'), (397, 'OMI'), (398, 'OSIS'), (399, 'OSPN'), (400, 'OSUR'), (401, 'OTTR'), (402, 'OUT'), (403, 'OXM'), (404, 'PACW'), (405, 'PAHC'), (406, 'PARR'), (408, 'PATK'), (409, 'PBH'), (410, 'PBI'), (411, 'PCRX'), (412, 'PDFS'), (413, 'PEB'), (415, 'PFBC'), (416, 'PFS'), (417, 'PGTI'), (419, 'PINC'), (420, 'PIPR'), (421, 'PLAB'), (422, 'PLAY'), (423, 'PLMR'), (424, 'PLUS'), (425, 'PLXS'), (426, 'PMT'), (427, 'POWL'), (428, 'PPBI'), (429, 'PRA'), (430, 'PRAA'), (431, 'PRDO'), (432, 'PRFT'), (433, 'PRG'), (434, 'PRGS'), (435, 'PRK'), (436, 'PRLB'), (438, 'PSMT'), (439, 'PTEN'), (440, 'PUMP'), (441, 'PZZA'), (442, 'QNST'), (443, 'RAMP'), (444, 'RC'), (446, 'RCUS'), (447, 'RDN'), (448, 'RDNT'), (449, 'RES'), (450, 'REX'), (451, 'REZI'), (452, 'RGNX'), (453, 'RGP'), (454, 'RGR'), (455, 'RILY'), (456, 'RMBS'), (457, 'RNST'), (458, 'ROCK'), (459, 'ROG'), (460, 'ROIC'), (461, 'RPT'), (462, 'RWT'), (464, 'SAFE'), (465, 'SABR'), (466, 'SAFT'), (467, 'SAH'), (468, 'SANM'), (469, 'SBCF'), (470, 'SBH'), (471, 'SBSI'), (472, 'SCHL'), (473, 'SCL'), (474, 'SCSC'), (475, 'SCVL'), (477, 'SEM'), (478, 'SFBS'), (479, 'SFNC'), (480, 'SGH'), (481, 'SHAK'), (482, 'SHEN'), (483, 'SHO'), (484, 'SHOO'), (485, 'SIG'), (486, 'SITC'), (488, 'SIX'), (489, 'SJW'), (490, 'SKT'), (491, 'SKYW'), (492, 'SLCA'), (493, 'SLG'), (494, 'SLP'), (496, 'SM'), (497, 'SMP'), (498, 'SMPL'), (499, 'SMTC'), (500, 'SNBR'), (502, 'SNEX'), (503, 'SONO'), (504, 'SPNT'), (505, 'SPSC'), (506, 'SPTN'), (507, 'SPWR'), (508, 'SPXC'), (509, 'SSP'), (510, 'SSTK'), (511, 'STAA'), (512, 'STBA'), (513, 'STC'), (514, 'STEL'), (515, 'STRA'), (516, 'SUPN'), (517, 'SVC'), (518, 'SXC'), (519, 'SXI'), (520, 'SXT'), (521, 'TALO'), (522, 'TBBK'), (523, 'TBI'), (524, 'TDS'), (525, 'TFIN'), (526, 'TGI'), (527, 'THRM'), (528, 'THRY'), (529, 'THS'), (530, 'TILE'), (531, 'TMP'), (532, 'TMST'), (533, 'TNC'), (534, 'TNDM'), (535, 'TPH'), (536, 'TR'), (537, 'TRIP'), (538, 'TRMK'), (539, 'TRN'), (540, 'TRST'), (541, 'TRUP'), (542, 'TTEC'), (543, 'TTGT'), (544, 'TTMI'), (545, 'TWI'), (546, 'TWO'), (547, 'UCBI'), (548, 'UCTT'), (549, 'UE'), (550, 'UFCS'), (551, 'UFPT'), (552, 'UHT'), (553, 'UNF'), (554, 'UNFI'), (555, 'UNIT'), (556, 'URBN'), (557, 'USNA'), (558, 'USPH'), (559, 'UTL'), (560, 'UVV'), (561, 'VBTX'), (562, 'VCEL'), (563, 'VECO'), (564, 'VGR'), (565, 'VIAV'), (566, 'VICR'), (567, 'VIR'), (568, 'VRE'), (569, 'VREX'), (570, 'VRRM'), (571, 'VRTS'), (572, 'VRTV'), (573, 'VSAT'), (575, 'VSTO'), (576, 'VTOL'), (577, 'VTLE'), (578, 'VVI'), (579, 'WABC'), (580, 'WAFD'), (581, 'WD'), (582, 'WDFC'), (583, 'WGO'), (584, 'WIRE'), (585, 'WKC'), (586, 'WLY'), (587, 'WNC'), (589, 'WRLD'), (590, 'WSFS'), (591, 'WSR'), (592, 'WT'), (593, 'WWW'), (594, 'XHR'), (595, 'XNCR'), (596, 'XPEL'), (598, 'XRX'), (599, 'YELP'), (600, 'ZEUS')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists('stocks_data.pkl'):\n",
    "    # If the file exists, load it\n",
    "    with open('stocks_data.pkl', 'rb') as f:\n",
    "        stocks_data = pickle.load(f)\n",
    "else:\n",
    "    # If the file doesn't exist, download the stocks data\n",
    "    # This is a placeholder for the code to download the stocks data\n",
    "    # Replace it with the actual code to download the data\n",
    "    stocks_data = download_stocks(ticker_list)\n",
    "\n",
    "    # Save the downloaded data into a file\n",
    "    with open('stocks_data.pkl', 'wb') as f:\n",
    "        pickle.dump(stocks_data, f)\n",
    "\n",
    "kept_stocks_with_indexes = stocks_data[1]\n",
    "normalized_values_list = stocks_data[0]\n",
    "print(f\"kept_stocks_with_indexes : {kept_stocks_with_indexes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGQJ_f9PufGo",
    "outputId": "45b82fd0-3d4e-4766-e008-015c9a73a536",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:19:23.828805Z",
     "start_time": "2023-11-25T20:19:23.798256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([32, 10, 100])\n",
      "Batch shape: torch.Size([20, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Use the previously prepared data\n",
    "sub_series_length = 100\n",
    "stock_symbols = [stock[1] for stock in kept_stocks_with_indexes]\n",
    "\n",
    "# Check that the length of each normalized series is divisible by sub_series_length\n",
    "number_of_sub_series = len(normalized_values_list[0]) // sub_series_length\n",
    "print()\n",
    "for i in range(len(stock_symbols)):\n",
    "    assert len(normalized_values_list[i]) % sub_series_length == 0\n",
    "\n",
    "# Create sub-series for each stock\n",
    "sub_series_list = [normalized_values.reshape((-1, sub_series_length)) for normalized_values in normalized_values_list]\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "stocks_np_array = np.zeros((len(stock_symbols), sub_series_list[0].shape[0], sub_series_list[0].shape[1]))\n",
    "for i in range(len(stock_symbols)):\n",
    "    stocks_np_array[i] = sub_series_list[i]\n",
    "\n",
    "# Create a PyTorch Dataset\n",
    "stock_dataset = StockDataset(stocks_np_array)\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "batch_size = 32\n",
    "shuffle = True  # To shuffle the data\n",
    "data_loader = DataLoader(stock_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# Iterate through the DataLoader to get shuffled batches\n",
    "for batch in data_loader:\n",
    "    # Process each batch\n",
    "    print(\"Batch shape:\", batch.shape)  # Adjust this according to your processing needs\n",
    "    # Your processing logic here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocks_predict shape : (564, 1000)\n",
      "stocks_np_array shape : (564, 10, 100)\n",
      "total stocks : 564\n",
      "total days : 1000\n",
      "stock_dataset : <__main__.StockDataset_predict object at 0x2a7da9160>\n",
      "sample_sequence : [-0.43067246 -0.45028347 -0.44109085 -0.39574072 -0.45671825 -0.46652366\n",
      " -0.49042441 -0.50329397 -0.48919864 -0.5176956  -0.57560899 -0.49624639\n",
      " -0.51432497 -0.50114892 -0.44844491 -0.51034154 -0.51187379 -0.48766657\n",
      " -0.51647002 -0.47724836 -0.50053613 -0.52045344 -0.59368774 -0.60778307\n",
      " -0.58786576 -0.58970431 -0.55783672 -0.59950973 -0.61360506 -0.57009331\n",
      " -0.53945148 -0.5379194  -0.57162556 -0.63628003 -0.61605623 -0.58112449\n",
      " -0.61820128 -0.57377043 -0.60318667 -0.56090087 -0.5385322  -0.53822571\n",
      " -0.6010418  -0.54098355 -0.46437862 -0.37367854 -0.38440323 -0.33016697\n",
      " -0.26827015 -0.28849395 -0.27286655 -0.32434498 -0.29186459 -0.24804653\n",
      " -0.25601339  0.02589246  0.01945767  0.14110625  0.12609164  0.11965686\n",
      "  0.19411675  0.19503603  0.1699097   0.1487668   0.18431134  0.17297385\n",
      "  0.14539616  0.14263833  0.04826112  0.09085341  0.16408771  0.1441704\n",
      "  0.20024522  0.1441704   0.10801289  0.13068804  0.18431134  0.20208378\n",
      "  0.17328033  0.176038    0.17971511  0.13375219  0.07461322  0.06511429\n",
      "  0.04611625  0.09790117  0.08319304  0.0599051   0.09177269  0.05193824\n",
      "  0.09024062  0.04335842  0.02834381 -0.06848475 -0.10433577  0.00873298\n",
      "  0.01547425  0.05224455  0.06327573  0.08686999]\n",
      "next_value : 0.12149542214401121\n",
      "sequence_index : 701\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class StockDataset_predict(Dataset):\n",
    "    def __init__(self, data, sequence_length):\n",
    "        self.data = data\n",
    "        self.sequence_length = sequence_length\n",
    "        self.total_stocks = data.shape[0]\n",
    "        print(f\"total stocks : {self.total_stocks}\")\n",
    "        self.total_days = data.shape[1]\n",
    "        print(f\"total days : {self.total_days}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total number of subsequences that can be formed\n",
    "        return (self.total_days - self.sequence_length)\n",
    "\n",
    "    def __getitem__(self, idx,stock_index=0):\n",
    "        # assert that the stock index is between 0 and total_stocks\n",
    "        assert stock_index >= 0 and stock_index < self.total_stocks\n",
    "        # assert that the idx is between 0 and total_days - sequence_length\n",
    "        assert idx >= 0 and idx < (self.total_days - self.sequence_length)\n",
    "\n",
    "        # Calculate start and end indices for the subsequence\n",
    "        start_idx = idx\n",
    "        end_idx = idx + self.sequence_length\n",
    "\n",
    "        # Extract the subsequence and the next value, the next value is the actual value that we want to predict\n",
    "        sub_sequence = self.data[stock_index][ start_idx:end_idx]\n",
    "        \"\"\"print(f\"start idx : {start_idx}\")\n",
    "        print(f\"end idx : {end_idx}\")\n",
    "        print(self.data[stock_index][end_idx:end_idx+1])\"\"\"\n",
    "        next_value = self.data[stock_index][end_idx]\n",
    "\n",
    "        # Index of the subsequence\n",
    "        sub_sequence_index = idx + 1  # Indexing starting from 1\n",
    "\n",
    "        return sub_sequence, next_value, sub_sequence_index\n",
    "\n",
    "# Example usage:\n",
    "# Assuming your data array is named 'stock_values'\n",
    "# stock_values has the shape (number_stocks, 1000, 1)\n",
    "# Adjust sequence_length according to your requirement\n",
    "stocks_predict = np.array(normalized_values_list)\n",
    "print(f\"stocks_predict shape : {stocks_predict.shape}\")\n",
    "# Convert the list to a numpy array\n",
    "sequence_length = 100\n",
    "print(f\"stocks_np_array shape : {stocks_np_array.shape}\")\n",
    "stock_dataset = StockDataset_predict(stocks_predict, sequence_length)\n",
    "print(f\"stock_dataset : {stock_dataset}\")\n",
    "# Example of accessing the dataset\n",
    "sample_sequence, next_value, sequence_index = stock_dataset.__getitem__(700,0)  # Accessing the first sequence\n",
    "print(f\"sample_sequence : {sample_sequence}\")\n",
    "print(f\"next_value : {next_value}\")\n",
    "print(f\"sequence_index : {sequence_index}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T20:19:24.303263Z",
     "start_time": "2023-11-25T20:19:24.274867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def get_training_data(data_set_stocks):\n",
    "    training_data_input = []\n",
    "    training_data_output = []\n",
    "    for stock in range(stocks_np_array.shape[0]):\n",
    "        for sliding_window in range(len(data_set_stocks)):\n",
    "            # get the sub sequence\n",
    "            sub_sequence, next_value, sequence_index = data_set_stocks.__getitem__(sliding_window,stock)\n",
    "            training_data_input.append(sub_sequence)\n",
    "            training_data_output.append(next_value)\n",
    "\n",
    "    training_data_output = np.array(training_data_output)\n",
    "    training_data_input = np.array(training_data_input)\n",
    "    print(f\"training_data_input shape : {training_data_input.shape}\")\n",
    "    print(f\"training_data_output shape : {training_data_output.shape}\")\n",
    "    return training_data_input,training_data_output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T20:19:24.655697Z",
     "start_time": "2023-11-25T20:19:24.649370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data_input shape : (507600, 100)\n",
      "training_data_output shape : (507600,)\n"
     ]
    }
   ],
   "source": [
    "training_data_input,training_data_output = get_training_data(stock_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T20:19:25.285072Z",
     "start_time": "2023-11-25T20:19:24.881405Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : torch.Size([406080, 100, 1])\n",
      "X_test shape : torch.Size([101520, 100, 1])\n",
      "y_train shape : torch.Size([406080, 1])\n",
      "y_test shape : torch.Size([101520, 1])\n"
     ]
    }
   ],
   "source": [
    "# split into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data_input, training_data_output, test_size=0.2, random_state=42)\n",
    "X_train = torch.from_numpy(X_train).float().to(device).unsqueeze(-1)\n",
    "y_train = torch.from_numpy(y_train).float().to(device).unsqueeze(-1)\n",
    "X_test = torch.from_numpy(X_test).float().to(device).unsqueeze(-1)\n",
    "y_test = torch.from_numpy(y_test).float().to(device).unsqueeze(-1)\n",
    "print(f\"X_train shape : {X_train.shape}\")\n",
    "print(f\"X_test shape : {X_test.shape}\")\n",
    "print(f\"y_train shape : {y_train.shape}\")\n",
    "print(f\"y_test shape : {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:49.507259Z",
     "start_time": "2023-11-25T20:29:49.309150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "ppp0apqNufGo",
    "outputId": "398c547e-de09-4e9d-b007-e850033c677a",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:49.594066Z",
     "start_time": "2023-11-25T20:29:49.510193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAIjCAYAAADxz9EgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAACHw0lEQVR4nOzdd3hUZfrG8XsmvRfSIZRQE7oEkI5SBQs2REEFEXQV++rC7m9X3V0Xey/YK9gFO4qA1BA6UgOhhpBCCOmkzvn9ERKNJJCESSaT+X6uay7NmXPOPMEx5J73fZ/XZBiGIQAAAACAVZhtXQAAAAAANCeELAAAAACwIkIWAAAAAFgRIQsAAAAArIiQBQAAAABWRMgCAAAAACsiZAEAAACAFRGyAAAAAMCKCFkAAAAAYEWELACATU2dOlVt27a1dRkN6pFHHpHJZFJGRoatS6kVk8mkRx55xNZlAIDdImQBgIN47733ZDKZKh/Ozs5q2bKlpk6dquTkZFuX16Rs375d11xzjdq0aSN3d3e1bNlSo0aN0ksvvWSzmr799lsNGzZMISEh8vT0VFRUlCZOnKjFixfbrCYAQPWcbV0AAKBx/fvf/1a7du1UWFiodevW6b333tPq1au1Y8cOubu727o8m1u7dq0uuugitW7dWjNmzFBYWJiSkpK0bt06vfDCC7rrrrsavaann35aDz74oIYNG6Y5c+bI09NTiYmJ+uWXX/TJJ59o7NixVn29U6dOydmZXxEAoL74CQoADuaSSy5RbGysJOnWW29VUFCQnnjiCX3zzTeaOHGijauzvccee0x+fn7asGGD/P39qzyXnp7e6PWUlpbqP//5j0aNGqWff/75jOetVZPFYlFxcbHc3d0J2wBwnpguCAAObsiQIZKk/fv3Vx4rLi7Wv/71L/Xp00d+fn7y8vLSkCFDtHz58irXHjp0SCaTSU8//bTeeOMNtW/fXm5uburbt682bNhwxmstWrRI3bp1k7u7u7p166aFCxdWW1N+fr4eeOABRUZGys3NTZ07d9bTTz8twzCqnGcymTRr1ix9/vnniomJkYeHhwYMGKDt27dLkl5//XV16NBB7u7uGj58uA4dOnTOP4/9+/era9euZwQsSQoJCTnje3/vvffOOK+mNU0ZGRmaOHGifH191aJFC91zzz0qLCw8az0ZGRnKycnRoEGDqn3+jzVJUlFRkR5++GF16NBBbm5uioyM1EMPPaSioqIzapw1a5bmz5+vrl27ys3NrXLqYXX1Jycn65ZbblFoaKjc3NzUtWtXvfPOO2fU89JLL6lr167y9PRUQECAYmNjtWDBgrN+jwDQ3DCSBQAOriJ4BAQEVB7LycnRW2+9peuvv14zZsxQbm6u3n77bY0ZM0br169Xr169qtxjwYIFys3N1W233SaTyaQnn3xSV111lQ4cOCAXFxdJ0s8//6yrr75aMTExmjt3rk6cOKFp06apVatWVe5lGIYuv/xyLV++XNOnT1evXr30008/6cEHH1RycrKee+65KuevWrVK33zzje68805J0ty5c3XppZfqoYce0quvvqo77rhDJ0+e1JNPPqlbbrlFy5YtO+ufR5s2bRQXF6cdO3aoW7du9fkjrdHEiRPVtm1bzZ07V+vWrdOLL76okydP6oMPPqjxmpCQEHl4eOjbb7/VXXfdpcDAwBrPtVgsuvzyy7V69WrNnDlT0dHR2r59u5577jnt3btXixYtqnL+smXL9Nlnn2nWrFkKCgqqsQFJWlqaLrzwwspgFhwcrB9//FHTp09XTk6O7r33XknSm2++qbvvvlvXXHNNZYD87bffFB8frxtuuKGuf1wAYL8MAIBDePfddw1Jxi+//GIcP37cSEpKMr744gsjODjYcHNzM5KSkirPLS0tNYqKiqpcf/LkSSM0NNS45ZZbKo8dPHjQkGS0aNHCyMzMrDz+9ddfG5KMb7/9tvJYr169jPDwcCMrK6vy2M8//2xIMtq0aVN5bNGiRYYk47///W+V17/mmmsMk8lkJCYmVh6TZLi5uRkHDx6sPPb6668bkoywsDAjJyen8vicOXMMSVXOrc7PP/9sODk5GU5OTsaAAQOMhx56yPjpp5+M4uLiKudVfO/vvvvuGfeQZDz88MOVXz/88MOGJOPyyy+vct4dd9xhSDK2bdt21pr+9a9/GZIMLy8v45JLLjEee+wxY9OmTWec9+GHHxpms9lYtWpVlePz5s0zJBlr1qypUqPZbDZ27tx5zvqnT59uhIeHGxkZGVXOmzRpkuHn52cUFBQYhmEYV1xxhdG1a9ezfi8A4AiYLggADmbkyJEKDg5WZGSkrrnmGnl5eembb76pMqLk5OQkV1dXSeWjI5mZmSotLVVsbKw2b958xj2vu+66KiNhFVMQDxw4IElKSUnR1q1bdfPNN8vPz6/yvFGjRikmJqbKvX744Qc5OTnp7rvvrnL8gQcekGEY+vHHH6scHzFiRJURmP79+0uSrr76avn4+JxxvKKmmowaNUpxcXG6/PLLtW3bNj355JMaM2aMWrZsqW+++eas155LxWhbhYomGj/88MNZr3v00Ue1YMEC9e7dWz/99JP+8Y9/qE+fPrrgggu0e/fuyvM+//xzRUdHq0uXLsrIyKh8XHzxxZJ0xnTPYcOGnfHn/2eGYejLL7/UZZddJsMwqtx3zJgxys7OrnxP+Pv76+jRo9VOFQUAR0LIAgAH88orr2jJkiX64osvNG7cOGVkZMjNze2M895//3316NFD7u7uatGihYKDg/X9998rOzv7jHNbt25d5euKwHXy5ElJ0uHDhyVJHTt2POPazp07V/n68OHDioiIqBKQJCk6OrrKvWp67YoQFxkZWe3xiprOpm/fvvrqq6908uRJrV+/XnPmzFFubq6uueYa7dq165zX1+TP33/79u1lNptrtVbs+uuv16pVq3Ty5En9/PPPuuGGG7RlyxZddtllleu69u3bp507dyo4OLjKo1OnTpLObJLRrl27c77u8ePHlZWVpTfeeOOM+06bNq3Kff/2t7/J29tb/fr1U8eOHXXnnXdqzZo153wNAGhuWJMFAA6mX79+ld0FJ0yYoMGDB+uGG25QQkKCvL29JUkfffSRpk6dqgkTJujBBx9USEiInJycNHfu3CoNMio4OTlV+1rGnxpVNISaXtsaNbm6uqpv377q27evOnXqpGnTpunzzz/Xww8/LJPJVO01ZWVltb5/Tfc4G19fX40aNUqjRo2Si4uL3n//fcXHx2vYsGGyWCzq3r27nn322Wqv/XPw9PDwOOfrWSwWSdKUKVN08803V3tOjx49JJUH4YSEBH333XdavHixvvzyS7366qv617/+pUcffbQu3yYA2DVCFgA4sIrgdNFFF+nll1/W7NmzJUlffPGFoqKi9NVXX1UJAg8//HC9XqdNmzaSykda/iwhIeGMc3/55Rfl5uZWGc3as2dPlXs1topgmpKSIun30bqsrKwq5/15pO2P9u3bV2X0KDExURaLpcaGE7Wp6f3336+sqX379tq2bZtGjBhRrwBXneDgYPn4+KisrEwjR4485/leXl667rrrdN1116m4uFhXXXWVHnvsMc2ZM4fW8AAcBtMFAcDBDR8+XP369dPzzz9fOe2sYhToj6M+8fHxiouLq9drhIeHq1evXnr//ferTDdcsmTJGdPvxo0bp7KyMr388stVjj/33HMymUy65JJL6lVDbS1fvrza0a6KdVMV0xt9fX0VFBSklStXVjnv1VdfrfHer7zySpWvX3rpJUk66/dUUFBQ4597xfq0ipomTpyo5ORkvfnmm2ece+rUKeXn59f4OjVxcnLS1VdfrS+//FI7duw44/njx49X/vuJEyeqPOfq6qqYmBgZhqGSkpI6vzYA2CtGsgAAevDBB3Xttdfqvffe0+23365LL71UX331la688kqNHz9eBw8e1Lx58xQTE6O8vLx6vcbcuXM1fvx4DR48WLfccosyMzMr91T64z0vu+wyXXTRRfrHP/6hQ4cOqWfPnvr555/19ddf695771X79u2t9W1X66677lJBQYGuvPJKdenSRcXFxVq7dq0+/fRTtW3btnIdklS+mfPjjz+uW2+9VbGxsVq5cqX27t1b470PHjyoyy+/XGPHjlVcXJw++ugj3XDDDerZs2eN1xQUFGjgwIG68MILNXbsWEVGRiorK0uLFi3SqlWrNGHCBPXu3VuSdOONN+qzzz7T7bffruXLl2vQoEEqKyvTnj179Nlnn+mnn36qHJGri8cff1zLly9X//79NWPGDMXExCgzM1ObN2/WL7/8oszMTEnS6NGjFRYWpkGDBik0NFS7d+/Wyy+/rPHjx5+xxg4AmjXbNTYEADSmihbuGzZsOOO5srIyo3379kb79u2N0tJSw2KxGP/73/+MNm3aGG5ubkbv3r2N7777zrj55purtFuvaGP+1FNPnXFP/akNuGEYxpdffmlER0cbbm5uRkxMjPHVV1+dcU/DMIzc3FzjvvvuMyIiIgwXFxejY8eOxlNPPWVYLJYzXuPOO++scqymmpYvX25IMj7//POz/jn9+OOPxi233GJ06dLF8Pb2NlxdXY0OHToYd911l5GWllbl3IKCAmP69OmGn5+f4ePjY0ycONFIT0+vsYX7rl27jGuuucbw8fExAgICjFmzZhmnTp06az0lJSXGm2++aUyYMKHyv4enp6fRu3dv46mnnjqj1X5xcbHxxBNPGF27djXc3NyMgIAAo0+fPsajjz5qZGdnn/XP7o/P/fm/XVpamnHnnXcakZGRhouLixEWFmaMGDHCeOONNyrPef31142hQ4caLVq0MNzc3Iz27dsbDz74YJXXBQBHYDKMRliVDAAAAAAOgjVZAAAAAGBFhCwAAAAAsCJCFgAAAABYESELAAAAAKyIkAUAAAAAVkTIAgAAAAArYjPic7BYLDp27Jh8fHxkMplsXQ4AAAAAGzEMQ7m5uYqIiJDZXPN4FSHrHI4dO6bIyEhblwEAAACgiUhKSlKrVq1qfJ6QdQ4+Pj6Syv8gfX19bVwNAAAAAFvJyclRZGRkZUaoCSHrHCqmCPr6+hKyAAAAAJxzGRGNLwAAAADAiuwuZL3yyitq27at3N3d1b9/f61fv/6s53/++efq0qWL3N3d1b17d/3www+NVCkAAAAAR2RXIevTTz/V/fffr4cfflibN29Wz549NWbMGKWnp1d7/tq1a3X99ddr+vTp2rJliyZMmKAJEyZox44djVw5AAAAAEdhMgzDsHURtdW/f3/17dtXL7/8sqTy9uqRkZG66667NHv27DPOv+6665Sfn6/vvvuu8tiFF16oXr16ad68ebV6zZycHPn5+Sk7O5s1WQAAAIADq202sJuRrOLiYm3atEkjR46sPGY2mzVy5EjFxcVVe01cXFyV8yVpzJgxNZ4vSUVFRcrJyanyAAAAAIDaspuQlZGRobKyMoWGhlY5HhoaqtTU1GqvSU1NrdP5kjR37lz5+flVPtgjCwAAAEBd2E3Iaixz5sxRdnZ25SMpKcnWJQEAAACwI3azT1ZQUJCcnJyUlpZW5XhaWprCwsKqvSYsLKxO50uSm5ub3Nzczr9gAAAAAA7JbkayXF1d1adPHy1durTymMVi0dKlSzVgwIBqrxkwYECV8yVpyZIlNZ4PAAAAAOfLbkayJOn+++/XzTffrNjYWPXr10/PP/+88vPzNW3aNEnSTTfdpJYtW2ru3LmSpHvuuUfDhg3TM888o/Hjx+uTTz7Rxo0b9cYbb9jy2wAAAADQjNlVyLruuut0/Phx/etf/1Jqaqp69eqlxYsXVza3OHLkiMzm3wfnBg4cqAULFuj//u//9Pe//10dO3bUokWL1K1bN1t9CwAAAACaObvaJ8sW2CcLAAAAgNQM98kCAAAAAHtAyAIAAAAAKyJkAQAAAIAVEbIAAAAAwIoIWQAAAADOW15RqXan5Ni6jCaBkAUAAADgvD32/S5d8sIq/ZqQbutSbI6QBQAAAOC8/XY0W5K0ZFeajSuxPUIWAAAAgPOWllMkSYo/mGnjSmyPkAUAAADgvJSUWXQivzxkJabnKSOvyMYV2RYhCwAAAMB5OZ5bJMP4/ev1Dj6aRcgCAAAAcF7ScgqrfB1/4ISNKmkaCFkAAAAAzkvFeqwKjr4ui5AFAAAA4Lyk55aPZPVtGyBJ2pOaq5P5xbYsyaYIWQAAAADOS2p2eciKCfdVhxBvSdL6Q447mkXIAgAAAHBeKqYLhvi6q3+7QElS/AFCFgAAAADUS8V0wVBfd/WPaiFJij/ouM0vnG1dAAAAAAD7VtFdMMzXXZ1Cy6cL7krJUfapEvl5uNiyNJtgJAsAAADAealYkxXq66YQX3e1C/KSYUgbHXRdFiELAAAAQL2dKi5TTmGppPI1WZJ+X5floK3cCVkAAAAA6q1iPZaHi5N83ctXI/WPKg9Z6xx0U2JCFgAAAIB6q+gsGOrrJpPJJEnq3668+cWO5GzlFpbYrDZbIWQBAAAAqLfU000vKqYKSlKEv4ciAz1kMaSNh0/aqjSbIWQBAAAAqLf0nN/bt/9RxWiWI+6XRcgCAAAAUG+/t293q3L89+YXjrcui5AFAAAAoN5+X5NVdSTrwtObEm8/mq2C4tJGr8uWCFkAAAAA6q26NVmS1CrAQxF+7iq1GNrkYOuyCFkAAAAA6q1yTZZP1emCJpNJ/aPOvS4rI69Ib648UHmf5oCQBQAAAKBeDMOonC4Y5ud+xvPnWpeVnlOoia/H6bEfdmv6+xtVZjEarthGRMgCAAAAUC+5RaU6VVImSQrxqSZknR7J2paUrcLT51VIzy3U9W+u04Hj+ZKk7cnZem/toYYtuJEQsgAAAADUS1p2+RQ/X3dnebg6nfF82xaeCvV1U3GZRZuP/L4uKz23UNe/sU77j+crws9dsy7qIEl65ucEJWedapziGxAhCwAAAEC91NRZsILJZDpjv6zjuUW64c34yoD1ycwBun9UJ/VtG6CC4jL9c9EOGYZ9TxskZAEAAACol8o9sqpZj1Whf9Tv67KO5xbp+jfXKTE9T+F+7vp45oVq3cJTZrNJc6/qLhcnk5btSdcP21Mbpf6GQsgCAAAAUC9puafbt1ezHqtCxUjW5iNZuuEPAeuTmReqTQuvyvM6hPjoL8PLpw0+8u1OZZ8qacDKGxYhCwAAAEC9VKzJCvV1q/Gc9sFeCvJ2U3GpRfvS8xTm666PZ1QNWBXuGN5eUUFeOp5bpCcW72mwuhsaIQsAAABAvZxrTZZUsV9W+ZTBMN/yEay2QWcGLElyd3HS/67qLklaEH9EGw7VvL9WU0bIAgAAAFAvFdMFzxayJOm+kR01dWBbfXpbzQGrwoVRLXRdbKQkac5X21VUWnbW85siQhYAAACAekmvHMmqebqgVL7e6pHLu1Y7RbA6c8Z1UZC3qxLT8/T6igPnXWdjI2QBAAAAqDOLxajsLniukay68vd01T8vjZEkvbwsUfuP51n1/g2NkAUAAACgzjILilVqMWQyScE+Zx/Jqo/Le0ZoWKdgFZdZ9PevttvV3lmELAAAAAB1VjGK1cLLTS5O1o8VJpNJ/53QTYFerrqoS4gs9pOx5GzrAgAAAADYn9quxzofkYGeWvO3i+Xh6tRgr9EQGMkCAAAAUGepDbQe68/sLWBJhCwAAAAA9fB704uGG8myV4QsAAAAAHVWm42IHRUhCwAAAECdpTfSdEF7RMgCAAAAUGepTBesESELAAAAQJ1VTBcM8WEk688IWQAAAADqpKTMohP55SErzI+Q9Wd2E7IyMzM1efJk+fr6yt/fX9OnT1deXt5Zr3njjTc0fPhw+fr6ymQyKSsrq3GKBQAAAJqxjLwiGYbkbDYp0NPV1uU0OXYTsiZPnqydO3dqyZIl+u6777Ry5UrNnDnzrNcUFBRo7Nix+vvf/95IVQIAAADNX2p2+XqsEB83mc0mG1fT9DjbuoDa2L17txYvXqwNGzYoNjZWkvTSSy9p3LhxevrppxUREVHtdffee68k6ddff22kSgEAAIDmr3I9Fp0Fq2UXI1lxcXHy9/evDFiSNHLkSJnNZsXHx1v1tYqKipSTk1PlAQAAAOB36bnlI1lhhKxq2UXISk1NVUhISJVjzs7OCgwMVGpqqlVfa+7cufLz86t8REZGWvX+AAAAgL1Lo337Wdk0ZM2ePVsmk+msjz179jRqTXPmzFF2dnblIykpqVFfHwAAAGjqUrOZLng2Nl2T9cADD2jq1KlnPScqKkphYWFKT0+vcry0tFSZmZkKCwuzak1ubm5ycyORAwAAADWpmC4YSsiqlk1DVnBwsIKDg8953oABA5SVlaVNmzapT58+kqRly5bJYrGof//+DV0mAAAAgD+omC7Imqzq2cWarOjoaI0dO1YzZszQ+vXrtWbNGs2aNUuTJk2q7CyYnJysLl26aP369ZXXpaamauvWrUpMTJQkbd++XVu3blVmZqZNvg8AAACgOajoLsiarOrZRciSpPnz56tLly4aMWKExo0bp8GDB+uNN96ofL6kpEQJCQkqKCioPDZv3jz17t1bM2bMkCQNHTpUvXv31jfffNPo9QMAAADNQWFJmbJPlUhiTVZNTIZhGLYuoinLycmRn5+fsrOz5evra+tyAAAAAJs6fCJfw576Ve4uZu3+91iZTI6zGXFts4HdjGQBAAAAsL2KqYJhvu4OFbDqgpAFAAAAoNYqml4wVbBmhCwAAAAAtfb7RsSErJoQsgAAAADUWmXI8qGzYE0IWQAAAABqrXJNlh8jWTUhZAEAAACoNdZknRshCwAAAECtMV3w3AhZAAAAAGrFMIzK6YI0vqgZIQsAAABAreQWlepUSZkkQtbZELIAAAAA1Er66amCvu7O8nB1snE1TRchCwAAAECtpGYzVbA2CFkAAAAAaoWNiGuHkAUAAACgVtJyCVm1QcgCAAAAUCvplZ0Fad9+NoQsAAAAALWSms1IVm0QsgAAAADUCtMFa4eQBQAAAOCcThWXadexHElSuyAvG1fTtBGyAAAAAJzT6sQMFZVa1NLfQ51CvW1dTpNGyAIAAABwTr/sSpMkjYoJlclksnE1TRshCwAAAMBZWSyGlu4pD1kjo0NtXE3TR8gCAAAAcFZbj2YpI69YPm7O6tcu0NblNHmELAAAAABnVTFVcFjnYLk6EyHOhT8hAAAAAGf1y+7f12Ph3AhZAAAAAGp0+ES+9qblycls0vBOIbYuxy4QsgAAAADU6Jfd6ZKkfm0D5efpYuNq7AMhCwAAAECNKtZjjWSqYK0RsgAAAABUK6ugWOsPZUqSRtG6vdYIWQAAAEAzk1tYot0pOcrMLz6v+/yacFxlFkOdQ33UuoWnlapr/pxtXQAAAACA+tl5LFs7k3N0ODNfRzJP6UhmgZIyCyrDlZPZpKEdgzShd0uNigmVp2vdfv1fsrtiqiANL+qCkAUAAADYoW1JWbrilTU1Pu/r7qycwlItTziu5QnH5enqpDFdwzShd0sNat9Czk5nn9RWXGrRioTjkqSRTBWsE0IWAAAAYIfWHyxfK9XS30MXdQlW60BPtQ70Kv9nC095uzlr//E8fb0lWYu2HtORzAIt3JKshVuSFeTtqmmD2umO4e1lMpmqvX/8wRPKKypVkLeberbyb8TvzP4RsgAAAAA7tDs1R5J0Xd9I3T2iY7XntA/21v2jO+u+UZ20+UiWvt6arO9+S1FGXrGe+ilBZRajxmsruwpGh8hsrj6IoXo0vgAAAADs0J6UXElSlzCfc55rMpnUp02A/n1FN8X/fYT+MS5akvTskr36YtPRM843DKNyfyymCtYdIQsAAACwMyVlFiWm50mSosN963Sti5NZM4ZG6fZh7SVJs7/8Tav2Ha9yzu6UXCVnnZK7i1mDOgRZp2gHQsgCAAAA7MyB4/kqLrPI281ZrQI86nWPh8Z01uU9I1RqMfSXjzZr17Gcyud+Od1VcHCHYHm4OlmlZkdCyAIAAADszJ7T67G6hPnU2LjiXMxmk566tocujApUXlGppr23XseyTkn6PWSNonV7vRCyAAAAADuzK6U8ZNV1quCfuTk76fUpseoY4q20nCJNe3eD9qXl6rej2TKZpIu7sB6rPghZAAAAgJ2pbHoRfu6mF+fi5+mid6f1VbCPmxLScnXt63GSpF6R/gr2cTvv+zsiQhYAAABgZ36fLnh+I1kVWgV46t2pfeXl6qSsghJJdBU8H4QsAAAAwI5k5hcrLadIktS5Fu3ba6tbSz+9OqWPnE7viTU6hpBVX2xGDAAAANiRPafXY7Vp4SlvN+v+Oj+sU7A+nnGhsgqK1THUegHO0RCyAAAAADuyO7X2mxDXR792gQ1yX0fCdEEAAADAjlSMZFlrPRasj5AFAAAA2JE9p0eyoq3QWRANg5AFAAAA2InSMosS0ipCFiNZTRUhCwAAALATh07kq7jUIk9XJ0UGeNq6HNSAkAUAAADYid2nNyHuHOYj8+lW62h6CFkAAACAndhN0wu7QMgCAAAA7ERF04sYml40aXYTsjIzMzV58mT5+vrK399f06dPV15e3lnPv+uuu9S5c2d5eHiodevWuvvuu5Wdnd2IVQMAAMARGIah7347prk/7FZ6TmGDvU5l+3aaXjRpdrMZ8eTJk5WSkqIlS5aopKRE06ZN08yZM7VgwYJqzz927JiOHTump59+WjExMTp8+LBuv/12HTt2TF988UUjVw8AAIDmakdyth75Zqc2Hj4pSfpkQ5IevbyrrugVIZPJeuumsgtKdCy7PMB1bqCNiGEdJsMwDFsXcS67d+9WTEyMNmzYoNjYWEnS4sWLNW7cOB09elQRERG1us/nn3+uKVOmKD8/X87O1efLoqIiFRUVVX6dk5OjyMhIZWdny9eXTwwAAABQLiOvSE//lKBPNybJMCR3F7NaBXgqMb18ttWomFA9dmU3hfi4W+X11h04oUlvrFNLfw+tmX2xVe6JusnJyZGfn985s4FdTBeMi4uTv79/ZcCSpJEjR8psNis+Pr7W96n4w6gpYEnS3Llz5efnV/mIjIw8r9oBAABgX77emqz/frdL8+MPa92BEzqeW6Q/jksUl1r01qoDuuipX/XJhvKAdUWvCC17YLh+vGeIHhjVSS5OJi3ZlabRz63U11uTZY1xjYqpguyP1fTZxXTB1NRUhYSEVDnm7OyswMBApaam1uoeGRkZ+s9//qOZM2ee9bw5c+bo/vvvr/y6YiQLAAAAzV9qdqHu+3SrLH/KRL7uzmof4q32wd7afOSkDhzPlyR1a+mrRy7rqti2gZXn3jWio0bGhOqBz7ZpV0qO7vlkq37YnqL/TuiuYB+3etdW0fQimqYXTZ5NR7Jmz54tk8l01seePXvO+3VycnI0fvx4xcTE6JFHHjnruW5ubvL19a3yAAAAgGP4emuyLIYUGeihizoHq3Wgp0wmKaewVFuOZOmLTUd14Hi+grxd9cTV3fX1nYOrBKwK0eG++nrWIN03spOczSb9tDNNo59boR3J9W/Ctvt0yKJ9e9Nn05GsBx54QFOnTj3rOVFRUQoLC1N6enqV46WlpcrMzFRYWNhZr8/NzdXYsWPl4+OjhQsXysXF5XzLBgAAQDO1cEuyJOn2Ye01uX8bSVJhSZkOncjX/vR8Jabnyd3FrOv7t5av+9l/r3RxMuuekR01MiZED3y2TXtSc/XgF7/pm1mD5OJUt7GOMouhhNSKzoKMZDV1Ng1ZwcHBCg4OPud5AwYMUFZWljZt2qQ+ffpIkpYtWyaLxaL+/fvXeF1OTo7GjBkjNzc3ffPNN3J3t86iQwAAADQ/u1NytCc1V65OZl3a/ffGau4uTuoS5lvvEaSuEX6af2t/jXh2hXan5Oid1Qd127D2dbrH4RP5KiyxyN3FrLYtvOpVBxqPXTS+iI6O1tixYzVjxgytX79ea9as0axZszRp0qTKzoLJycnq0qWL1q9fL6k8YI0ePVr5+fl6++23lZOTo9TUVKWmpqqsrMyW3w4AAACaoEWnR7Eu7hIiP0/rzn5q4e2mf4yLliQ998teHTlRUKfrK9ZjdQ71kZPZem3h0TDsImRJ0vz589WlSxeNGDFC48aN0+DBg/XGG29UPl9SUqKEhAQVFJS/YTdv3qz4+Hht375dHTp0UHh4eOUjKSnJVt8GAAAAmqAyi6FFW8tD1oTeLRvkNa7p00oDolqosMSifyzaXqeOg7srNiFmPZZdsIvugpIUGBhY48bDktS2bdsqb9Thw4dbpVUmAAAAmr91B04oLadIfh4uuqjLuZez1IfJZNL/ruquMc+v1Kp9Gfpm2zFd0at2gW53yummF6zHsgt2M5IFAAAANJSvNpePYo3vES43Z6cGe512QV66++IOkqR/f7tLWQXFtbpuTyp7ZNkTQhYAAAAc2qniMi3ekSJJuqqBpgr+0cyh7dUp1Fsn8ov1vx92n/P8nMISHT15SpLUJYyRLHtAyAIAAIBD+3lXqvKLyxQZ6KE+bQIa/PVcnc2ae1V3SdJnG49q7f6Ms56fcLrpRbifu/w9XRu8Ppw/QhYAAAAcWkVXwSt7tZTJ1Did+/q0CdTk/q0lSf9YuEOFJTV3v95T2fSCUSx7QcgCAACAwzqeW6SV+8pHkhqqq2BNHhrbRSE+bjqYka9XlyfWeN7u0yNZrMeyH4QsAAAAOKzvfjumMouhnpH+igr2btTX9vNw0aOXd5UkvbZivxbvSFVpmeWM8ypHsghZdoOQBQAAAIe1sHKqYIRNXn9stzCNjA5RSZmh2z/apIGPL9PcH3crMT1PkmSxGJUbEUczXdBu2M0+WQAAAIA1Jabn6bej2XI2m3RZT9uELJPJpGcm9tILv+zTwi1HlZ5bpNdXHNDrKw6od2t/Xdw5RAXFZXJ1NqtdkJdNakTdEbIAAADgkCoaXgzrFKwW3m42q8PPw0X/uixGsy/pomV70vT5xqP6de9xbTmSpS1HsiRJnUK95ezEJDR7QcgCAACAw7FYDC3aWh6yGrvhRU1cnc0a2y1cY7uFKz2nUF9tSdbnG5O0/3i+Lu4cYuvyUAeELAAAADicjYdP6ujJU/J2c9aomFBbl3OGEF933T6svW4bGqWMvGIFerE/lj0hZAEAAMDhVDS8uKRbmNxdnGxcTc1MJpOCfWw3lRH1w8ROAAAAOJTCkjJ9/9sxSdKVFzSNqYJoXghZAAAAcCg/7UxVTmGpIvzcdWG7FrYuB80QIQsAAAAOZUH8EUnSdX1by2w22bgaNEeELAAAADiM/cfzFH8wU2aTNLFvK1uXg2aKkAUAAACH8fHpUayLu4Qq3M/DxtWguSJkAQAAwCEUlpTpy81HJUk39I+0cTVozghZAAAAcAg/7UzVyYISRfi5a1gnNvdFwyFkAQAAwCH8seGFEw0v0IAIWQAAAGj2EtNpeIHGQ8gCAABAs/fJehpeoPEQsgAAANCsFZaU6QsaXqAREbIAAADQrP20M1VZNLxAIyJkAQAAoFmbT8MLNDJCFgAAAJqtxPQ8rafhBRoZIQsAAADN1seVDS9CaHiBRkPIAgAAQLNUWFKmLysbXrS2cTVwJIQsAAAANEs0vICtELIAAADQLNHwArZCyAIAAECzk5ieS8ML2AwhCwAAAM3Oe2sPSZJGRIfS8AKNjpAFAACAZiX7VIm+3JQsSZo2sK1ti4FDImQBAACgWfl8Y5JOlZSpc6iPBrRvYety4IAIWQAAAGg2yiyG3o87JEmaOqitTCYaXqDxEbIAAADQbCzdnaakzFPy93TRhF4tbV0OHBQhCwAAAM1GRcOLSX1by8PVybbFwGERsgAAANAsJKTmau3+EzKbpBsHtLF1OXBg9QpZq1at0pQpUzRgwAAlJ5d3bvnwww+1evVqqxYHAAAA1NZ7aw9KksZ0DVNLf9q2w3bqHLK+/PJLjRkzRh4eHtqyZYuKiookSdnZ2frf//5n9QIBAACAczmZX6yFW063bR/UzsbVwNHVOWT997//1bx58/Tmm2/KxcWl8vigQYO0efNmqxYHAAAAx5aUWaB/f7tLW46cPOt5n25MUmGJRTHhvurbNqCRqgOqV+eQlZCQoKFDh55x3M/PT1lZWdaoCQAAANDBjHxdOy9O76w5qOteX6dFp0eq/qy0zKIPTje8oG07moI6h6ywsDAlJiaecXz16tWKioqySlEAAABwbInpebru9Til5hTK09VJxWUW3fvpVj27ZK8Mw6hy7pJdaTqWXahAL1dd3jPCRhUDv6tzyJoxY4buuecexcfHy2Qy6dixY5o/f77++te/6i9/+UtD1AgAAAAHsi8tV5PeWKf03CJ1DvXRrw8O1+3D2kuSXly6T3d/slWFJWWV5797ehTrhn6t5e5C23bYnnNdL5g9e7YsFotGjBihgoICDR06VG5ubvrrX/+qu+66qyFqBAAAgIPYk5qjyW/G60R+saLDfTX/1v4K9HLV7Eu6KCrIS39fuF3fbjumoycL9MaNsUrPLdT6g5lyNps05ULatqNpMBl/Hm+tpeLiYiUmJiovL08xMTHy9va2dm1NQk5Ojvz8/JSdnS1fX19blwMAANBs7TyWrSlvxetkQYm6tfTVR9P7y9/Ttco5cftP6PaPNin7VIla+nuofYi3Vu49rst6Ruil63vbqHI4itpmgzqPZFVwdXVVTExMfS8HAAAAKm0/mq0pb8cr+1SJerby0we39Jefp8sZ5w1o30IL7xioW97boEMnCpScdUqSNHVg20auGKhZnUPWRRdddNaOLcuWLTuvggAAAOBYdh7L1g1vrVNuYal6t/bX+7f0k6/7mQGrQlSwtxbeMUi3f7RJ8Qcz1SvSXxe09m+8goFzqHPji169eqlnz56Vj5iYGBUXF2vz5s3q3r17Q9QoScrMzNTkyZPl6+srf39/TZ8+XXl5eWe95rbbblP79u3l4eGh4OBgXXHFFdqzZ0+D1QgAAIC6MQxD/7doh3ILSxXbJkAfnCNgVQjwctWH0/vr1ckX6K2bY2nbjialziNZzz33XLXHH3nkkXOGnvMxefJkpaSkaMmSJSopKdG0adM0c+ZMLViwoMZr+vTpo8mTJ6t169bKzMzUI488otGjR+vgwYNycqLzDAAAgK39mnBcW45kyd3FrFenXCCfWgSsCq7OZo3rHt6A1QH1U+/GF3+WmJiofv36KTMz0xq3q2L37t2KiYnRhg0bFBsbK0lavHixxo0bp6NHjyoionb7Ifz222/q2bOnEhMT1b59+1pdQ+MLAACAhmEYhi5/eY22J2drxpB2+sd41vujaattNqjzdMGaxMXFyd3d3Vq3O+Pe/v7+lQFLkkaOHCmz2az4+Pha3SM/P1/vvvuu2rVrp8jIyBrPKyoqUk5OTpUHAAAArO+X3enanpwtT1enyn2wgOagztMFr7rqqipfG4ahlJQUbdy4Uf/85z+tVtgfpaamKiQkpMoxZ2dnBQYGKjU19azXvvrqq3rooYeUn5+vzp07a8mSJXJ1da3x/Llz5+rRRx+1St0AAAConsVi6NkleyVJNw9sqxbebjauCLCeOo9k+fn5VXkEBgZq+PDh+uGHH/Twww/X6V6zZ8+WyWQ66+N8G1VMnjxZW7Zs0YoVK9SpUydNnDhRhYWFNZ4/Z84cZWdnVz6SkpLO6/UBAABwpp92pmp3So683Zw1c0iUrcsBrKrOI1nvvvuu1V78gQce0NSpU896TlRUlMLCwpSenl7leGlpqTIzMxUWFnbW6yvCYMeOHXXhhRcqICBACxcu1PXXX1/t+W5ubnJz45MUAACAhlJmMfTcL+WjWLcMaqsAr5pnGQH2qN6bEVtDcHCwgoODz3negAEDlJWVpU2bNqlPnz6Syvfjslgs6t+/f61fzzAMGYahoqKietcMAACA8/P99hTtTcuTj7uzpg9mFAvNT61CVkBAQK33HmiI7oLR0dEaO3asZsyYoXnz5qmkpESzZs3SpEmTKjsLJicna8SIEfrggw/Ur18/HThwQJ9++qlGjx6t4OBgHT16VI8//rg8PDw0btw4q9cIAACAcyuzGHr+9CjWjCFR8vOsfct2wF7UKmQ9//zzDVzGuc2fP1+zZs3SiBEjZDabdfXVV+vFF1+sfL6kpEQJCQkqKCiQJLm7u2vVqlV6/vnndfLkSYWGhmro0KFau3btGU00AAAA0Di+3pqsA8fz5e/pommD2tq6HKBBWG2frOaKfbIAAACso7TMohHPrtDhEwV6aGxn3TG8g61LAuqkttngvNZkFRYWqri4uMoxgggAAACq89XmZB0+UaAWXq66eUBbW5cDNJg6t3DPz8/XrFmzFBISIi8vLwUEBFR5AAAAAH9WXGrRi8v2SZJuH9ZeXm427b8GNKg6h6yHHnpIy5Yt02uvvSY3Nze99dZbevTRRxUREaEPPvigIWoEAACAnfti01EdPXlKQd5umnJhG1uXAzSoOn+E8O233+qDDz7Q8OHDNW3aNA0ZMkQdOnRQmzZtNH/+fE2ePLkh6gQAAIAd+2F7iiRpxpB28nB1snE1QMOq80hWZmamoqLK9zPw9fWtbNk+ePBgrVy50rrVAQAAoFk4dCJfktSnDctL0PzVOWRFRUXp4MGDkqQuXbros88+k1Q+wuXv72/V4gAAAGD/ikrLdCzrlCSpTQsvG1cDNLw6h6xp06Zp27ZtkqTZs2frlVdekbu7u+677z49+OCDVi8QAAAA9u3oyVOyGJKXq5OCvF1tXQ7Q4Gq9Juuvf/2rbr31Vt13332Vx0aOHKk9e/Zo06ZN6tChg3r06NEgRQIAAMB+HT49VbBNCy+ZTCYbVwM0vFqPZH399dfq2rWrBg4cqHfeeUf5+af/Z2nTRldddRUBCwAAANU6lFEgSWob5GnjSoDGUeuQtW/fPi1fvlydOnXSPffco7CwMN1yyy1au3ZtQ9YHAAAAO/fHkSzAEdRpTdbQoUP13nvvKTU1VS+88IL27dunwYMHKzo6Wk8//bTS0tIaqk4AAADYqUMnTo9ktWAkC46hzo0vJMnLy0u33HKLVq1apb179+qqq67S3Llz1bp1a2vXBwAAADtXMZLVOpCRLDiGeoWsCvn5+Vq1apVWrFihkydPVu6fBQAAAEhSSZlFR0+Wt29nTRYcRb1C1urVq3XLLbcoPDxcd999tzp16qRVq1Zp9+7d1q4PAAAAduxY1imVWgy5OZsV6uNu63KARlHrFu4pKSl6//339d5772nv3r268MIL9eyzz2rSpEny9vZuyBoBAABgpyrWY7Vp4SmzmfbtcAy1DlmRkZFq0aKFbrzxRk2fPl3R0dENWRcAAACaAToLwhHVOmR99tlnuvzyy+XsXOtLAAAA4OAq98iisyAcSK0T01VXXdWQdQAAAKAZYiQLjui8ugsCAAAAZ3PodMhqS8iCAyFkAQAAoEGUWQwlZZa3b2/DdEE4EEIWAAAAGkRK9ikVl1nk4mRShL+HrcsBGg0hCwAAAA3i8On27ZGBnnKifTscSK0aX9Sl6cVXX31V72IAAADQfLAeC46qViNZfn5+lQ9fX18tXbpUGzdurHx+06ZNWrp0qfz8/BqsUAAAANiXw3/YiBhwJLUayXr33Xcr//1vf/ubJk6cqHnz5snJyUmSVFZWpjvuuEO+vr4NUyUAAADszqEMRrLgmOq8Juudd97RX//618qAJUlOTk66//779c4771i1OAAAANgvRrLgqOocskpLS7Vnz54zju/Zs0cWi8UqRQEAAMC+WSyGDmcykgXHVKvpgn80bdo0TZ8+Xfv371e/fv0kSfHx8Xr88cc1bdo0qxcIAAAA+5OeW6TCEouczCa1DKB9OxxLnUPW008/rbCwMD3zzDNKSUmRJIWHh+vBBx/UAw88YPUCAQAAYH8On+4s2CrAQy5O7BoEx1LnkGU2m/XQQw/poYceUk5OjiTR8AIAAABV/L4ei6mCcDz1+lihtLRUv/zyiz7++GOZTOUbyx07dkx5eXlWLQ4AAAD26fc9smh6AcdT55Gsw4cPa+zYsTpy5IiKioo0atQo+fj46IknnlBRUZHmzZvXEHUCAADAjjCSBUdW55Gse+65R7GxsTp58qQ8PH5fxHjllVdq6dKlVi0OAAAA9omRLDiyOo9krVq1SmvXrpWrq2uV423btlVycrLVCgMAAIB9MgyDkSw4tDqPZFksFpWVlZ1x/OjRo/Lx8bFKUQAAALBfJ/KLlVdUKpNJigykfTscT51D1ujRo/X8889Xfm0ymZSXl6eHH35Y48aNs2ZtAAAAsEMV7dsj/Dzk5uxk42qAxlfn6YLPPPOMxowZo5iYGBUWFuqGG27Qvn37FBQUpI8//rghagQAAIAdOZRRPlWwbRDrseCY6hyyWrVqpW3btunTTz/Vtm3blJeXp+nTp2vy5MlVGmEAAADAMVWMZLEeC46qziFLkpydnTV58mRNnjzZ2vUAAADAzh063fSCzoJwVHVek+Xk5KSLLrpImZmZVY6npaXJyYk5twAAAI6OkSw4ujqHLMMwVFRUpNjYWO3cufOM5wAAAODYfh/JImTBMdU5ZJlMJn355Ze67LLLNGDAAH399ddVngMAAIDjyiooVvapEklS60CmC8Ix1Wsky8nJSS+88IKefvppXXfddfrvf//LKBYAAAAqR7HCfN3l4cpSEjimejW+qDBz5kx17NhR1157rVauXGmtmgAAAGCnfl+PxSgWHFedR7LatGlTpcHFRRddpHXr1ikpKcmqhQEAAMD+VO6RxXosOLA6j2QdPHjwjGMdOnTQli1blJaWZpWiAAAAYJ8qR7LYiBgOrM4jWTVxd3dXmzZtrHU7AAAA2KFDp0MWI1lwZLUayQoMDNTevXsVFBSkgICAs3YR/PP+WQAAAHAch083vqCzIBxZrULWc889Jx8fH0nS888/35D11CgzM1N33XWXvv32W5nNZl199dV64YUX5O3tfc5rDcPQuHHjtHjxYi1cuFATJkxo+IIBAAAcTE5hiU7kF0ui8QUcW61C1s0331ztvzemyZMnKyUlRUuWLFFJSYmmTZummTNnasGCBee89vnnn2cPLwAAgAZ25PQoVpC3q3zcXWxcDWA7tQpZOTk5tb6hr69vvYupye7du7V48WJt2LBBsbGxkqSXXnpJ48aN09NPP62IiIgar926daueeeYZbdy4UeHh4VavDQAAAOUOVbZvZz0WHFutQpa/v/85R4IMw5DJZFJZWZlVCvujuLg4+fv7VwYsSRo5cqTMZrPi4+N15ZVXVntdQUGBbrjhBr3yyisKCwur1WsVFRWpqKio8uu6BEwAAABHVrEei6mCcHS1ClnLly9v6DrOKjU1VSEhIVWOOTs7KzAwUKmpqTVed99992ngwIG64oorav1ac+fO1aOPPlrvWgEAABzVoQw6CwJSLUPWsGHDGuTFZ8+erSeeeOKs5+zevbte9/7mm2+0bNkybdmypU7XzZkzR/fff3/l1zk5OYqMjKxXDQAAAM3Nh3GH9P32FBUUlym/qFSnistUUFKmgqIyFZdZJDGSBdR5M+IKBQUFOnLkiIqLi6sc79GjR63v8cADD2jq1KlnPScqKkphYWFKT0+vcry0tFSZmZk1TgNctmyZ9u/fL39//yrHr776ag0ZMkS//vprtde5ubnJzc2ttt8CAACwoeJSi77emqyWAR7q0yZAbs5Oti6pWTuZX6xHv92lUotR4zktvFx1YVSLRqwKaHrqHLKOHz+uadOm6ccff6z2+bqsyQoODlZwcPA5zxswYICysrK0adMm9enTR1J5iLJYLOrfv3+118yePVu33nprlWPdu3fXc889p8suu6zWNQIAgKbrrdUH9OTiBEmSu4tZ/dq10JAOQRrUIUhdwnxkNte9u7DFYmjeyv0K8nbTxFhms/zR4p2pKrUY6hjirdmXdJGnq7M8XZ3k5eYkD1dnebo4ycfdWc5OZluXCthUnUPWvffeq6ysLMXHx2v48OFauHCh0tLS9N///lfPPPNMQ9So6OhojR07VjNmzNC8efNUUlKiWbNmadKkSZWdBZOTkzVixAh98MEH6tevn8LCwqod5WrdurXatWvXIHUCAIDGtWhLsiTJ09VJBcVlWrn3uFbuPS6pvI34wPZBmjEkSt1b+dX6no/9sFtvrz4ok0ka3jlYIT7uDVK7Pfrut2OSpCsvaKkR0aE2rgZouuocspYtW6avv/5asbGxMpvNatOmjUaNGiVfX1/NnTtX48ePb4g6NX/+fM2aNUsjRoyo3Iz4xRdfrHy+pKRECQkJKigoaJDXBwAATcue1BztTcuTq5NZcbNHKCXnlFbvy9DqxAzFH8hURl6xvtl2TEt2pemdqX01oP25p7C9s/qg3l59UJJkGNLPO9M05cI2Df2t2IXjuUWK239CknRp95q3zwFQj5CVn59f2ekvICBAx48fV6dOndS9e3dt3rzZ6gVWCAwMPOvGw23btpVh1Dw/WNI5nwcAAPbjm63loyrDOgfLz9NFfp4u6hLmq1uHRKm41KItR07qpWWJWp2YoWnvrddbN/XV4I5BNd7vx+0p+s/3uyRJ0eG+2p2So8U7UglZpy3ekSKLIfVs5afWNLYAzqrOE2Y7d+6shITyuc89e/bU66+/ruTkZM2bN4/NfgEAQKMwDEPfnp66dnnPM0dVXJ3N6h/VQm/dHKuLu4SosMSi6e9v0IrTUwn/bNPhTN376VYZhjTlwtaaN+UCSVLcgRPKzC+u9hpH8+1vKZKkS3swigWcS51D1j333KOUlPL/yR5++GH9+OOPat26tV588UX973//s3qBAAAAf7YlKUtJmafk6eqkkWdZG+Tu4qTXplygUTGhKiq1aMb7G7V8T9WOxQeO5+nW9zeqqNSikdEheuSyrmrTwksx4b4qsxhasqvmPTkdRVpOoTYcypQkje/Bh+rAudQ5ZE2ZMqWy7XqfPn10+PBhbdiwQUlJSbruuuusXR8AAMAZKqYKjooJlYfr2du2uzk76ZUbLtDYrmEqLrNo5ocbtWRXmiQpI69IU9/doJMFJerZyk8vXt+7sjPeuO7lDbR+2E7I+v63FBmG1KdNgCL8PWxdDtDknXd/TU9PT11wwQUKCqp5jjMAAIC1lFkMfb+9fFZNdVMFq+PqbNZLN/TW+O7hKikz9JePNmnhlqOa/v5GHcksUOtAT709ta88XX9frn5J9/IRm7X7M5RdUGL9b8SOVHQVvJRRLKBW6tz4wjAMffHFF1q+fLnS09NlsViqPP/VV19ZrTgAAIA/W3fghI7nFsnPw0VDOp57v80KLk5mvTCpl5ydTPp66zHd9+k2SVKAp4vem9ZXQd5uVc5vH+ytTqHe2puWp192p+nqPq2s+n3Yi+SsU9p8JEsmkzSuOyELqI06j2Tde++9uvHGG3Xw4EF5e3vLz8+vygMAAKAhVUwVHNc9TK7OdftVxtnJrGcn9tJVvVtKktyczXrr5lhFBXtXe/4l3cpDxY87Us6jYtvILSzRugMntC0pSyfzi+vdZfmH0w0v+rUNVKgve4YBtVHnkawPP/xQX331lcaNG9cQ9QAAANSoqLSsMvBcVsupgn/mZDbpqWt7alCHIHUM9VaPVv41njuue7heWLpPK/dmKLewRD7uLvV6zYZmGIYOZuRr85EsbTp8UluOnFRCWq7+mKt83J3VOtDz90cLT43oEqowv7MHJ6YKAnVX55Dl5+enqKiohqgFAADgrFbuzVBOYalCfNzUv925NxeuiZPZVKvpf51CvRUV7KUDx/O1bE+6rujVst6v2RAOZeTr8R/3KP7gCZ2sZt1YS38PlZRZlJ5bpNzCUu08lqOdx3Iqn3/KM0GL7hiktkFe1d7/yIkCbTuaLbNJGtuNkAXUVp1D1iOPPKJHH31U77zzjjw86C4DAAAazzfbKkZVIuRkNjX465lMJo3rFq6Xlyfqx+2pTSpkxR84ods+2qSs0+HK1dmsHi39dEGbAF3Q2l8XtA5QyOnpfaeKy3T0ZIGOZBbo8Inyf67cd1wHjufr1g826qs7Bsq3mlG677aX/3kPaN9CwT5uZzwPoHp1DlkTJ07Uxx9/rJCQELVt21YuLlX/h9y8ebPVigMAAKhQUFyqX063Xr+8V+NtiDu2W5heXp6o5Qnpyi8qlZdbnX99srovNh3VnK9+U0mZoZ6t/PTw5V3VLcKvxjVqHq5O6hjqo46hPpXH0nMKdfnLa5SYnqe7FmzRO1P7nhFcv9vGBsRAfdT5p8TNN9+sTZs2acqUKQoNDZXJ1PCfIgEAACzZlaZTJWVq08JTPVs1XrOtrhG+ah3oqSOZBfo14bhNN+O1WAw9/XOCXv11vyRpfPdwPTOxp9xdzr5XWHVCfN315k2xuvb1tVqx97jm/rBb/3dpTOXzB47naVdKjpzNJo3tGma17wFwBHUOWd9//71++uknDR48uCHqAQAAqNa3p6cKXtYjolE/5DWZTLqke5heX3FAP+xIsVnIOlVcpgc+31q5OfKsizro/lGdZD6PaZPdW/npmWt76c4Fm/XW6oPqGOqt6/q2liR9d7qr4KAOQQrwcj3/bwBwIHVu4R4ZGSlfX9+GqAUAAKBaWQXFWrH3uKTGnSpYYdzppg/L96SrsKSs0V8/PadQk96I0w/bU+XiZNIz1/bUX8d0Pq+AVWF8j3DdO7KjJOn/Fu3Q+oOZkugqCJyPOo9kPfPMM3rooYc0b948tW3btgFKAgAAqGrxjlSVlBnqEuajTn9YV9RYerTyU0t/DyVnndKKvcc1xsrT51KzC/X5xiTlFZWquMyikjKLSsuM0/9uaMPBTKXmFCrA00Wv3xirfu0Crfr6d1/cUfvS8vT99hTd/tEmPX1tD+1Ny5Ork1mjmSoI1FmdQ9aUKVNUUFCg9u3by9PT84zGF5mZmVYrDgAAQJK+PT2qUt+9sc6XyWTS2G5henv1Qf24PcWqIet4bpGufX2tkjJPnfW8qGAvvXNz3xrbrZ8Ps9mkp6/tqcOZ+dqRnKMZH2ySJA3tFCQ/j6a5NxjQlNU5ZD3//PMNUAYAAED10nMLFbf/hCTpchuFLEka1708ZC3dna6i0jK5Ode92cSfFRSXavr7G5SUeUqtAjx0SbcwuTiZ5eJklquzWc5mk1yczPJxd9aYbmHVtlm3Fg9XJ715U6yueHmN0nOLJNFVEKivOoWskpISrVixQv/85z/Vrl27hqoJAACg0g+/pchiSL1b+ysy0NNmdfSODFCor5vScoq0JjFDF3cJPa/7lZZZNGvBFv12NFsBni76cHp/tWuAUaq6CPfz0Bs3xeq61+Pk5mzWyJjz+x4BR1WnxhcuLi768ssvG6oWAACAMyxPKG94UdF8wlbMf2hlXtHhr74Mw9C/vtmpZXvS5eZs1ls397V5wKrQK9JfS+4bpu/vHiLvJrAnGGCP6txdcMKECVq0aFEDlAIAAFBVcamlstvdoA5BNq5GuqR7edD7eWeq8opK632fV3/drwXxR2QySS9M6q0+bQKsVaJVtG7hadNRQ8De1fnjiY4dO+rf//631qxZoz59+sjLq+qnLnfffbfVigMAAI5t29EsnSopU6CXq7qENX5XwT/r2zZQrQI8dPTkKf3ty9/08vW967xn16ItyXrqpwRJ0r8ujdHYbnTvA5qbOoest99+W/7+/tq0aZM2bdpU5TmTyUTIAgAAVrMmMUOSNKB9C6vsCXW+nMwmvTCpl657fZ2+/y1FsW0CNG1Q7depr03M0INfbJMk3Tq4XZ2uBWA/6hyyDh482BB1AAAAnGFtYnlXwUHtbT9VsEKfNoH6x/hoPfrtLj32/W71aOWnPm3OvW9VQmqubvtok0rKDI3vHq6/j4tuhGoB2EKd12T9kWEYMgzDWrUAAABUKigu1Zakk5Kkge1b2LiaqqYObKtLe4Sr1GLojvmblZFXdNbzlyek65p5a5VbWKq+bQP0zMSeTWJkDkDDqFfI+uCDD9S9e3d5eHjIw8NDPXr00Icffmjt2gAAgAPbcOikSsoMtfT3UJsWTasJg8lk0hNX91D7YC+l5RTp7o+3qMxy5gfPhmHo1V8Tdct7G5RbWKoLWvvrzZti5e5y/ntsAWi66hyynn32Wf3lL3/RuHHj9Nlnn+mzzz7T2LFjdfvtt+u5555riBoBAIADWnt6PdbA9i3q3FyiMXi5OWvelD7ydHXS2v0n9OyShCrP5xeVataCLXpycYIMQ7q+X6Q+nnmh/D1dbVQxgMZS5zVZL730kl577TXddNNNlccuv/xyde3aVY888ojuu+8+qxYIAAAc05r95SGrKbRur0nHUB89fnUP3f3xFr2yfL96RwZoZEyojpwo0MwPN2pPaq5cnEx65PKumty/ja3LBdBI6jySlZKSooEDB55xfODAgUpJSbFKUQAAwLFlFRRr57EcSeWdBZuyy3tGaOrAtpKk+z7bqk83HNFlL6/WntRcBXm76eMZFxKwAAdT55DVoUMHffbZZ2cc//TTT9WxY0erFAUAABzbugMnZBhShxBvhfq627qcc/r7uGhd0NpfuYWl+tuX25V9qkQ9I/313V2DFdv23J0HATQvdZ4u+Oijj+q6667TypUrNWjQIEnSmjVrtHTp0mrDFwAAQF2tqWzd3rRHsSq4Opv1yuQLdOmLq3Uiv1gTY1vp31d0o8EF4KDqHLKuvvpqxcfH67nnntOiRYskSdHR0Vq/fr169+5t7foAAIADqliPNbAJr8f6s3A/D31392AdOVGgfu0Cm2SzDgCNo84hS5L69Omjjz76yNq1AAAAKDW7UAeO58tski5sZx8jWRXC/TwU7udh6zIA2Nh5bUYMAABgbWtPj2J1a+knP08XG1cDAHVX65Ess9l8zmFvk8mk0tLS8y4KAAA4ror1WAPb289UQQD4o1qHrIULF9b4XFxcnF588UVZLBarFAUAAByTYRiK2//7JsQAYI9qHbKuuOKKM44lJCRo9uzZ+vbbbzV58mT9+9//tmpxAADAsRw6UaBj2YVydTKrL63PAdipeq3JOnbsmGbMmKHu3burtLRUW7du1fvvv682bdhoDwAA1N+axPJRrN6t/eXhSvtzAPapTiErOztbf/vb39ShQwft3LlTS5cu1bfffqtu3bo1VH0AAMCBVDS9GGRHrdsB4M9qPV3wySef1BNPPKGwsDB9/PHH1U4fBAAAqC+LxVDc/oqmF6zHAmC/TIZhGLU50Ww2y8PDQyNHjpSTU83D91999ZXVimsKcnJy5Ofnp+zsbPn6+tq6HAAAmq2dx7I1/sXV8nJ10taHR8vFiZ1mADQttc0GtR7Juummm9i5HAAANJi1p1u392sXSMACYNdqHbLee++9BiwDAAA4OtZjAWgu+JgIAADYXEmZResPZkqSBrAeC4CdI2QBAACb25aUpfziMgV6uSo6jDXQAOwbIQsAANjc6tP7Yw2IaiGzmTXgAOwbIQsAANjUpsOZen3FAUnS0E6sxwJg/whZAADAZnan5Gjauxt0qqRMQzsF68rerWxdEgCcN0IWAACwiYMZ+brx7fXKKSxVbJsAzZtygVyd+dUEgP3jJxkAAGh0KdmnNOWteGXkFSk63FdvT+0rT9da7ywDAE2a3YSszMxMTZ48Wb6+vvL399f06dOVl5d31muGDx8uk8lU5XH77bc3UsUAAKA6mfnFuvHt9UrOOqV2QV764JZ+8vNwsXVZAGA1dvOR0eTJk5WSkqIlS5aopKRE06ZN08yZM7VgwYKzXjdjxgz9+9//rvza09OzoUsFAAA1yC0s0c3vrFdiep7C/dz14fR+CvZxs3VZAGBVdhGydu/ercWLF2vDhg2KjY2VJL300ksaN26cnn76aUVERNR4raenp8LCwhqrVAAAUIPCkjLd+v5GbU/OVqCXqz6c3l+tAvjwE0DzYxfTBePi4uTv718ZsCRp5MiRMpvNio+PP+u18+fPV1BQkLp166Y5c+aooKDgrOcXFRUpJyenygMAANRfmcXQ97+l6MpX1yr+YKZ83Jz1wS391CHE29alAUCDsIuRrNTUVIWEhFQ55uzsrMDAQKWmptZ43Q033KA2bdooIiJCv/32m/72t78pISFBX331VY3XzJ07V48++qjVagcAwFEVlZbpq83Jen3Ffh06Uf4hp7ebs966OVbdWvrZuDoAaDg2DVmzZ8/WE088cdZzdu/eXe/7z5w5s/Lfu3fvrvDwcI0YMUL79+9X+/btq71mzpw5uv/++yu/zsnJUWRkZL1rAADA0eQWlmh+/BG9s/qg0nOLJEn+ni66eUBb3TywrQK9XG1cIQA0LJuGrAceeEBTp0496zlRUVEKCwtTenp6leOlpaXKzMys03qr/v37S5ISExNrDFlubm5yc2MBLgAA9fHx+iP63w+7lVtYKkkK93PXrUOiNKlvpLzc7GICDQCcN5v+tAsODlZwcPA5zxswYICysrK0adMm9enTR5K0bNkyWSyWyuBUG1u3bpUkhYeH16teAABQs7ScQv1z0Q6VWgy1D/bS7cPa64peLdlgGIDDsYufetHR0Ro7dqxmzJih9evXa82aNZo1a5YmTZpU2VkwOTlZXbp00fr16yVJ+/fv13/+8x9t2rRJhw4d0jfffKObbrpJQ4cOVY8ePWz57QAA0CzNjz+iUouhPm0CtOS+Ybo2NpKABcAh2c1Pvvnz56tLly4aMWKExo0bp8GDB+uNN96ofL6kpEQJCQmV3QNdXV31yy+/aPTo0erSpYseeOABXX311fr2229t9S0AANBsFZWWaUH8YUnStEFtZTabbFwRANiOyTAMw9ZFNGU5OTny8/NTdna2fH19bV0OAABN0sItR3Xfp9sU5uuuVX+7SC5OdvM5LgDUWm2zAT8BAQDAeXtvbfko1uT+rQlYABwePwUBAMB52XLkpLYlZcnVyazr+7e2dTkAYHOELAAAcF7eX3tIknRpz3AFebMNCgAQsgAAQL2l5xbq++0pkqSpA9vathgAaCIIWQAAoN4+jk9SSZmh3q391aOVv63LAYAmgZAFAADqpbjUovmn27YzigUAvyNkAQCAevlxR4rSc4sU7OOmS7qF27ocAGgyCFkAAKBeKhpeTO7fWq7O/EoBABX4iQgAAOps+9FsbT6SJRcnk26gbTsAVEHIAgAAdfbe6VGs8d3DFeLjbttiAKCJIWQBAIA6ycgr0rfbjkmSbqbhBQCcgZAFAADq5JP1R1RcZlHPVn7q3TrA1uUAQJPjbOsCAABA01dYUqY1iRn6eWeavvuNUSwAOBtCFgAAqFZ2QYmWJaTp551pWrH3uAqKyyqf697ST+N70LYdAKpDyAIAAFUUlpTpgc+2afHOVJVZjMrjEX7uGt01TKNjQtW3XaBcnFh1AADVIWQBAIAqnlycoO+3p0iSuoT5aHRMqEZ3DVPXCF+ZTCYbVwcATR8hCwAAVFq7P0PvrDkoSXrzpliNigm1cUUAYH8Y5wcAAJKknMIS/fWzbZKkG/q3JmABQD0RsgAAgCTp0W926Vh2oVoHeuof46JtXQ4A2C1CFgAA0OIdqfpy81GZTdKzE3vKy40VBQBQX4QsAAAcXHpuof6+cLsk6bZh7RXbNtDGFQGAfSNkAQDgwAzD0N+/2q7M/GJ1CfPRvSM72rokALB7hCwAABzYZxuT9MvudLk6mfXcdb3k5uxk65IAwO4RsgAAcFBJmQX697e7JEn3j+6k6HBfG1cEAM0DIQsAAAdUZjH0wGfblF9cpr5tAzRjSJStSwKAZoOQBQCAA/p5Z6rWH8qUl6uTnrm2l5zMJluXBADNBiELAAAHtGD9EUnSzQPbqnULTxtXAwDNCyELAAAHc+REgVbty5AkXd+vtY2rAYDmh5AFAICD+XhD+SjWkI5BigxkFAsArI2QBQCAAykutejzjUmSpMn9GcUCgIZAyAIAwIH8sjtNGXnFCvZx04joUFuXAwDNEiELAAAH8vHphhcTY1vJxYlfAwCgIfDTFQAAB/HHhheT+jJVEAAaCiELAAAHQcMLAGgchCwAABwADS8AoPEQsgAAcABLaXgBAI2GkAUAgANYQMMLAGg0/JQFAKCZq2h4YTLR8AIAGgMhCwCAZu73hhfBNLwAgEZAyAIAoBn7Y8OLG/pF2rgaAHAMhCwAAJoxGl4AQONztnUBAABAij9wQl9vO6YuYT66oHWAuoT5yNkKDSpoeAEAjY+QBQCAjWXmF+v2jzbpZEFJ5TEPFyf1aOWnC9oE6ILWAerTJkCBXq51ui8NLwDANghZAADUUXGpRSaTrDYy9Nj3u3WyoERtWniqTQsvbTlyUrmFpYo/mKn4g5mSJFdns16f0kcXdQmp9X3fWXNQEg0vAKCxEbIAAKiD7FMlGv/iKnm7OevrWYPk5ux0Xvdbk5ihLzcflckkPXddL13QOkAWi6H9x/O0+chJbTp8UvEHM3X4RIH++/0uDe0ULCez6Zz3PZFXpE9OdxWcOSTqvGoEANQNk7MBAKiDeSv26+jJU9qTmqsvNh09r3sVlpTp7wu3S5JuvLCNLmgdIEkym03qGOqj6/q21pPX9NR3dw2Wr7uz9h/P1w/bU2p17/fWHlJhiUU9WvlpUIcW51UnAKBuCFkAANRSWk6h3j09BU+SXl2+X8Wllnrf76Vl+3T4RIHCfN314JjONZ7n4+6i6YOjKq+xWIyz3je3sETvrz0kSfrLsPYymc498gUAsB5CFgAAtfTC0n0qLLGoV6S/gn3clJx1Sgu31G80a09qjl5fcUCS9OgVXeXj7nLW86cOaisfN2ftTcvTTztTz3rugvgjyiksVVSwl8Z0DatXfQCA+rObkJWZmanJkyfL19dX/v7+mj59uvLy8s55XVxcnC6++GJ5eXnJ19dXQ4cO1alTpxqhYgBAc3LgeJ4+3VC+qe/fx0XrtqHlI0svL09USVndRrMsFkNzvtquUouh0TGhtQpCfh4umjaoraTysFfTaFZhSZneWl0+2nb7sPYy12L9FgDAuuwmZE2ePFk7d+7UkiVL9N1332nlypWaOXPmWa+Ji4vT2LFjNXr0aK1fv14bNmzQrFmzZDbbzbcNAGginlmyV2UWQxd3CVG/doGa3L+NgrxdlZR5Sl9vPVane82PP6wtR7Lk7easR6/oWuvrbhncTl6uTtqTmqtfdqdVe85Xm5N1PLdI4X7umtCrZZ3qAgBYh12kjd27d2vx4sV666231L9/fw0ePFgvvfSSPvnkEx07VvNfbPfdd5/uvvtuzZ49W127dlXnzp01ceJEubm5NWL1AAB7t/1otr7/LUUmkyrXTnm4OmnG6a59ryxPVGktR7NSswv1xOIESeX3CvfzqHUd/p6uunlgW0nSi8v2yTCqjmaVlln0+sr9kqQZQ6Lk6mwXf80DQLNjFz994+Li5O/vr9jY2MpjI0eOlNlsVnx8fLXXpKenKz4+XiEhIRo4cKBCQ0M1bNgwrV69+qyvVVRUpJycnCoPAIBje/KnPZKkCb1aKjrct/L4lAvbKMDTRQcz8vXdb7Xr+vfINzuVV1SqXpH+mnJhmzrXcuuQKHm6OmlHco6WJ6RXee6HHak6fKJAAZ4umtQvss73BgBYh12ErNTUVIWEVN180dnZWYGBgUpNrX7x74ED5YuJH3nkEc2YMUOLFy/WBRdcoBEjRmjfvn01vtbcuXPl5+dX+YiM5C8pAHBkaxIztGpfhlycTLp/VKcqz3m5OevWIb93/Ss7R9e/n3emavHOVDmbTZp7Vfda7Xf1Z4FerrpxQHk4e2FpYuVolmEYeu3X8lGsqQPbydOVrTABwFZsGrJmz54tk8l01seePXvqdW+LpXzaxm233aZp06apd+/eeu6559S5c2e98847NV43Z84cZWdnVz6SkpLq9foAAPtnGIaeWFz+99Dk/m0UGeh5xjk3DWgjPw+Xc+5h9eP2FN376VZJ0oyhUVVGxOpqxpAoubuYtS0pSyv3ZUiSfk04rt0pOfJyddLNA+s+QgYAsB6bfsz1wAMPaOrUqWc9JyoqSmFhYUpPrzolorS0VJmZmQoLq74jU3h4uCQpJiamyvHo6GgdOXKkxtdzc3NjzRYAQJL0445U/XY0W56uTpp1cYdqzynfw6qdnl2yVy8t26fx3cOrdPSzWAw9u2SvXl6eKEka1KGF7hnR8bzqCvJ205T+bfTW6oN64Ze9GtoxqHIU64b+reXv6Xpe9wcAnB+bhqzg4GAFBwef87wBAwYoKytLmzZtUp8+fSRJy5Ytk8ViUf/+/au9pm3btoqIiFBCQkKV43v37tUll1xy/sUDAJq10jKLnv6p/O+QW4dEKci75g/gbh7YVm+uOlC5h9Ul3cs/6Ms+VaL7Pt2qZXvKPyi8dXA7zb6ki5ydzn8iycyhUfpw3WFtPpKlF5cmav2hTLk6mSunLwIAbMcu1mRFR0dr7NixmjFjhtavX681a9Zo1qxZmjRpkiIiIiRJycnJ6tKli9avXy9JMplMevDBB/Xiiy/qiy++UGJiov75z39qz549mj59ui2/HQCAHfh801EdyMhXoJerZgxpd9Zzy/ewKj+nYg+rxPRcXfnKGi3bky43Z7Oeu66n/u/SGKsELEkK8XXX9f1aS5Ke+2WvJOnqPi0V6utulfsDAOrPblbFzp8/X7NmzdKIESNkNpt19dVX68UXX6x8vqSkRAkJCSooKKg8du+996qwsFD33XefMjMz1bNnTy1ZskTt27e3xbcAALAThSVlev50cLnzog7ycXc55zXTB7XTO6sPak9qrv7z/S59vvGo8opKFeHnrtdvjFX3Vn5Wr/P2Ye21IP6IisssMpukmUP5+w0AmgKT8edNNlBFTk6O/Pz8lJ2dLV/f+i9SBgDYj6+3JuueT7Yq3M9dvz44XG7OTrW67umfEirXXklS/3aBemXyBWedani+/vX1Dn0Qd1iX9gjXyzdc0GCvAwCofTawm5EsAAAay6ItyZKka/u0qnXAkqTpg9vp/bWHlFtUqqkD2+of46PlYqXpgTX5+7hodYvw09ju1TeCAgA0PkIWAAB/kJFXVNkW/YreLet0bYCXqxbeOUjZp4rVp01gQ5R3BncXJ03sy56OANCUELIAAPiD77YdU5nFUI9Wfmof7F3n6zuE1P0aAEDzYhfdBQEAaCyLth6TJE3oVbdRLAAAKhCyAAA47WBGvrYmZcnJbNJlPSNsXQ4AwE4RsgAAOK2i4cXgDkEK9mm4joAAgOaNkAUAgCTDMLRoa3nImtCbUSwAQP0RsgAAkLQlKUuHTxTIw8VJo2Nohw4AqD9CFgAAkr4+PVVwTNdQebnRfBcAUH+ELACAwysps+jb31IkSRPquDcWAAB/RsgCADi8VfuOKzO/WEHerhrcIcjW5QAA7BwhCwDg8BZuKd8b69IeEXJ24q9GAMD54W8SAIBDyysq1ZJdqZKkK5kqCACwAkIWAMCh/bQjVYUlFkUFealHKz9blwMAaAYIWQAAh/b73lgtZTKZbFwNAKA5IGQBABxWWk6h1iRmSJIm9GKqIADAOghZAACH9e22Y7IY0gWt/dW6haetywEANBOELACAw6qYKkjDCwCANRGyAAAOKTE9VzuSc+RsNml8jwhblwMAaEYIWQAAh7R4R3nb9iEdgxTo5WrjagAAzQkhCwDgkJbsTpckje4aZuNKAADNDSELAOBw0nMKtS0pS5I0okuIbYsBADQ7hCwAgMNZuqd8FKtnpL9CfN1tXA0AoLkhZAEAHM4vu9IkSaOiGcUCAFgfIQsA4FAKiku1+vQGxCNjQm1cDQCgOSJkAQAcyup9GSoqtahVgIc6h/rYuhwAQDNEyALOwjAMW5cAwMp+2V0+VXBkdKhMJpONqwEANEfOti4AaKo2HT6pm96Ol5+Hi7q19FP3ln7q1qr8n0HebrYuD0A9lFkMLT3dun0UUwUBAA2EkIV6yykskbers8zm5vlJ8NM/JSi/uEz5xWU6ll2on08vlJekCD93dWvpp2mD2mlA+xY2rBJNzcGMfH3/2zEFernp+n6RjJQ0MVuTTupEfrF83J3Vr12grcsBADRThCzUWXpOoZ5dslefbUxSxxAfPXxZjAZ2CLJ1WVa15chJxR04IWezSa9OvkBHMgu0IzlbvyVn62BGvo5lF+pYdqFW7D2uT2ZeqN6tA2xdMmzoeG6RvvvtmBZtPVa595IkbT5yUv+7srtcnZmZ3VQs2VU+ijW8c4hcnPjvAgBoGIQsB5CUWaBdKTm6qHPIef2yV1BcqjdXHtTrK/eroLhMkpSQlqsb3orX2K5h+sf4aEUGelqrbJt69df9kqQJvVtqdNewKs/lFpZo57Ecvfbrfq3Ye1wzPtioRXcOUquA5vG9o3byikq1ZFeqFm05ptWJGSqzlK/fczKbFNsmQBsOZeqLTUeVml2oV6dcIF93FxtXDOn39VhMFQQANCRCVjNVUmbR0t3pWrD+iFbtOy7DkDqEeOt/V3av8xQZi8XQl5uP6umfE5SWUyRJ6hXpr/tGddKy3Wn6KP6IFu9M1bKEdM0cEqU7LmovT1f7fWvtS8vVkl1pMpmk24dFnfG8j7uLLoxqoe4t/XTNvDjtTsnRre9v1Oe3D5APv0jbLcMwVGoxVFJmUUlZ+T+LSi1KzS7Ukcx8HTlxSkcyC5SUWaDDmfmV/y9U6BXprwm9InRpzwgFebtp+Z503blgs1YnZuja1+L07rS+ivD3sNF3B6l8Kmdiep6czSYN6xRs63IAAM2YyaB92lnl5OTIz89P2dnZ8vX1tXU553T0ZIE+WZ+kzzYmKT33918Cvd2clVdUKkm6LjZSc8Z1kb+n61nvZRiG1u4/oce+361dKTmSpFYBHvrb2C66tEd45VqThNRcPfrtTq3df0KSFObrrtmXdNEVvSLscj3K/Z9t1VebkzWma6hevzH2rOceyzqlK15Zo+O5Rbqoc7DeurmvnJrpGrXmwGIxdOhEvrYnZ2v70WxtT87WntRcFRSXqqSs7j8K2wV56YpeEbqiV0u1C/I64/kdydm65b0NSs8tUoiPm96Z2lfdWvpZ41tBPby16oD++/1uDerQQvNvvdDW5QAA7FBtswEh6xzsIWTlFJbo14Tj+mrzUa3YWz5qJUlB3q66pk+kru8XKX8PVz2+eI8+Xn9EktTCy1X/d2m0JvRqWSUIlZZZtOnwSf28K00/70pVUuYpSZKPu7PuuriDbhrQVu4uTmfUYBiGft6Vpv9+v6vymhFdQjTvxj52te7h6MkCDX/qV5VaDH195yD1jPQ/5zXbkrJ03RtxKiyxaNqgtnr4sq41npuWU6gP4g7Jz8NFM4ZE2WUItTcn8or01uqD2nLkpHYm5yj39IcNteHiZFKIj7taB3qWP1p4KrLi3wM9FeDpcs7/hslZpzTt3fXam5YnT1cnvXLDBbqoS8j5fluoh+tej1P8wUw9fFmMpg1qZ+tyAAB2iJBlJU01ZKXlFGrJrjT9vCtNcfszqnwKP6hDC93Qr41GxYSesQZr46FM/X3hdu1Ny6s895+Xxigp85R+3pmqpXvSlZlfXHm+m7NZ1/drrbtHdFSg19lHviSpsKRMb68+qJeW7VNhiUXX9Gmlp67pYTdh4uGvd+j9uMN1/qT7h+0pumP+ZknSfyZ0040Xtqny/LGsU5q3Yr8+2ZCk4lKLJOm/E7ppyp/Og3XlFJZo4rw47UnNrTzm5mxWdLiverTyU7eWfuoW4acALxc5m81ydTLLxdkkZ7NZLk4mq71vcwpL9JePNmlN4gk5mU26dUg7+bg5q6C47PSjVPnFZTpVXCYfd2dN7t+GzndWdjK/WLGP/aIyi6FVD13UbNaPAgAaFyHLSppSyEpMz9PPu1L18840bf1DBzNJah/spTFdw3RtbGS105b+qLjUojdXHdCLS/ep6PQv/H/k5+GiEdEhGh0TpqGdguq1vmrZnjTd+v5GWQzpnhEddd+oTnW+R2PLyCvSoMeXqajUoo+m99fgjnXrmPjK8kQ99VOCnMwmvTu1r4Z2ClZSZoFe/XW/vtiUVBmE2wV56WBGvlydzPryLwPVvRXTxxpCUWmZpr6zQXEHTijYx01/Hd1JPVr5q0OIt01GV4tLLfr7wu36YtPRWp0f2yZAfxneXhd1Dmm22yQ0poVbjuq+T7epS5iPFt871NblAADsFCHLSppKyMotLFHvfy9RqeX3/1y9W/trdEyYRsWEqkOId53vefhEvv759U6t3HtcLf09NComVKO7hqpf20A5W+GX0AXxR/T3hdslSU9e3UMT+0ae9z0b0tM/Jejl5Ynq0cpPX985qM6jGIZh6IHPt+mrzcnycXPWyJhQfbPtWGXXuQFRLXT3iI66MCpQMz/cpCW70hQZ6KHvZg2RnycNM6zJYjF01ydb9P1vKfJ2c9YnMy9sEmuhDMPQgvVHtO5ApjxdnOTh6iQvNyd5ujrL09VJnq5O2pqUrS83HVVxWfkHIJ1DfXT78Chd2iPCrqbeNjV3zt+s77enaNZFHfTXMZ1tXQ4AwE4RsqykqYQsSbrlvQ0qsxga3TVUo6JDFeLrbpX75haWyNvNuUGm9D310x69sny/nMwmvTO1b5Pt6JVbWKKBjy9TbmGp5k25QGO7hdfrPkWlZZryVrw2HDpZeWxIxyDddXHHKtO/sgtKdOnLq5SUeUqjYkL1xo197GZKZVNnGIb+/d0uvbvmkFycTHpvWj8NsrN93NJzCvXOmkP6aN3hyoY1Lf09NHNolKZc2IbmKnVUVFqmPv/5RXlFpVp05yD1qsVaSwAAqkPIspKmFLIMw7C7X8QNw9D9n23Twi3J8nJ10qe3DWgSIwp/9vqK/Zr74x5FBXvpl/uGndf0rMz8Yt398RZ5uDrpL8Pb64IaNirefjRbV7+2VsVlFv1jXLRmDD2zXTzqruK/pSS9MKmXrujV0sYV1V/2qRLNjz+sd1YfVEZe+VrJS7qF6flJveTmfGYDGlRv5d7juumd9Qr2cVP8nBFMvwQA1FttswFzT+yIvQUsqbzmJ67uoQFRLZRfXKZb3tug5KxTti6risKSMr21+qAk6fZh7c/7F7BAL1d9dGt/vXlTbI0BS5K6t/LTPy+LkSQ9vniPNh7KPK/XhfTV5qOVAev/xkfbdcCSytdH3jG8g1b/7WI9clmMXJ3M+nFHqm59f6MKimvfJdHRVWxAPDKa9W0AgMZByEKDc3U2a96NfdQp1FvpuUWa+s56ZReU2LqsSl9uPqrjuUUK93PXhEb+pXxK/9a6rGeEyiyGZi3YohN5Ree+CNVaufe4HvriN0nSjCHtdOuQ5jMy6O7ipKmD2umdqX3l6eqkVfsydOPb65V9qun8f9RUGYahX3ZVhKxQG1cDAHAUhCw0Cj8PF703rZ9Cfd20Lz1P170Rp682H1VhSZlN6yots+j1FQckSTOGRJ3R8r6hmUwmzb2qu6KCvZSaU6h7P90qi4UZvOeSV1SqxPRcrdx7XJ9tSNJzS/bq9o82qdRi6IpeEZpzSbStS2wQgzsG6cPp/eXr7qxNh0/q+jfWKYNgXqPCkjIt3JKsY9mFcncx293aPACA/WJN1jk0pTVZzcGuYzm67o045RaWT3Xy83DR1Re00g39W9erQ+L5KCot0zM/79UbKw8owNNFa2ZfXK929dawJzVHE15Zo8ISi2YOjdI1fVop3M9dPu50Hazw5aajenPVASVnnap8//zZ4A5Bemdq30YPy41td0qObnx7vTLyihQV5KUPb+2vlv4eti6rScg+VaJfE9L18840/ZqQrvzi8g9yRseE6o2bYm1cHQDA3tH4wkoIWdaXnluoT9cn6ZMNSVXWZ/VrF6jJ/VtrWKdgWQyppMxy+mGopMyi4lKL/DxcrLKJaNz+E/rHou06cDxfkppE44nPNybpwdPT3Sp4uzkr3M9dYX7uivDzUHS4j24a0Nbh1pX8vDNVt320SX/8aeXj5qxwf3eF+3ko3M9dHUK8dX2/1vJys01QbmyHMvI1+a14JWedUoSfuz66tb+ighv3g4qmorTMok82JOmnnamK23+iylYXob5uGhUTqr8M70AQBQCcN0KWlRCyGk6ZxdDKvce1YP0RLd2dptrOkusS5qPx3cM1rke42tfxl8rM/GL974fdlRvCBvu46eHLYjS+e3iTaCzyxsr9+mpzslKyC2tcb2PvHfPqakdytq6dF6dTJWW6LjZStw5ppzBG+SRJKdmnNOWteO0/nq8gb1dNHdhWgzoEqUcrf4dq8/7INzv13tpDlV93DPHW6K6hGh0Tpu4t/RzuQwkAQMMhZFkJIatxpGYX6tMNSfp0wxEdyy6UJDmZTXJxMsnFbJaLs1nOZpMy84urfErdJcxHl/YI17ju4Wf9FN8wDH25OVmPfb9LJwtKZDJJk/u31oNjusjPo2n+sl5QXKqU7EKlZBUqJfuUlu5O1+KdqerTJkBf/mWgrctrFGk5hbri5TVKzSnUkI5BendqX6tslN2cnMgr0s3vrteO5JzKY77uzhrQvoUGdwzW4A5BatvC06ofIhiGoV/3HleIj5u6Rth2S4aU7FMa9uSvKi6z6O4RHTWhV4TDjugBABoeIctKCFmNyzAMFZVa5OpkrvbT56yCYv28M03fb0/RmsSMKoErKshLAV6u8nR1Ov1wrvz3345mK/5geYv0LmE+euzK7urTpub26k1Rek6hBj6+TKUWQ9/fPdjmv9w2tILiUl33+jptT85WhxBvffmXgU02ENtaQXGpFm5J1qq9GVq7P0M5f1qz1irAQ49d2d0qm4Fn5hfrb1/+piW70uTmbNbie4eqXZDXed+3vv719Q59EHdY/doF6rPbBtisDgCAYyBkWQkhq+k6mV+sn3el6vvtqVqTmKGyc8w3dHcx696RnTR9cDu52OloyKwFm/Xdbyma1DdSj1/dw9blNBiLxdAd8zdr8c5UBXq5atEdg9S6xfmvxXMEZRZD25OztSYxQ6v2HdemwydVUmbIy9VJX88afF4NZlbtO677P9um47m/dzSMbROgT28bYJPpianZhRr65HIVl1m0YEZ/DWxP90AAQMNqdiErMzNTd911l7799luZzWZdffXVeuGFF+TtXf0vDIcOHVK7du2qfe6zzz7TtddeW6vXJWTZh8z8Yu08lq38ojKdKikt/2dxmfKLS3WquExOZpOu79faKk0zbGn9wUxNfD1O7i5mxc8ZKT/P5jmy88TiPXrt1/1ydTJr/oz+6ts20NYl2a2C4lLd8t4GrTuQqfbBXvp61mB517E5SFFpmZ5anFC5aXf7YC/NuSRa9366VXlFpfq/8dE22Zfs4a936P24w+rXNlCf3nZhk1hXCQBo3ppdyLrkkkuUkpKi119/XSUlJZo2bZr69u2rBQsWVHt+WVmZjh8/XuXYG2+8oaeeekopKSk1hrM/I2ShKTEMQ5e8sEp7UnNt9ottQ/tjl8XnruupK3u3snFF9i8jr0iXvrhaqTmFuqRbmF6dfEGtA0lieq7u/nirdqWUr/macmFr/WNcjDxcnfTx+iOa89V2uTmb9cM9Q+rciOZ8pGYXauhTy1VcatGCW/trIHtgAQAaQW2zgV3Mmdq9e7cWL16st956S/3799fgwYP10ksv6ZNPPtGxY8eqvcbJyUlhYWFVHgsXLtTEiRNrHbCApsZkMummAW0lSR+uO9zsNi5ed+CE/r5wuyTpros7ELCsJMjbTa9NuUCuTmb9uCNVr688cM5rDMPQh+sOa/yLq7UrJUeBXq5686ZY/XdCd3m4OkmSJvWN1JCOQSoqtejBz7edc8quNc1bsV/FpRb1bRugAe1bNNrrAgBQG3YRsuLi4uTv76/Y2N83khw5cqTMZrPi4+NrdY9NmzZp69atmj59+lnPKyoqUk5OTpUH0JRM6B0hH3dnHT5RoJX7jp/7AjtgGIY+WndYN7+zXiVlhsZ3D9d9IzvZuqxmpXfrAD18eYwk6cnFe7QmMaPGcw+fKN+D65+Ldqio1KIhHYO0+J4hGhUTWuU8k8mkx6/uIW83Z20+kqV3Tk8nbGhpOYVasP6IJOnekZ2YJggAaHLsImSlpqYqJCSkyjFnZ2cFBgYqNTW1Vvd4++23FR0drYEDz976eu7cufLz86t8REZG1rtuoCF4ujrrmj7lIzwfxh22cTXnL/tUie5csFn/d/oX+os6B+uZiT3Z26gB3NCvta7t00oWQ7rr4y1VNgOXyptmvLXqgMY8v1Jr95+Qu4tZ/7w0Ru9P66cQX/dq79nS30P/vDRakvTUzwlKTM9r8O/jtV9/H8UayCgWAKAJsmnImj17tkwm01kfe/bsOe/XOXXqlBYsWHDOUSxJmjNnjrKzsysfSUlJ5/36gLXdeGEbSdKyhHQlZRbYuJr623LkpMa/uEo/bE+Vs9mkf4yL1ts395W7i5OtS2uWTCaT/jOhm7q19FVmfrH+8tEmFZaUSZL2pOboqtfW6r/f71ZhiUUDolrop3uHavrgducMvBNjIzWsU7CKSy168IuGnTaYnlOoj0+PYt0zglEsAEDTVLcWU1b2wAMPaOrUqWc9JyoqSmFhYUpPT69yvLS0VJmZmQoLCzvn63zxxRcqKCjQTTfddM5z3dzc5Obmds7zAFuKCvbWkI5BWrUvQx+tO6w546JtXVKdWCyG3lh1QE//lKBSi6HIQA+9dP0F6hXpb+vSmj13FyfNm9JHl720Wr8dzdY/F+1QuL+HXl2eqFKLIR93Z/1jXLSu6xtZ6wBTPm2wu0Y/u1JbjmTprVUHdNuw9lXOyS4oUdyBDK1OzJCrk5PmjOtSr60UXluxX0WlFsW2CdCgDoxiAQCaJpuGrODgYAUHn3tzzAEDBigrK0ubNm1Snz59JEnLli2TxWJR//79z3n922+/rcsvv7xWrwXYi5sGtNWqfRn6dGOS7hvVyW5GfzLyinT/Z9u0cm/5erLxPcI196ru8nVvnu3om6JWAZ568freuvmd9fp809HK46NiQvXfCd0UWsPUwLMJ9/PQPy+N0UNf/qZnluzVkI7Byj5VotWJx7U68YS2H83SHwe4OoR464b+rev0Guk5hVoQf3oUa2RHRrEAAE2WXazJio6O1tixYzVjxgytX79ea9as0axZszRp0iRFRERIkpKTk9WlSxetX7++yrWJiYlauXKlbr31VluUDjSYi7uEqKW/h7IKSvTttuq7bDY1+9JyddlLq7Vy73G5u5j1+FXd9fL1vQlYNjCkY7D+OqazJCnI21Wv3HCB3rixT70CVoVrY1tpeOfyaYPjXlyl699cp1eW79e2pPKA1SHEW4NPt1p/ZXmiikstdbr/6ysPqKjUoj5tAirvAwBAU2TTkay6mD9/vmbNmqURI0ZUbkb84osvVj5fUlKihIQEFRRUXZ/yzjvvqFWrVho9enRjlww0KCezSVMubKMnFu/RB3GHdU2fVk36k/1Nh0/qlvc2KPtUiaKCvTRvSh91CvWxdVkO7Y7hHTS4Q5DatPCSn8f5B12TyaTHr+qhsS+sVFZBiYK83TS4QwsN7hisQR1aKNzPQ4UlZRry5HIlZ53Sl5uP6vp+tRvNSs8t1Efryhu93DOCUSwAQNNmN5sR2wqbEaMpy8wv1oVzl6q41KKFdwxU79YBjfK6+UWl2peep9aBngr0cj3n+csT0nXHR5t1qqRMvVv7652b+yqgFtfBPqXnFCr7VIk6hHhXG4beWnVA//1+t1oFeGjZA8Pl6nzuSRX/+nqHPog7rAta++vLvwwkZAEAbKK22cBuRrIAnCnQy1WX9gjXV5uT9WHc4QYJWflFpdqVkqPtR7O1Pbn8sf94ngxDcncx6+YBbXXbsPY1hq1FW5L118+3qdRiaFinYL025QJ5uvKjpzkL8XWvseW7JE3u30bzVhzQ0ZOn9NXmo5p0jtGs9Qcz9eHpUay/ju5MwAIANHmMZJ0DI1lo6rYmZWnCK2vk6mTW6tkXKcSn/mtq/ujwiXzd88lWbTuapep+Svi6OyunsFSS5OXqpGmD2mnGkCj5ef4+7eyd1Qf17+92SZIm9IrQU9f2rFdHOTQ/fxzNWv7X4TW+LwqKS3XJC6t0+ESBJvWN1ONX92jkSgEA+F1tswG/7QB2rlekv3q28lNxmUVXvbpWW46cPO97FpaU6faPNmtrUnnACvV108joUN03spPemRqr9f8YoW0Pj9a7U/uqW0tf5ReX6eXliRr85DK9uHSfcgtL9NRPeyoD1rRBbfXsxF4ELFSa3L+NgrxdK0ezavLk4gQdPlGgCD93/WO8fW1VAABwXIxknQMjWbAHCam5uvWDDUrKPCVns0l/HdNZM4dEnXMT2Zr836Lt+mjdEQV6uerLvwxUuyCvGs81DEM/7UzTc0v2KiEtV5Lk5mxW0enOcQ+O6aw7hrdnihfO8ObKA3rsh92KDCxfm/XnEL7uwAlNemOdJOmDW/ppaCe24QAA2BYjWYAD6Rzmo+/vHqLxPcJVajH0+I97NPW9DcrIK6rzvb777Zg+Wle+F9GzE3ueNWBJ5R3lxnYL04/3DNGL1/dWVLCXikotMpukuVd1150XdSBgoVqTL2ytIG9XJWWe0sLNyVWeKygu1UNf/CZJur5fJAELAGBXCFlAM+Hr7qKXr++tx6/qLncXs1buPa5LXlilNYkZtb7H4RP5mv3ldknSX4a31/DOIbW+1mw26fKeEfr53qGaN6WPPrttQK3bc8Mxebo6a+bQKEnSy8sTVVL2+75ZT/y4R0cyC9TS30N/H8c0QQCAfSFkAc2IyWTSpH6t9c2sweoU6q3juUWa8na8nv4pocovsNUpKi3TnQs2K6+oVLFtAvTAqE71qsHZyayx3cIU2zawXtfDsUy5sI1aeLnqSGaBFm4pH81auz9D78eVdxN8/Oru8mGzagCAnSFkAc1Qp1AffX3nYF3fL1KGUT5KMOb5lVqyK001LcP83/e7tSM5RwGeLnrx+t5ypkkFGsEfR7NeWZ6o7FMlf5gm2FpDOjJNEABgf/gtCmimPFydNPeqHnrp+t5q4eWqA8fzNeODjbr+zXXafjS7yrk/bk+pHDl4dmIvRfh72KJkOKgbB7RRoJerDp8o0DWvrdXRk6dOTxPsYuvSAACoF0IW0Mxd1jNCyx8crr8Mby9XZ7PWHcjUZS+v1v2fbtWxrFM6cqJAD31ZPnJw29AoXdSl9uuwAGvwdHXWbadHs/al50mSnri6B9MEAQB2ixbu50ALdzQnR08W6OmfErRo6zFJ5a3Wg33cdPTkKV3Q2l+f3jaAvaxgEwXFpRr8xHJl5hdrcv/WeuzK7rYuCQCAM9Q2GxCyzoGQheZoW1KWHvt+t9YfypQk+Xm46Id7hqgl0wRhQ2sTM7RyX4buHtFBnq7Oti4HAIAzELKshJCF5sowDP28K01fbjqq6YPbqX9UC1uXBAAA0KTVNhvwUSHgoEwmk8Z0DdOYrmG2LgUAAKBZYfEFAAAAAFgRIQsAAAAArIiQBQAAAABWRMgCAAAAACsiZAEAAACAFRGyAAAAAMCKCFkAAAAAYEWELAAAAACwIkIWAAAAAFgRIQsAAAAArIiQBQAAAABWRMgCAAAAACsiZAEAAACAFRGyAAAAAMCKCFkAAAAAYEWELAAAAACwIkIWAAAAAFgRIQsAAAAArMjZ1gU0dYZhSJJycnJsXAkAAAAAW6rIBBUZoSaErHPIzc2VJEVGRtq4EgAAAABNQW5urvz8/Gp83mScK4Y5OIvFomPHjsnHx0cmk8mmteTk5CgyMlJJSUny9fW1aS2wH7xvUF+8d1AfvG9QH7xvUF+N/d4xDEO5ubmKiIiQ2VzzyitGss7BbDarVatWti6jCl9fX34Aoc5436C+eO+gPnjfoD5436C+GvO9c7YRrAo0vgAAAAAAKyJkAQAAAIAVEbLsiJubmx5++GG5ubnZuhTYEd43qC/eO6gP3jeoD943qK+m+t6h8QUAAAAAWBEjWQAAAABgRYQsAAAAALAiQhYAAAAAWBEhCwAAAACsiJBlR1555RW1bdtW7u7u6t+/v9avX2/rktCEzJ07V3379pWPj49CQkI0YcIEJSQkVDmnsLBQd955p1q0aCFvb29dffXVSktLs1HFaIoef/xxmUwm3XvvvZXHeN+gOsnJyZoyZYpatGghDw8Pde/eXRs3bqx83jAM/etf/1J4eLg8PDw0cuRI7du3z4YVoykoKyvTP//5T7Vr104eHh5q3769/vOf/+iPfdh472DlypW67LLLFBERIZPJpEWLFlV5vjbvkczMTE2ePFm+vr7y9/fX9OnTlZeX12jfAyHLTnz66ae6//779fDDD2vz5s3q2bOnxowZo/T0dFuXhiZixYoVuvPOO7Vu3TotWbJEJSUlGj16tPLz8yvPue+++/Ttt9/q888/14oVK3Ts2DFdddVVNqwaTcmGDRv0+uuvq0ePHlWO877Bn508eVKDBg2Si4uLfvzxR+3atUvPPPOMAgICKs958skn9eKLL2revHmKj4+Xl5eXxowZo8LCQhtWDlt74okn9Nprr+nll1/W7t279cQTT+jJJ5/USy+9VHkO7x3k5+erZ8+eeuWVV6p9vjbvkcmTJ2vnzp1asmSJvvvuO61cuVIzZ85srG9BMmAX+vXrZ9x5552VX5eVlRkRERHG3LlzbVgVmrL09HRDkrFixQrDMAwjKyvLcHFxMT7//PPKc3bv3m1IMuLi4mxVJpqI3Nxco2PHjsaSJUuMYcOGGffcc49hGLxvUL2//e1vxuDBg2t83mKxGGFhYcZTTz1VeSwrK8twc3MzPv7448YoEU3U+PHjjVtuuaXKsauuusqYPHmyYRi8d3AmScbChQsrv67Ne2TXrl2GJGPDhg2V5/z444+GyWQykpOTG6VuRrLsQHFxsTZt2qSRI0dWHjObzRo5cqTi4uJsWBmasuzsbElSYGCgJGnTpk0qKSmp8j7q0qWLWrduzfsIuvPOOzV+/Pgq7w+J9w2q98033yg2NlbXXnutQkJC1Lt3b7355puVzx88eFCpqalV3jd+fn7q378/7xsHN3DgQC1dulR79+6VJG3btk2rV6/WJZdcIon3Ds6tNu+RuLg4+fv7KzY2tvKckSNHymw2Kz4+vlHqdG6UV8F5ycjIUFlZmUJDQ6scDw0N1Z49e2xUFZoyi8Wie++9V4MGDVK3bt0kSampqXJ1dZW/v3+Vc0NDQ5WammqDKtFUfPLJJ9q8ebM2bNhwxnO8b1CdAwcO6LXXXtP999+vv//979qwYYPuvvtuubq66uabb658b1T39xbvG8c2e/Zs5eTkqEuXLnJyclJZWZkee+wxTZ48WZJ47+CcavMeSU1NVUhISJXnnZ2dFRgY2GjvI0IW0Azdeeed2rFjh1avXm3rUtDEJSUl6Z577tGSJUvk7u5u63JgJywWi2JjY/W///1PktS7d2/t2LFD8+bN080332zj6tCUffbZZ5o/f74WLFigrl27auvWrbr33nsVERHBewfNCtMF7UBQUJCcnJzO6OaVlpamsLAwG1WFpmrWrFn67rvvtHz5crVq1aryeFhYmIqLi5WVlVXlfN5Hjm3Tpk1KT0/XBRdcIGdnZzk7O2vFihV68cUX5ezsrNDQUN43OEN4eLhiYmKqHIuOjtaRI0ckqfK9wd9b+LMHH3xQs2fP1qRJk9S9e3fdeOONuu+++zR37lxJvHdwbrV5j4SFhZ3RHK60tFSZmZmN9j4iZNkBV1dX9enTR0uXLq08ZrFYtHTpUg0YMMCGlaEpMQxDs2bN0sKFC7Vs2TK1a9euyvN9+vSRi4tLlfdRQkKCjhw5wvvIgY0YMULbt2/X1q1bKx+xsbGaPHly5b/zvsGf/X97dxoSVdvHcfw3LWpy1Kk0rcg0sqw0mYpiivYwI8oWMiRKRQpt9UUE0WZF25ug5VWFFRRlULTR8qK0RZpW0aKwhbKCqaiQMm2d63lxc89z+2g9UXM7Vt8PHJg55+Jc/3O4mDk/rjNnBg0aVO8vIu7evavOnTtLkmJjYxUVFVVn3Lx580aXL19m3Pzhampq1KxZ3cvP5s2by+PxSGLs4P/7njHidDpVVVWl69eve9ucPXtWHo9HAwYMaJxCG+XxGvhp+/fvN4GBgWbXrl3m9u3bZtasWcZut5tnz575uzQ0Ebm5uSYsLMwUFxcbt9vtXWpqarxtcnJyTHR0tDl79qy5du2acTqdxul0+rFqNEX/fLqgMYwb1HflyhXTokULs2bNGnPv3j2zd+9eExwcbPbs2eNts379emO3282RI0dMeXm5SU1NNbGxsaa2ttaPlcPfMjIyTMeOHc3x48fNw4cPzaFDh0x4eLhZtGiRtw1jB2/fvjWlpaWmtLTUSDIbN240paWlprKy0hjzfWMkJSXFOBwOc/nyZXPx4kUTFxdn0tPTG+0YCFm/kC1btpjo6GgTEBBg+vfvb1wul79LQhMiqcFl586d3ja1tbVm9uzZpnXr1iY4ONhMnDjRuN1u/xWNJul/QxbjBg05duyYSUhIMIGBgSY+Pt5s27atznaPx2OWLVtmIiMjTWBgoBk5cqSpqKjwU7VoKt68eWMWLFhgoqOjTVBQkOnSpYtZsmSJ+fDhg7cNYwdFRUUNXtNkZGQYY75vjLx69cqkp6cby7JMaGioycrKMm/fvm20Y7AZ84+/2AYAAAAA/BR+kwUAAAAAPkTIAgAAAAAfImQBAAAAgA8RsgAAAADAhwhZAAAAAOBDhCwAAAAA8CFCFgAAAAD4ECELAAAAAHyIkAUA+KVlZmZqwoQJ/i4DAAAvQhYAoMmy2WzfXPLz87Vp0ybt2rXLL/Vt375dSUlJsixLdrtdDodD69at824nAALAn6mFvwsAAOBr3G6393VhYaGWL1+uiooK7zrLsmRZlj9KU0FBgfLy8rR582YNHTpUHz58UHl5uW7duuWXegAATQczWQCAJisqKsq7hIWFyWaz1VlnWVa92aJhw4Zp3rx5ysvLU+vWrRUZGant27fr3bt3ysrKUkhIiLp27aqTJ0/W6evWrVsaM2aMLMtSZGSkpk+frpcvX361tqNHjyotLU3Z2dnq2rWrevXqpfT0dK1Zs0aSlJ+fr927d+vIkSPembfi4mJJ0pMnT5SWlia73a42bdooNTVVjx498u7772NauXKlIiIiFBoaqpycHH38+NFn5xYA8O8hZAEAfju7d+9WeHi4rly5onnz5ik3N1dTpkzRwIEDdePGDSUnJ2v69OmqqamRJFVVVWnEiBFyOBy6du2aTp06pefPnystLe2rfURFRcnlcqmysrLB7QsXLlRaWppSUlLkdrvldrs1cOBAffr0SaNHj1ZISIguXLigkpISWZallJSUOiHqzJkzunPnjoqLi7Vv3z4dOnRIK1eu9O2JAgD8KwhZAIDfTlJSkpYuXaq4uDgtXrxYQUFBCg8P18yZMxUXF6fly5fr1atXKi8vlyRt3bpVDodDa9euVXx8vBwOhwoKClRUVKS7d+822MeKFStkt9sVExOj7t27KzMzUwcOHJDH45H0162MrVq1UmBgoHfmLSAgQIWFhfJ4PNqxY4cSExPVo0cP7dy5U48fP/bOdElSQECACgoK1KtXL40dO1arVq3S5s2bvfsHADRdhCwAwG+nd+/e3tfNmzdX27ZtlZiY6F0XGRkpSXrx4oUkqaysTEVFRd7feFmWpfj4eEnSgwcPGuyjffv2unTpkm7evKkFCxbo8+fPysjIUEpKyjeDUFlZme7fv6+QkBBvX23atNH79+/r9JWUlKTg4GDve6fTqerqaj158uQHzggAoDHx4AsAwG+nZcuWdd7bbLY662w2myR5w1B1dbXGjRunDRs21NtX+/btv9lXQkKCEhISNHv2bOXk5Gjw4ME6d+6chg8f3mD76upq9e3bV3v37q23LSIi4tsHBgD4JRCyAAB/vD59+ujgwYOKiYlRixY//tXYs2dPSdK7d+8k/XXL35cvX+r1VVhYqHbt2ik0NPSr+yorK1Ntba1atWolSXK5XLIsS506dfrh+gAAjYPbBQEAf7w5c+bo9evXSk9P19WrV/XgwQOdPn1aWVlZ9ULS33Jzc7V69WqVlJSosrJSLpdLM2bMUEREhJxOpyQpJiZG5eXlqqio0MuXL/Xp0ydNmzZN4eHhSk1N1YULF/Tw4UMVFxdr/vz5evr0qXf/Hz9+VHZ2tm7fvq0TJ05oxYoVmjt3rpo146sbAJo6PqkBAH+8Dh06qKSkRF++fFFycrISExOVl5cnu93+1VAzatQouVwuTZkyRd26ddPkyZMVFBSkM2fOqG3btpKkmTNnqnv37urXr58iIiJUUlKi4OBgnT9/XtHR0Zo0aZJ69Oih7OxsvX//vs7M1siRIxUXF6chQ4Zo6tSpGj9+vPLz8xvjdAAAfpLNGGP8XQQAAPivzMxMVVVV6fDhw/4uBQDwA5jJAgAAAAAfImQBAAAAgA9xuyAAAAAA+BAzWQAAAADgQ4QsAAAAAPAhQhYAAAAA+BAhCwAAAAB8iJAFAAAAAD5EyAIAAAAAHyJkAQAAAIAPEbIAAAAAwIf+A+jsy8p0ffthAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a random sub series\n",
    "number_of_stocks = len(stock_symbols)\n",
    "random_index_stocks = np.random.randint(0, number_of_stocks)\n",
    "random_index_sub_series = np.random.randint(0, number_of_sub_series)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(stocks_np_array[random_index_stocks][random_index_sub_series])\n",
    "plt.title('Random Sub Series')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "YROjk-wXufGo",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:50.082310Z",
     "start_time": "2023-11-25T20:29:49.900860Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SamplingLayerVAE(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SamplingLayerVAE, self).__init__()\n",
    "\n",
    "  def forward(self, mu, log_var):\n",
    "    std = torch.exp(0.5 * log_var)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=64,num_layers=3,bidirectional=False,\n",
    "               transfromer_hidden_size_attention = 128,num_heads=8,sub_seq_len=20,\n",
    "               latent_dim=64):\n",
    "    super(Encoder, self).__init__()\n",
    "    assert seq_len % sub_seq_len  == 0\n",
    "    self.number_of_sub_seq = seq_len // sub_seq_len\n",
    "    self.sub_seq_len = sub_seq_len\n",
    "    self.seq_len, self.n_features = seq_len, n_features\n",
    "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "    self.num_layers = num_layers\n",
    "    self.bidirectional = bidirectional\n",
    "    self.chunk_index_embedding = ChunkIndexEmbedding(num_chunks=self.seq_len,embedding_dim=embedding_dim)\n",
    "\n",
    "    self.mu = nn.Linear((self.sub_seq_len//2)*self.embedding_dim,latent_dim)\n",
    "    self.log_var = nn.Linear((self.sub_seq_len//2)*self.embedding_dim, latent_dim)\n",
    "    self.sampling_layer = SamplingLayerVAE()\n",
    "    self.rnn1 = nn.LSTM(\n",
    "          input_size=embedding_dim,\n",
    "          hidden_size=embedding_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "\n",
    "    multiple_bi = 2 if bidirectional else 1\n",
    "\n",
    "\n",
    "    #self.positional_encoding = PositionalEncoding(embedding_dim)\n",
    "    self.embedding_layer = nn.Linear(n_features, embedding_dim)\n",
    "    self.transformer_1 = CompressWithAttentionResidual(input_size=self.hidden_dim,output_size=embedding_dim,\n",
    "                                             hidden_size_attention=embedding_dim*2,\n",
    "                                             group_size=self.number_of_sub_seq)\n",
    "\n",
    "    self.transformer_2 = CompressWithAttentionResidual(input_size=embedding_dim,output_size=embedding_dim,\n",
    "                                             hidden_size_attention=embedding_dim,\n",
    "                                             group_size=2)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    batch_size, seq_len, n_features = x.size()\n",
    "    original_x = x\n",
    "\n",
    "    #x = x.reshape((batch_size * seq_len, n_features))\n",
    "    x = self.embedding_layer(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.chunk_index_embedding(x)\n",
    "    x = F.relu(x)\n",
    "    x, (_, _) = self.rnn1(x)\n",
    "\n",
    "\n",
    "    x = self.transformer_1(x)\n",
    "    x = self.transformer_2(x)\n",
    "    x = x.reshape((batch_size, (self.sub_seq_len//2)*self.embedding_dim))\n",
    "    mu = self.mu(x)\n",
    "    log_var = self.log_var(x)\n",
    "    z = self.sampling_layer(mu, log_var)\n",
    "\n",
    "    return z, mu, log_var, original_x\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, seq_len, input_dim=64, n_features=1,num_layers=3,bidirectional=False,\n",
    "               sub_seq_len=20,latent_dim=64):\n",
    "    super(Decoder, self).__init__()\n",
    "    assert seq_len % sub_seq_len  == 0\n",
    "    self.number_of_sub_seq = seq_len // sub_seq_len\n",
    "    # number\n",
    "    self.sub_seq_len = sub_seq_len\n",
    "    self.seq_len, self.input_dim = seq_len, input_dim\n",
    "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "    self.num_layers = num_layers\n",
    "    self.bidirectional = bidirectional\n",
    "    self.expend_layer_1 = ExpandWithAttentionResidual(input_size=latent_dim,output_size=input_dim,\n",
    "                                             hidden_size_attention=latent_dim,\n",
    "                                             group_size=self.sub_seq_len ,expansion_factor=\n",
    "                                                    self.number_of_sub_seq)\n",
    "\n",
    "    self.expend_layer_2 = ExpandWithAttentionResidual(input_size=input_dim,output_size=input_dim,\n",
    "                                             hidden_size_attention=input_dim,\n",
    "                                             group_size=self.sub_seq_len*self.number_of_sub_seq,expansion_factor=2)\n",
    "\n",
    "    self.output_embeding = OutputEmbedding(input_dim=self.hidden_dim,seq_len=self.seq_len,output_dim=1)\n",
    "    self.chunk_index_embedding = ChunkIndexEmbedding(num_chunks=self.seq_len,embedding_dim=input_dim)\n",
    "    self.rnn1 = nn.LSTM(\n",
    "          input_size=input_dim,\n",
    "          hidden_size=input_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "    multiple_bi = 2 if bidirectional else 1\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    # x is shape (batch_size, 1, n_features)\n",
    "    # repeat the last dimension to have (batch_size, seq_len, n_features)\n",
    "    x = x.unsqueeze(1)\n",
    "    x = x.repeat(1, self.sub_seq_len//2, 1)\n",
    "\n",
    "    x = self.expend_layer_1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.chunk_index_embedding(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.expend_layer_2(x)\n",
    "    x = F.relu(x)\n",
    "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "    x = x.reshape((batch_size,self.seq_len, self.hidden_dim))\n",
    "    x = self.output_embeding(x)\n",
    "\n",
    "    # keep only the last layer\n",
    "\n",
    "\n",
    "    return x\n",
    "class ExpandWithAttentionResidual(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size_attention, group_size, expansion_factor):\n",
    "        super(ExpandWithAttentionResidual, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size_attention\n",
    "        self.group_size = group_size\n",
    "        self.expansion_factor = expansion_factor\n",
    "\n",
    "        # Linear projections for attention\n",
    "        self.Q_linear = nn.Linear(self.input_size, self.expansion_factor * self.hidden_size)\n",
    "        self.K_linear = nn.Linear(self.input_size, self.expansion_factor * self.hidden_size)\n",
    "        self.V_linear = nn.Linear(self.input_size, self.expansion_factor * self.hidden_size)\n",
    "\n",
    "        # Final linear transformations\n",
    "        self.attention_output_linear = nn.Linear(self.expansion_factor * self.hidden_size,  self.expansion_factor * self.hidden_size)\n",
    "        self.output_linear = nn.Linear(self.hidden_size , self.output_size)\n",
    "        self.norma = nn.LayerNorm(self.hidden_size)\n",
    "    def forward(self, x):\n",
    "        # x is shape (batch_size, seq_len, n_features)\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        # Use attention to expand the input\n",
    "\n",
    "        x = x.view(batch_size* seq_len , n_features)\n",
    "        Q = self.Q_linear(x)\n",
    "        K = self.K_linear(x)\n",
    "        V = self.V_linear(x)\n",
    "        Q = Q.reshape((batch_size, seq_len, self.expansion_factor * self.hidden_size))\n",
    "        K = K.reshape((batch_size, seq_len, self.expansion_factor * self.hidden_size))\n",
    "        V = V.reshape((batch_size, seq_len, self.expansion_factor * self.hidden_size))\n",
    "        # Compute attention weights\n",
    "        attention_weights = torch.matmul(Q, K.transpose(-2, -1)) / (self.hidden_size ** 0.5)\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "\n",
    "        # Apply attention weights to values\n",
    "        attended_values = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # Apply final linear transformations\n",
    "        attended_values = attended_values.reshape((batch_size* seq_len , self.expansion_factor * self.hidden_size))\n",
    "        attention_output = self.attention_output_linear(attended_values)\n",
    "\n",
    "        # Reshape attention output into groups of size self.group_size\n",
    "        attention_output = attention_output.view(batch_size, seq_len* self.expansion_factor ,self.hidden_size)\n",
    "\n",
    "        # Add residual connection\n",
    "        # repeat the tensor x to have the same shape as attention_output\n",
    "        # repeat to have from (batch_size, seq_len, n_features) to (batch_size, seq_len* self.expansion_factor ,n_features)\n",
    "        x = x.view(batch_size, seq_len, n_features)\n",
    "        x = x.repeat(1, self.expansion_factor, 1)\n",
    "        out = attention_output + x\n",
    "        batch_size, expended_seq_len, n_features = out.size()\n",
    "        # normalize the output\n",
    "        out = out.reshape((batch_size* expended_seq_len , n_features))\n",
    "        #out = self.norma(out)\n",
    "\n",
    "        # Final linear transformation\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        # RElu\n",
    "        out = F.relu(out)\n",
    "        out = out.reshape((batch_size, expended_seq_len, self.output_size))\n",
    "        return out\n",
    "\n",
    "class CompressWithAttentionResidual(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size_attention, group_size):\n",
    "        super(CompressWithAttentionResidual, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        print(f\"ouput size : {output_size}\")\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size_attention\n",
    "        self.group_size = group_size\n",
    "\n",
    "        # Linear projections for attention\n",
    "        self.Q_linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.K_linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.V_linear = nn.Linear(self.input_size, self.hidden_size)\n",
    "\n",
    "        # Final linear transformations\n",
    "        self.attention_output_linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.output_linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is shape (batch_size, seq_len, n_features)\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        # Reshape input into groups of size self.group_size\n",
    "\n",
    "        x = x.view(batch_size, -1, self.group_size, n_features)\n",
    "        group_len = x.size(1)\n",
    "\n",
    "        # Linear projections for attention\n",
    "        Q = self.Q_linear(x)\n",
    "        K = self.K_linear(x)\n",
    "        V = self.V_linear(x)\n",
    "\n",
    "        # Compute attention weights\n",
    "        attention_weights = torch.matmul(Q, K.transpose(-2, -1)) / (self.hidden_size ** 0.5)\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "\n",
    "        # Apply attention weights to values\n",
    "        attended_values = torch.matmul(attention_weights, V)\n",
    "\n",
    "        # Sum along the group dimension\n",
    "        attended_values = attended_values.sum(dim=2)\n",
    "\n",
    "        # Apply final linear transformations\n",
    "        attention_output = self.attention_output_linear(attended_values)\n",
    "\n",
    "\n",
    "        # Add residual connection\n",
    "        # so, we need to pack the tensor x to have the same shape as attention_output. We have to do : x[i] = x[i] + x[i+1] and so on paired by 2\n",
    "        group_size = self.group_size\n",
    "\n",
    "# Create slices and sum them based on the group size\n",
    "        slices = [x[:, i::group_size, :] for i in range(group_size)]\n",
    "\n",
    "        x = sum(slices)\n",
    "        # Final linear transformation\n",
    "\n",
    "        batch_size_2, sub_series_length, n_features = attention_output.size()\n",
    "\n",
    "\n",
    "        x = x.reshape((batch_size_2 , sub_series_length, n_features))\n",
    "        out = attention_output + x\n",
    "\n",
    "        # Final linear transformation\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        # RElu\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ChunkIndexEmbedding(nn.Module):\n",
    "    def __init__(self,num_chunks=100,embedding_dim=64):\n",
    "        super(ChunkIndexEmbedding, self).__init__()\n",
    "        self.num_chunks = num_chunks\n",
    "        self.embedding = nn.Embedding(self.num_chunks,embedding_dim )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        chunk_index = torch.arange(0, seq_len, 1).to(x.device)\n",
    "\n",
    "        chunk_index = chunk_index.unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "        chunk_index = self.embedding(chunk_index)\n",
    "\n",
    "        x = x + chunk_index\n",
    "        return x\n",
    "\n",
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self,seq_len, input_dim=1,output_dim=64):\n",
    "        super(InputEmbedding, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Linear(self.input_dim, self.output_dim)\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        x = x.reshape((batch_size * seq_len, n_features))\n",
    "        x = self.embedding(x)\n",
    "        x = x.reshape((batch_size, seq_len, self.output_dim))\n",
    "        return x\n",
    "\n",
    "class OutputEmbedding(nn.Module):\n",
    "    def __init__(self,seq_len, input_dim=64,output_dim=1):\n",
    "        super(OutputEmbedding, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Linear(self.input_dim, self.output_dim)\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, n_features = x.size()\n",
    "        x = x.reshape((batch_size * seq_len, n_features))\n",
    "        x = self.embedding(x)\n",
    "        x = x.reshape((batch_size, seq_len, self.output_dim))\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "dczKuxarcnVI",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:50.082499Z",
     "start_time": "2023-11-25T20:29:49.915545Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleEncoderLSTM(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=64,num_layers=3,bidirectional=False,latent_dim=64):\n",
    "    super(SimpleEncoderLSTM, self).__init__()\n",
    "    self.seq_len, self.n_features = seq_len, n_features\n",
    "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "    print(f\"hidden_dim: {self.hidden_dim}\")\n",
    "    self.num_layers = num_layers\n",
    "    self.bidirectional = bidirectional\n",
    "    self.chunk_index_embedding = ChunkIndexEmbedding(num_chunks=self.seq_len,embedding_dim=embedding_dim)\n",
    "    self.embedding_layer = nn.Linear(n_features, embedding_dim)\n",
    "\n",
    "    self.rnn1 = nn.LSTM(\n",
    "          input_size=embedding_dim,\n",
    "          hidden_size=self.hidden_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "\n",
    "    multiple_bi = 2 if bidirectional else 1\n",
    "\n",
    "    self.rnn2 = nn.LSTM(\n",
    "          input_size=multiple_bi * self.hidden_dim,\n",
    "          hidden_size=embedding_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True\n",
    "    )\n",
    "\n",
    "    self.mu = torch.nn.Linear(self.seq_len * embedding_dim, latent_dim)\n",
    "    self.log_var = torch.nn.Linear(self.seq_len * embedding_dim, latent_dim)\n",
    "    self.sampling_layer = SamplingLayerVAE()\n",
    "\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    original_x = x\n",
    "    batch_size, seq_len, n_features = x.size()\n",
    "    #x = x.reshape((batch_size * seq_len, n_features))\n",
    "    x = self.embedding_layer(x)\n",
    "    x = nn.ReLU()(x)\n",
    "    x = self.chunk_index_embedding(x)\n",
    "    x = nn.ReLU()(x)\n",
    "    x, (_, _) = self.rnn1(x)\n",
    "    x, (hidden_n, _) = self.rnn2(x)\n",
    "    x = x.reshape((batch_size, self.seq_len * self.embedding_dim))\n",
    "    mu = self.mu(x)\n",
    "    log_var = self.log_var(x)\n",
    "    z = self.sampling_layer(mu, log_var)\n",
    "\n",
    "    return z, mu, log_var,  original_x\n",
    "\n",
    "class SimpleDecoderLSTM(nn.Module):\n",
    "  def __init__(self, seq_len, input_dim=64, n_features=1,num_layers=3,bidirectional=False):\n",
    "    super(SimpleDecoderLSTM, self).__init__()\n",
    "    self.seq_len, self.input_dim = seq_len, input_dim\n",
    "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "    self.num_layers = num_layers\n",
    "    self.bidirectional = bidirectional\n",
    "    self.rnn1 = nn.LSTM(\n",
    "          input_size=input_dim,\n",
    "          hidden_size=input_dim,\n",
    "          num_layers=self.num_layers,\n",
    "          batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "    multiple_bi = 2 if bidirectional else 1\n",
    "    self.rnn2 = nn.LSTM(\n",
    "      input_size=input_dim * multiple_bi,\n",
    "      hidden_size=self.hidden_dim,\n",
    "      num_layers=self.num_layers,\n",
    "      batch_first=True\n",
    "    )\n",
    "    self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    # x is shape (batch_size,  n_features)\n",
    "    # repeat the last dimension to have (batch_size, seq_len, n_features)\n",
    "    x = x.unsqueeze(1)\n",
    "    x = x.repeat(1, self.seq_len, 1)\n",
    "\n",
    "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "    x = x.reshape((batch_size,self.seq_len, self.hidden_dim))\n",
    "    # keep only the last layer\n",
    "\n",
    "\n",
    "    return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "class PredictNextDayHead(nn.Module):\n",
    "    def __init__(self,latent_dim,hidden_dim=64):\n",
    "        super(PredictNextDayHead, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.linear_1 = nn.Linear(self.latent_dim,self.hidden_dim)\n",
    "        self.linear_2 = nn.Linear(self.hidden_dim,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear_1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = nn.Tanh()(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:50.084160Z",
     "start_time": "2023-11-25T20:29:50.076920Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "w-x4llsWcnVI",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:50.486162Z",
     "start_time": "2023-11-25T20:29:50.305676Z"
    }
   },
   "outputs": [],
   "source": [
    "class RecurrentAutoencoder_LSTM(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=64,latent_dim=2):\n",
    "    super(RecurrentAutoencoder_LSTM, self).__init__()\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.encoder = SimpleEncoderLSTM(seq_len, n_features, embedding_dim,bidirectional=True,num_layers=1,latent_dim=latent_dim).to(device)\n",
    "    self.decoder = SimpleDecoderLSTM(seq_len, latent_dim, n_features,bidirectional=True,num_layers=1).to(device)\n",
    "  def forward(self, x):\n",
    "    z, mu, log_var,  original_x = self.encoder(x)\n",
    "\n",
    "    x = self.decoder(z)\n",
    "    x = nn.Tanh()(x)\n",
    "    return x, original_x, mu, log_var\n",
    "\n",
    "  def predict_next_day(self,x):\n",
    "        z, mu, log_var, original_x = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hh7J7ZH9cnVI",
    "outputId": "1acb0e81-14d5-45ca-d8e8-137104b6e52f",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:50.899541Z",
     "start_time": "2023-11-25T20:29:50.712743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_dim: 64\n",
      "model : RecurrentAutoencoder_LSTM(\n",
      "  (encoder): SimpleEncoderLSTM(\n",
      "    (chunk_index_embedding): ChunkIndexEmbedding(\n",
      "      (embedding): Embedding(100, 32)\n",
      "    )\n",
      "    (embedding_layer): Linear(in_features=1, out_features=32, bias=True)\n",
      "    (rnn1): LSTM(32, 64, batch_first=True, bidirectional=True)\n",
      "    (rnn2): LSTM(128, 32, batch_first=True)\n",
      "    (mu): Linear(in_features=3200, out_features=64, bias=True)\n",
      "    (log_var): Linear(in_features=3200, out_features=64, bias=True)\n",
      "    (sampling_layer): SamplingLayerVAE()\n",
      "  )\n",
      "  (decoder): SimpleDecoderLSTM(\n",
      "    (rnn1): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
      "    (rnn2): LSTM(128, 128, batch_first=True)\n",
      "    (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "model_LSTM = RecurrentAutoencoder_LSTM(sub_series_length, 1, 32,latent_dim=latent_dim)\n",
    "print(f\"model : {model_LSTM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "RNCtBAqRufGp",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:50.899834Z",
     "start_time": "2023-11-25T20:29:50.720190Z"
    }
   },
   "outputs": [],
   "source": [
    "class RecurrentAutoencoder(nn.Module):\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=128,sub_seq_len=10,latent_dim=2):\n",
    "    super(RecurrentAutoencoder, self).__init__()\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    self.encoder = Encoder(seq_len, n_features, embedding_dim,bidirectional=True,num_layers=1,\n",
    "        sub_seq_len=sub_seq_len,latent_dim=latent_dim).to(device)\n",
    "    self.decoder = Decoder(seq_len, embedding_dim, n_features,bidirectional=True,num_layers=1,\n",
    "        sub_seq_len=sub_seq_len,latent_dim=latent_dim).to(device)\n",
    "\n",
    "    self.predict_next_day_head = PredictNextDayHead(latent_dim=latent_dim).to(device)\n",
    "  def forward(self, x):\n",
    "    z, mu, sigma, original_x = self.encoder(x)\n",
    "    x = self.decoder(z)\n",
    "    x = nn.Tanh()(x)\n",
    "    return x, original_x, mu, sigma\n",
    "\n",
    "  def predict_next_day(self,x):\n",
    "    z, mu, sigma, original_x = self.encoder(x)\n",
    "    x = self.predict_next_day_head(z)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7_jlbF8ufGp",
    "outputId": "fac067c9-e243-47b1-9000-44a227cf2fa1",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:51.331953Z",
     "start_time": "2023-11-25T20:29:51.289923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_series_length : 100\n",
      "ouput size : 32\n",
      "ouput size : 32\n"
     ]
    }
   ],
   "source": [
    "print(f\"sub_series_length : {sub_series_length}\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "latent_dim = 64\n",
    "model_attention = RecurrentAutoencoder(sub_series_length, 1, 32,sub_seq_len=100,latent_dim=latent_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bFosZ2dsfvH",
    "outputId": "88f66a30-04bf-4ae5-f78e-d49b6fd36020",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:51.756473Z",
     "start_time": "2023-11-25T20:29:51.748129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecurrentAutoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (chunk_index_embedding): ChunkIndexEmbedding(\n",
      "      (embedding): Embedding(100, 32)\n",
      "    )\n",
      "    (mu): Linear(in_features=1600, out_features=64, bias=True)\n",
      "    (log_var): Linear(in_features=1600, out_features=64, bias=True)\n",
      "    (sampling_layer): SamplingLayerVAE()\n",
      "    (rnn1): LSTM(32, 32, batch_first=True, bidirectional=True)\n",
      "    (embedding_layer): Linear(in_features=1, out_features=32, bias=True)\n",
      "    (transformer_1): CompressWithAttentionResidual(\n",
      "      (Q_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (K_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (V_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (attention_output_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (output_linear): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (transformer_2): CompressWithAttentionResidual(\n",
      "      (Q_linear): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (K_linear): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (V_linear): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (attention_output_linear): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (output_linear): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (expend_layer_1): ExpandWithAttentionResidual(\n",
      "      (Q_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (K_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (V_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (attention_output_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (output_linear): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (norma): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (expend_layer_2): ExpandWithAttentionResidual(\n",
      "      (Q_linear): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (K_linear): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (V_linear): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (attention_output_linear): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (output_linear): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (norma): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (output_embeding): OutputEmbedding(\n",
      "      (embedding): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "    (chunk_index_embedding): ChunkIndexEmbedding(\n",
      "      (embedding): Embedding(100, 32)\n",
      "    )\n",
      "    (rnn1): LSTM(32, 32, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (predict_next_day_head): PredictNextDayHead(\n",
      "    (linear_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (linear_2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T20:29:52.205096Z",
     "start_time": "2023-11-25T20:29:52.202695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_param_LSTM : 682689\n",
      "trainable_param_attention : 303938\n"
     ]
    }
   ],
   "source": [
    "trainable_param_LSTM = sum(p.numel() for p in model_LSTM.parameters())\n",
    "print(f\"trainable_param_LSTM : {trainable_param_LSTM}\")\n",
    "trainable_param_attention = sum(p.numel() for p in model_attention.parameters())\n",
    "print(f\"trainable_param_attention : {trainable_param_attention}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[112], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Your processing logic here\u001B[39;00m\n\u001B[1;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 17\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_attention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_next_day\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(x,target)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m#loss.backward()\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m#optimizer.step()\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#epoch_loss += loss.item()\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[104], line 18\u001B[0m, in \u001B[0;36mRecurrentAutoencoder.predict_next_day\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_next_day\u001B[39m(\u001B[38;5;28mself\u001B[39m,x):\n\u001B[0;32m---> 18\u001B[0m   z, mu, sigma, original_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m   x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_next_day_head(z)\n\u001B[1;32m     20\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/PycharmProjects/StocksClusteringVAE/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/StocksClusteringVAE/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[99], line 63\u001B[0m, in \u001B[0;36mEncoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     61\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_index_embedding(x)\n\u001B[1;32m     62\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(x)\n\u001B[0;32m---> 63\u001B[0m x, (_, _) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_1(x)\n\u001B[1;32m     67\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_2(x)\n",
      "File \u001B[0;32m~/PycharmProjects/StocksClusteringVAE/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/StocksClusteringVAE/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/StocksClusteringVAE/venv/lib/python3.9/site-packages/torch/nn/modules/rnn.py:879\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    876\u001B[0m         hx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpermute_hidden(hx, sorted_indices)\n\u001B[1;32m    878\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 879\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    882\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[1;32m    883\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_train_data_loader = DataLoader(TensorDataset(X_train,y_train), batch_size=256, shuffle=True)\n",
    "prediction_test_data_loader = DataLoader(TensorDataset(X_test,y_test), batch_size=256, shuffle=True)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model_attention.parameters(), lr=1e-3)\n",
    "\n",
    "epoch = 100\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    epoch_loss = 0\n",
    "    for input,target in prediction_train_data_loader:\n",
    "        # Process each batch\n",
    "        batch = input.to(device)\n",
    "        batch = batch.to(torch.float32)\n",
    "        # Your processing logic here\n",
    "        optimizer.zero_grad()\n",
    "        x = model_attention.predict_next_day(batch)\n",
    "        loss = loss_fn(x,target)\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        #epoch_loss += loss.item()\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch}, loss: {loss.item()}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T20:33:41.458625Z",
     "start_time": "2023-11-25T20:33:24.331402Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "xlV0gPUvufGp",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:21:32.153322Z",
     "start_time": "2023-11-25T20:21:32.151256Z"
    }
   },
   "outputs": [],
   "source": [
    "def KL_loss(mu, sigma):\n",
    "    return -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "\n",
    "def reconstruction_loss(x, y):\n",
    "\n",
    "    return nn.MSELoss(reduction='sum')(x,y)\n",
    "\n",
    "def loss_function(x, original_x, mu, sigma,k1=1,k2=4e-2):\n",
    "    reconstruction  = reconstruction_loss(x, original_x)\n",
    "    kl = KL_loss(mu, sigma)\n",
    "    return k1 * reconstruction + k2 * kl  , reconstruction, kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYfQ0EHGufGp",
    "outputId": "a46f7ec3-3a66-4dfb-cbdd-c72679410057",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:21:32.769804Z",
     "start_time": "2023-11-25T20:21:32.738388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal_to_tensor shape : (5640, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy array to a PyTorch tensor\n",
    "# The shape is : (number_of_stocks, number_of_sub_series, sub_series_length, features)\n",
    "# We need to reshape it to (number_of_stocks * number_of_sub_series, sub_series_length, features)\n",
    "number_of_stocks = stocks_np_array.shape[0]\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "stocks_np_array_test = stocks_np_array.reshape((number_of_stocks*number_of_sub_series, sub_series_length, 1))\n",
    "signal_to_tensor = torch.from_numpy(stocks_np_array_test).float().to(device)\n",
    "print(f\"signal_to_tensor shape : {stocks_np_array_test.shape}\")\n",
    "# Forward pass through the model\n",
    "#x, original_x, mu, sigma = model_LSTM(signal_to_tensor)\n",
    "\n",
    "# Reconstruct the good output shape\n",
    "#x = x.reshape((number_of_stocks, number_of_sub_series, sub_series_length, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "fsiObNHocnVJ",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:21:33.968317Z",
     "start_time": "2023-11-25T20:21:33.963774Z"
    }
   },
   "outputs": [],
   "source": [
    "# load from cuda to cpu\n",
    "#model = torch.load(\"model.pth\",map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "IdYqaz71ufGp",
    "outputId": "7e00baa9-f932-4a3f-d06e-a56f21f3db79",
    "ExecuteTime": {
     "end_time": "2023-11-25T20:21:34.668583Z",
     "start_time": "2023-11-25T20:21:34.641169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random stocks : [313 229 291 501  14]\n",
      "random sub series : [3 2 4 7 0]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'original_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[68], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Plot the original and reconstructed signals\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(number_of_stocks_to_plot):\n\u001B[0;32m---> 11\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43moriginal_x\u001B[49m[random_stocks[i]][random_sub_series[i]]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy(), label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOriginal signal\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     12\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(x[random_stocks[i]][random_sub_series[i]]\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy(), label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReconstructed signal\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'original_x' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the reconstruction\n",
    "# Plot 10 random stocks\n",
    "number_of_stocks_to_plot = 5\n",
    "random_stocks = np.random.randint(0, number_of_stocks, number_of_stocks_to_plot)\n",
    "print(f\"random stocks : {random_stocks}\")\n",
    "# Plot 10 random sub-series\n",
    "random_sub_series = np.random.randint(0, number_of_sub_series, number_of_stocks_to_plot)\n",
    "print(f\"random sub series : {random_sub_series}\")\n",
    "# Plot the original and reconstructed signals\n",
    "for i in range(number_of_stocks_to_plot):\n",
    "    plt.plot(original_x[random_stocks[i]][random_sub_series[i]].cpu().detach().numpy(), label='Original signal')\n",
    "    plt.plot(x[random_stocks[i]][random_sub_series[i]].cpu().detach().numpy(), label='Reconstructed signal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "1iyceGB3ufGp",
    "outputId": "acbce16d-fdae-4ebb-f076-aa3652288c6b"
   },
   "outputs": [],
   "source": [
    "# try a simple overfitting\n",
    "optimizer = torch.optim.Adam(model_attention.parameters(), lr=1e-3)\n",
    "batch_size = 32\n",
    "shuffle = True  # To shuffle the data\n",
    "data_loader = DataLoader(stocks_np_array, batch_size=batch_size, shuffle=shuffle)\n",
    "loss_list_KL_attention = []\n",
    "loss_list_reconstruction_attention = []\n",
    "loss_list_attention = []\n",
    "#loss_fn = nn.L1Loss(reduction='sum')\n",
    "\n",
    "for epoch in range(200):\n",
    "    epoch_loss_KL = 0\n",
    "    epoch_loss_reconstruction = 0\n",
    "    epoch_loss = 0\n",
    "    for batch in data_loader:\n",
    "        # Process each batch\n",
    "        batch = batch.to(device)\n",
    "        batch = batch.to(torch.float32)\n",
    "        batch_size_current = batch.shape[0]\n",
    "        batch = batch.reshape((batch_size_current*number_of_sub_series, sub_series_length, 1))\n",
    "        # Your processing logic here\n",
    "        optimizer.zero_grad()\n",
    "        x, original_x, mu, sigma = model_attention(batch)\n",
    "        total_loss,reconstruction_l,KL_l = loss_function(x, original_x, mu, sigma)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss_KL += KL_l.item()\n",
    "        epoch_loss_reconstruction += reconstruction_l.item()\n",
    "        epoch_loss += total_loss.item()\n",
    "    loss_list_KL_attention.append(epoch_loss_KL)\n",
    "    loss_list_reconstruction_attention.append(epoch_loss_reconstruction)\n",
    "    loss_list_attention.append(epoch_loss)\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'Epoch: {epoch}, loss: {total_loss.item()}')\n",
    "# plot the loss, KL and reconstruction in 3 different color on the same plot\n",
    "# normalize loss between 0 and 1\n",
    "\"\"\"loss_list_attention = np.array(loss_list_attention)\n",
    "loss_list_attention = (loss_list_attention - np.min(loss_list_attention)) / (np.max(loss_list_attention) - np.min(loss_list_attention))\n",
    "loss_list_KL_attention = np.array(loss_list_KL_attention)\n",
    "loss_list_KL_attention = (loss_list_KL_attention - np.min(loss_list_KL_attention)) / (np.max(loss_list_KL_attention) - np.min(loss_list_KL_attention))\n",
    "loss_list_reconstruction_attention = np.array(loss_list_reconstruction_attention)\n",
    "loss_list_reconstruction_attention = (loss_list_reconstruction_attention - np.min(loss_list_reconstruction_attention)) / (np.max(loss_list_reconstruction_attention) - np.min(loss_list_reconstruction_attention))\n",
    "\"\"\"\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(loss_list_attention, label='Total loss')\n",
    "plt.plot(loss_list_KL_attention, label='KL loss')\n",
    "plt.plot(loss_list_reconstruction_attention, label='Reconstruction loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "id": "3kGHg2qscnVJ",
    "outputId": "dbb30cda-1b3f-4ff6-9c64-c294b94f5071",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try a simple overfitting\n",
    "optimizer = torch.optim.Adam(model_LSTM.parameters(), lr=2e-4)\n",
    "batch_size = 32\n",
    "shuffle = True  # To shuffle the data\n",
    "data_loader = DataLoader(stocks_np_array, batch_size=batch_size, shuffle=shuffle)\n",
    "loss_list_KL_LSTM = []\n",
    "loss_list_reconstruction_lSTM = []\n",
    "loss_list_LSTM = []\n",
    "#loss_fn = nn.L1Loss(reduction='sum')\n",
    "\n",
    "for epoch in range(500):\n",
    "    epoch_loss_KL = 0\n",
    "    epoch_loss_reconstruction = 0\n",
    "    epoch_loss = 0\n",
    "    for batch in data_loader:\n",
    "        # Process each batch\n",
    "        #print(\"Batch shape:\", batch.shape)  # Adjust this according to your processing needs\n",
    "        batch = batch.to(device)\n",
    "        batch = batch.to(torch.float32)\n",
    "        batch_size_current = batch.shape[0]\n",
    "        batch = batch.reshape((batch_size_current*number_of_sub_series, sub_series_length, 1))\n",
    "        # Your processing logic here\n",
    "        optimizer.zero_grad()\n",
    "        x, original_x, mu, sigma = model_LSTM(batch)\n",
    "        total_loss,reconstruction_l,KL_l = loss_function(x, original_x, mu, sigma)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss_KL += KL_l.item()\n",
    "        epoch_loss_reconstruction += reconstruction_l.item()\n",
    "        epoch_loss += total_loss.item()\n",
    "    loss_list_KL_LSTM.append(epoch_loss_KL)\n",
    "    loss_list_reconstruction_lSTM.append(epoch_loss_reconstruction)\n",
    "    loss_list_LSTM.append(epoch_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, loss: {total_loss.item()}')\n",
    "# plot the loss, KL and reconstruction in 3 different color on the same plot\n",
    "# normalize loss between 0 and 1\n",
    "\"\"\"loss_list_LSTM = np.array(loss_list_LSTM)\n",
    "loss_list_LSTM = (loss_list_LSTM - np.min(loss_list_LSTM)) / (np.max(loss_list_LSTM) - np.min(loss_list_LSTM))\n",
    "loss_list_KL_LSTM = np.array(loss_list_KL_LSTM)\n",
    "loss_list_KL_LSTM = (loss_list_KL_LSTM - np.min(loss_list_KL_LSTM)) / (np.max(loss_list_KL_LSTM) - np.min(loss_list_KL_LSTM))\n",
    "loss_list_reconstruction_LSTM = np.array(loss_list_reconstruction_lSTM)\n",
    "loss_list_reconstruction_LSTM = (loss_list_reconstruction_LSTM - np.min(loss_list_reconstruction_LSTM)) / (np.max(loss_list_reconstruction_LSTM) - np.min(loss_list_reconstruction_LSTM))\"\"\"\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(loss_list_LSTM, label='Total loss')\n",
    "plt.plot(loss_list_KL_LSTM, label='KL loss')\n",
    "plt.plot(loss_list_reconstruction_lSTM, label='Reconstruction loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "bqqK9PYQcnVJ",
    "outputId": "3a1522cb-1cb5-4e97-c831-ef0cdebb5412"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\"\"\"loss_list_LSTM = np.array(loss_list_LSTM)\n",
    "loss_list_LSTM = (loss_list_LSTM - np.min(loss_list_LSTM)) / (np.max(loss_list_LSTM) - np.min(loss_list_LSTM))\n",
    "loss_list_KL_LSTM = np.array(loss_list_KL_LSTM)\n",
    "loss_list_KL_LSTM = (loss_list_KL_LSTM - np.min(loss_list_KL_LSTM)) / (np.max(loss_list_KL_LSTM) - np.min(loss_list_KL_LSTM))\n",
    "loss_list_reconstruction_LSTM = np.array(loss_list_reconstruction_lSTM)\n",
    "loss_list_reconstruction_LSTM = (loss_list_reconstruction_LSTM - np.min(loss_list_reconstruction_LSTM)) / (np.max(loss_list_reconstruction_LSTM) - np.min(loss_list_reconstruction_LSTM))\n",
    "\"\"\"# Assuming you have lists of losses: loss_list_KL_LSTM, loss_list_KL_attention,\n",
    "# loss_list_reconstruction_lSTM, loss_list_reconstruction_attention, loss_list_LSTM, loss_list_attention\n",
    "\n",
    "# Plotting on three separate subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 5))\n",
    "\n",
    "# Subplot 1: KL loss\n",
    "axs[0].plot(loss_list_KL_LSTM, label='KL loss LSTM')\n",
    "axs[0].plot(loss_list_KL_attention, label='KL loss Attention')\n",
    "axs[0].set_title('KL Loss')\n",
    "axs[0].legend()\n",
    "\n",
    "# Subplot 2: Reconstruction loss\n",
    "axs[1].plot(loss_list_reconstruction_lSTM, label='Reconstruction loss LSTM')\n",
    "axs[1].plot(loss_list_reconstruction_attention, label='Reconstruction loss Attention')\n",
    "axs[1].set_title('Reconstruction Loss')\n",
    "axs[1].legend()\n",
    "# Subplot 3: Total loss\n",
    "axs[2].plot(loss_list_LSTM, label='Total loss LSTM')\n",
    "axs[2].plot(loss_list_attention, label='Total loss Attention')\n",
    "axs[2].set_title('Total Loss')\n",
    "axs[2].legend()\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "BzLxOulCcnVJ",
    "outputId": "a1c02df9-a243-41ae-c5e7-45e17bfdae54"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    x, original_x, mu, sigma = model_attention(signal_to_tensor)\n",
    "    x = x.cpu().detach().numpy()\n",
    "print(f\"x shape : {x.shape}\")\n",
    "# Plot the reconstruction of all signals\n",
    "stocks_kept= [stock[1] for stock in kept_stocks_with_indexes]\n",
    "stocks_to_plot = 10\n",
    "# Reshape the data\n",
    "print(f\"number_of_stocks : {number_of_stocks}\")\n",
    "print(f\"number_of_sub_series : {number_of_sub_series}\")\n",
    "print(f\"sub_series_length : {sub_series_length}\")\n",
    "stocks_np_array_reshaped = stocks_np_array.reshape((number_of_stocks, number_of_sub_series, sub_series_length))\n",
    "reconstructed_signals_reshaped = x.reshape((number_of_stocks, number_of_sub_series, sub_series_length, 1))\n",
    "print(f\"stocks_np_array_reshaped shape : {stocks_np_array_reshaped.shape}\")\n",
    "# Plot each stock in separate subplots\n",
    "plt.figure(figsize=(25, 18))\n",
    "\n",
    "for i in range(stocks_to_plot):\n",
    "    plt.subplot(stocks_to_plot, 1, i + 1)\n",
    "    plt.plot(stocks_np_array_reshaped[i].reshape((-1, 1)), label='Original Signal')\n",
    "    plt.plot(reconstructed_signals_reshaped[i].reshape((-1, 1)), label='Reconstructed Signal')\n",
    "    plt.title(f'Stock {stocks_kept[i]} - Original vs Reconstructed Signals')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Normalized Value')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "UnLunNiuufGp",
    "outputId": "96a4041d-6df8-44f9-ea06-ed6b7ad25eda"
   },
   "outputs": [],
   "source": [
    "# Apply PCA to the latent space\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Set seeds for reproducibility\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # with lstm : add _ \n",
    "    signals_latent,_,_,_= model_attention.encoder(signal_to_tensor)\n",
    "    signals_latent = signals_latent.squeeze().cpu().detach().numpy()\n",
    "print(f\"signals_latent shape : {signals_latent.shape}\")\n",
    "pca = PCA(n_components=2)\n",
    "latent_space = pca.fit_transform(signals_latent)\n",
    "# Reshape the latent space for each stock\n",
    "\n",
    "latent_space_np_array = np.array(latent_space).reshape((number_of_stocks, number_of_sub_series, 2))\n",
    "print(f\"latent_space_np_array shape : {latent_space_np_array.shape}\")\n",
    "# Plot the latent space for each stock\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, latent_space_stock in enumerate(latent_space_np_array):\n",
    "    plt.scatter(latent_space_stock[:, 0], latent_space_stock[:, 1], label=f'{stock_symbols[i]}')\n",
    "\n",
    "    # Annotate each point with its index\n",
    "    for j in range(number_of_sub_series):\n",
    "        plt.annotate(str(j), (latent_space_stock[j, 0], latent_space_stock[j, 1]))\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Latent Space Visualization with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojyPyE1Kh_FA"
   },
   "outputs": [],
   "source": [
    "# Apply PCA to the latent space\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Set seeds for reproducibility\n",
    "\n",
    "print(signal_to_tensor.shape)\n",
    "with torch.no_grad():\n",
    "    signals_latent,_,_,_ = model_attention.encoder(signal_to_tensor)\n",
    "    signals_latent = signals_latent.squeeze().cpu().detach().numpy()\n",
    "    print(signals_latent.shape)\n",
    "signals_latent_sumed = signals_latent.reshape(number_of_stocks,number_of_sub_series,latent_dim )\n",
    "\n",
    "signals_latent_sumed = np.sum(signals_latent_sumed, axis=(1))\n",
    "\n",
    "print(f\"signals_latent shape : {signals_latent_sumed.shape}\")\n",
    "pca = PCA(n_components=2)\n",
    "latent_space = pca.fit_transform(signals_latent_sumed)\n",
    "# Reshape the latent space for each stock\n",
    "print(latent_space.shape)\n",
    "latent_space_np_array = np.array(latent_space).reshape((number_of_stocks, 2))\n",
    "print(f\"latent_space_np_array shape : {latent_space_np_array.shape}\")\n",
    "# Plot the latent space for each stock\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, latent_space_stock in enumerate(latent_space_np_array):\n",
    "    plt.scatter(latent_space_stock[0], latent_space_stock[1], label=f'{stock_symbols[i]}')\n",
    "\n",
    "    # Annotate each point with its index\n",
    "    for j in range(number_of_sub_series):\n",
    "        plt.annotate(str(j), (latent_space_stock[0], latent_space_stock[1]))\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Latent Space Visualization with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGui_z3gcnVJ"
   },
   "outputs": [],
   "source": [
    "# Apply K-means to the latent space\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "K_means_PCA = KMeans(n_clusters=8, random_state=seed)\n",
    "K_means_PCA.fit(latent_space_np_array)\n",
    "inertia_Kmeans_PCA = K_means_PCA.inertia_\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(latent_space_np_array[:, 0], latent_space_np_array[:, 1], c=K_means_PCA.labels_, cmap='rainbow')\n",
    "plt.scatter(K_means_PCA.cluster_centers_[:, 0], K_means_PCA.cluster_centers_[:, 1], color='black')\n",
    "plt.title('K-means Clustering with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rXvrL8mcnVJ"
   },
   "outputs": [],
   "source": [
    " # Elbow Method for K means\n",
    "# Import ElbowVisualizer\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "model_bis = KMeans()\n",
    "# k is range of number of clusters.\n",
    "visualizer = KElbowVisualizer(model_bis, k=(2,30), timings= True)\n",
    "# Fit data to visualizer\n",
    "visualizer.fit(latent_space_np_array)\n",
    "visualizer.show()        # Finalize and render figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSw3G8JMcnVK"
   },
   "outputs": [],
   "source": [
    "# Silhouette Score for K means\n",
    "# Import ElbowVisualizer\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "models = KMeans()\n",
    "# k is range of number of clusters.\n",
    "visualizer = KElbowVisualizer(models, k=(2,30),metric='silhouette', timings= True)\n",
    "visualizer.fit(latent_space_np_array)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0WJM4VHLcnVK"
   },
   "outputs": [],
   "source": [
    "cluster_to_plot = 0\n",
    "# Plot the signals in the cluster\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, cluster in enumerate(K_means_PCA.labels_):\n",
    "    if cluster == cluster_to_plot:\n",
    "        plt.plot(stocks_np_array_reshaped[i].reshape((-1, 1)), label=f'{stock_symbols[i]}')\n",
    "plt.title(f'Stocks in Cluster {cluster_to_plot}')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tm5DahwSRz3n"
   },
   "outputs": [],
   "source": [
    "# interpolate between two signales\n",
    "# take the first signal\n",
    "print(f\"latent_signal_np_array shape : {signals_latent.shape}\")\n",
    "signals_latent = signals_latent.reshape((number_of_stocks, number_of_sub_series, latent_dim))\n",
    "\n",
    "signal_1_index,signal_1_name = 79, stock_symbols[79]\n",
    "\n",
    "signal_2_index ,signal_2_name = 43, stock_symbols[43]\n",
    "signal_1 = signals_latent[signal_1_index]\n",
    "signal_2 = signals_latent[signal_2_index]\n",
    "\n",
    "# define the number of points to interpolate\n",
    "number_of_points = signal_1.shape[0]\n",
    "print(f\"number_of_points : {number_of_points}\")\n",
    "print(f\"signal_1 shape : {signal_1.shape}\")\n",
    "print(f\"signal_2 shape : {signal_2.shape}\")\n",
    "new_signal = np.zeros((number_of_points,latent_dim))\n",
    "\n",
    "for i in range(number_of_points):\n",
    "\n",
    "\n",
    "    new_signal[i] = (signal_1[i] + (signal_2[i]) ) / 2\n",
    "\n",
    "# apply PCA to the new signal\n",
    "#pca = PCA(n_components=2)\n",
    "#\n",
    "# plot the latent space with the 3 signals in different colors\n",
    "#latent_space_new_signal = pca.fit_transform(new_signal)\n",
    "latent_space_new_signal = new_signal\n",
    "plt.scatter(signal_1[:,0],signal_1[:,1],label=signal_1_name)\n",
    "plt.scatter(signal_2[:,0],signal_2[:,1],label=signal_2_name)\n",
    "plt.scatter(latent_space_new_signal[:,0],latent_space_new_signal[:,1],label='new signal')\n",
    "for i in range(number_of_points):\n",
    "    plt.annotate(str(i), (signal_1[i, 0], signal_1[i, 1]))\n",
    "    plt.annotate(str(i), (signal_2[i, 0], signal_2[i, 1]))\n",
    "    plt.annotate(str(i), (latent_space_new_signal[i, 0], latent_space_new_signal[i, 1]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtobWaqXRz3n"
   },
   "outputs": [],
   "source": [
    "# decode the new signal\n",
    "new_signal = torch.from_numpy(new_signal).float().to(device)\n",
    "new_signal = new_signal.squeeze()\n",
    "print(f\"new signal shape : {new_signal.shape}\")\n",
    "with torch.no_grad():\n",
    "    new_signal_decoded = model_LSTM.decoder(new_signal)\n",
    "    new_signal_decoded = nn.Tanh()(new_signal_decoded)\n",
    "    new_signal_decoded = new_signal_decoded.squeeze().cpu().detach().numpy()\n",
    "print(f\"new signal decoded shape : {new_signal_decoded.shape}\")\n",
    "new_signal_decoded = new_signal_decoded.reshape((number_of_sub_series*sub_series_length,1))\n",
    "\n",
    "stocks_array_flatten = stocks_np_array.reshape((number_of_stocks,number_of_sub_series*sub_series_length,1))\n",
    "print(f\"stocks_array_flatten shape : {stocks_array_flatten.shape}\")\n",
    "# plot the new signal decoded, the first signal and the second signal\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.plot(stocks_array_flatten[signal_1_index],label=signal_1_name)\n",
    "plt.plot(stocks_array_flatten[signal_2_index],label=signal_2_name)\n",
    "plt.plot(new_signal_decoded,label='new signal decoded')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDhe8yubuc01"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Supposons que signals_latent, number_of_stocks, number_of_sub_series, latent_dim, signal_symbols sont définis\n",
    "\n",
    "# Réorganiser signals_latent\n",
    "signals_latent = signals_latent.reshape((number_of_stocks, number_of_sub_series, latent_dim))\n",
    "\n",
    "signal_1_index, signal_1_name = 79, stock_symbols[79]\n",
    "signal_2_index, signal_2_name = 43, stock_symbols[43]\n",
    "\n",
    "signal_1 = signals_latent[signal_1_index]\n",
    "signal_2 = signals_latent[signal_2_index]\n",
    "\n",
    "# Définir le nombre de points à interpoler\n",
    "number_of_points = 10\n",
    "\n",
    "# Créer un tableau de points entre signal_1 et signal_2\n",
    "interpolated_signals = np.linspace(signal_1, signal_2, num=number_of_points+2)[1:-1]  # Générer les points intermédiaires\n",
    "# Afficher les formes des signaux\n",
    "print(f\"Forme de signal_1 : {signal_1.shape}\")\n",
    "print(f\"Forme de signal_2 : {signal_2.shape}\")\n",
    "print(f\"Forme des signaux interpolés : {interpolated_signals.shape}\")\n",
    "\n",
    "# Le tableau interpolated_signals contient les 10 valeurs intermédiaires entre signal_1 et signal_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# decode the new signal\n",
    "interpolated_signals_tensor = torch.from_numpy(interpolated_signals).float().to(device)\n",
    "interpolated_signals_tensor = interpolated_signals_tensor.squeeze()\n",
    "interpolated_signals_tensor = interpolated_signals_tensor.reshape((number_of_points*number_of_sub_series,latent_dim))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    interpolated_signals_decoded = model_LSTM.decoder(interpolated_signals_tensor)\n",
    "    interpolated_signals_decoded = nn.Tanh()(interpolated_signals_decoded)\n",
    "    interpolated_signals_decoded = interpolated_signals_decoded.squeeze().cpu().detach().numpy()\n",
    "print(f\"interpolated_signals_decoded shape : {interpolated_signals_decoded.shape}\")\n",
    "interpolated_signals_decoded = interpolated_signals_decoded.reshape((number_of_points,number_of_sub_series*sub_series_length,1))\n",
    "print(f\"interpolated_signals_decoded shape : {interpolated_signals_decoded.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the new signal decoded, the first signal and the second signal\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.plot(stocks_array_flatten[signal_1_index],label=signal_1_name)\n",
    "plt.plot(stocks_array_flatten[signal_2_index],label=signal_2_name)\n",
    "for i in range(number_of_points):\n",
    "    plt.plot(interpolated_signals_decoded[i],label=f\"interpolated signal {i}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
